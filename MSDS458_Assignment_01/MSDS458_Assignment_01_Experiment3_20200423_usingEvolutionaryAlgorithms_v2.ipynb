{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATE: April 24, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1:\n",
    "\n",
    "In this assignment, we construct **dense neural networks** for classifying images from the `MNIST` dataset: http://yann.lecun.com/exdb/mnist/. The MNIST database consists of a set of 70,000 small (28x28 pixel) grayscale images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. \n",
    "\n",
    ">In **EXPERIMENTS 1 to 3**, we consider `dense neural network` models with one hidden layer. We start with one node in this hidden layer and progressively increase the number of (hidden) nodes in the layer until we find the \"best\" model in Experiment 3.\n",
    "\n",
    " But our goal in these `three` experiments is *not only* to find the \"best\" `dense neural network` model with one hidden but *also* to explore what the node(s) in the hidden layer are \"detecting\" and what their outputs (i.e. `activation values`) contribute to the final classification of an image. These are examples of intrinsic `global explanations` and `local explanations` , respectively, as described in this recent survey article: \n",
    "\n",
    "https://cacm.acm.org/magazines/2020/1/241703-techniques-for-interpretable-machine-learning/fulltext\n",
    "\n",
    "To determine what the hidden node is \"detecting\" we use gradient descent to find a visual pattern that maximizes the activation value of the hidden node, i.e. the visual pattern that the hidden node is maximally responsive to. In this case, the exercise is probably not very insightful. But in `Assignment 2`  we will repeat this analysis with \"clusters of nodes\" (`convnet filters`) in `convolutional neural network` models. By the examining the patterns that each convnet filter is maximally responsive (but also by visualizing the convnet activations for particular test images) we should be able to determine what (some of) the filters in the `CCN` model are up to. The (activation values of the) hidden nodes (actually, groups of hidden nodes corresponding or *convnet filters*) can be visualized in various ways to show what \"features\" (edges, texture, etc.) of the input images they capture.\n",
    "\n",
    ">In **EXPERIMENT 4** we use PCA decomposition to reduce the number of dimensions of our training set of 28x28 dimensional MNIST images from 784 to 154 (with 95% of training images variance lying along these components). We also reduce the number of dimensions of 'best' model from `Experiment 3` to 154 inputs nodes and train it on the new lower dimensional data. \n",
    "\n",
    ">In **EXPERIMENT 5** we use a Random Forest classifier to get the relative importance of the 784 features (pixels) of the 28x28 dimensional images in training set of MNIST images and select the top 70 features (pixels). We train our 'best' `dense neural network` using these 70 features and compare its performance to the the `dense neural network` models from EXPERIMENTS 3 and 4.\n",
    "\n",
    "Here are more details for the first `three` experiments:\n",
    "\n",
    "* **EXPERIMENT 1**: Our `dense neural network` will consist of 784 input nodes, a hidden layer with `1 node` and 10 output nodes (corresponding to the 10 digits). We use `mnist.load_data()` to get the 70,000 images divided into a set of 60,000 training images and 10,000 test images. We hold back 5,000 of the 60,000 training images for validation. After training the model, we group the 60,000 `activation values` of the hidden node for the (original) set of training images by the 10 predicted classes and visualize these sets of values using a `boxplot`. We expect the overlap between the range of values in the \"boxes\" to be minimal. In addition, we find the pattern that maximally activates the hidden node as a \"warm up\" exercise for similar analysis we will perform on `CNN` models in `Assignment 2`.\n",
    "\n",
    "* **EXPERIMENT 2**: This time our `dense neural network` will have 784 input nodes, a hidden layer with `2 nodes` and 10 output nodes (corresponding to the 10 digits). For each of the 60,000 images, the output of the two hidden nodes are plotted using a `scatterplot`. We color code the points according to which of the 10 classes the the output of the two nodes predicts. Ideally, just like in `EXPERIMENT 1`, the color clusters should have very little overlap.\n",
    "\n",
    "**NOTE**: For EXPERIMENTS 1 & 2 we also perform the following additional tasks:\n",
    "> 1. We use Matplotlib to create 2 plots--displaying the training and validation loss (resp. accuracy) for each (training) epoch side by side.\n",
    "> 2. For each model we obtain the confusion matrix and use it to display sample images of true vs false positives and negatives.\n",
    "\n",
    "\n",
    "* **EXPERIMENT 3**: Students can experiment with more hidden nodes (in the hidden layer) to obtain the `best` model. This `final` model will be used in EXPERIMENTS 4 & 5.\n",
    "\n",
    "\n",
    "**References**:\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks (2.1 & 5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages needed (and set seed)\n",
    "\n",
    "Since Keras in part of TensorFlow 2.x, we import keras from tensorflow and use tenserflow.keras.xxx to import all other Keras packages. The seed argument produces a deterministic sequence of tensors across multiple calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "The MNIST dataset of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It comes prepackaged as part of tf.Keras. Use the `mnist.load_data()` to the get these datasets (and the corresponding labels) as Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT  3:\n",
    "\n",
    "We want to select the *best* `DNN` model subject to some the following restriction on `hyperparameters`:\n",
    "* The number of hidden layers will be one. \n",
    "\n",
    "We will use `sklearn.grid_search.GridSearchCV` to find the `best` number of neurons for the hidden layer.\n",
    "\n",
    "As before we will need 784 input nodes and 10 output nodes (corresponding to the 10 digits). We use `mnist.load_data()` to get the 70,000 images divided into a set of 60,000 training images and 10,000 test images. We hold back 5,000 of the 60,000 training images for validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the \\[0, 1] interval.\n",
    "\n",
    "Our training images are stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. \n",
    "\n",
    "We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach\n",
    "\n",
    "Since we will be using categorical_crossentropy as the loss function we need to use to_categorical to convert the class vector of lables to binary matrix representation. \n",
    "\n",
    "We set apart 5,000 samples of our training data to use as a validation set. Since we will be using `sparse_categorical_crossentropy` as the loss function we **do not** need to use `to_categorical` to convert the class vector of labels to binary matrix representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, train_images = train_images[:5000], train_images[5000:] \n",
    "val_labels, train_labels = train_labels[:5000], train_labels[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Hyperparameters\n",
    "\n",
    "We adapt the code from Chapter 10 of Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow by A. Geron:\n",
    "\n",
    "https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html. \n",
    "\n",
    "We define a `build_model` function to create a `DNN` model with a given number of hidden layers and a fixed given number of nodes per hidden layer. (What if we wanted the number of nodes to vary by layer?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=2, learning_rate=0.001, input_shape=(28 * 28,)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No that the `build_model` function creates a neural network with the same (*n_neurons*) number of nodes in each hidden layer. Here is the revised `build_model2` that takes a tuple `(n1,n2...)`, where the number of coordinates is the number of `hidden layers` with `n1` nodes in the first hidden layer, `n2` nodes in the second, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(n_neurons=(2,3), learning_rate=0.001, input_shape=(28 * 28,)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(len(n_neurons)):\n",
    "        model.add(keras.layers.Dense(n_neurons[layer], activation=\"relu\"))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New we a create a `KerasClassifier` object, the class is an implementation of the scikit-learn classifier API for Keras. It is actually a thin wrapper around the model that is built using our `build_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_clf = KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first consider the performance from using 1 to 100 hidden nodes, i.e. we use the following grid parameters.\n",
    "\n",
    "```python\n",
    "param_grid = {'n_neurons': range(1,100)}\n",
    "param_grid\n",
    "```\n",
    "and found that 20 hidden nodes provided the best model with a test accuracy of 95.99%. \n",
    "\n",
    "We also tried multiples of 100 from 100 up to 900. Running the test and found the 500 nodes gave the best result with an accuracy of 99.68%. We demonstrate this latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': range(1, 101)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_neurons': range(1,101)}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `evolutionary algorithms` instead of gridsearch in scikit-learn. This allows you to reduce the time required to find the best parameters for your estimator. Instead of trying out every possible combination of parameters, evolve only the combinations that give the best results.\n",
    "\n",
    "See https://github.com/rsteca/sklearn-deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-deap in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (from sklearn-deap) (0.22.1)\n",
      "Requirement already satisfied: deap>=1.0.2 in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (from sklearn-deap) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (from sklearn-deap) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.16.0 in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (from sklearn-deap) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages (from scikit-learn>=0.18.0->sklearn-deap) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "# first we need to install sklearn-dd\n",
    "!pip install sklearn-deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "# I used the default parameters on the sklearn-deap Github page\n",
    "grid_cv = EvolutionaryAlgorithmSearchCV(estimator=keras_clf,\n",
    "                                   params=param_grid,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=50,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1] and maxint [99] detected\n",
      "--- Evolve in 100 possible combinations ---\n",
      "Train on 36666 samples\n",
      "   32/36666 [..............................] - ETA: 10:34 - loss: 2.3987 - accuracy: 0.0625Train on 36666 samples\n",
      "12352/36666 [=========>....................] - ETA: 2s - loss: 0.5411 - accuracy: 0.8567Train on 36666 samples\n",
      "11776/36666 [========>.....................] - ETA: 4s - loss: 0.5741 - accuracy: 0.8477Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 107us/sample - loss: 0.3619 - accuracy: 0.8995\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.3714 - accuracy: 0.8965\n",
      "14752/36666 [===========>..................] - ETA: 4s - loss: 0.7667 - accuracy: 0.7933Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.3383 - accuracy: 0.9055\n",
      "  800/36667 [..............................] - ETA: 48s - loss: 1.7259 - accuracy: 0.5325  Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 0.5123 - accuracy: 0.8569\n",
      " 4032/36667 [==>...........................] - ETA: 10s - loss: 0.9271 - accuracy: 0.7604Train on 36667 samples\n",
      "11392/36667 [========>.....................] - ETA: 4s - loss: 0.5913 - accuracy: 0.8416Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.3681 - accuracy: 0.8974\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.3848 - accuracy: 0.8932\n",
      "23488/36667 [==================>...........] - ETA: 1s - loss: 0.4008 - accuracy: 0.8886Train on 36667 samples\n",
      "36064/36667 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.9041Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 0.3399 - accuracy: 0.9046\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.5121 - accuracy: 0.8584\n",
      " 3392/36667 [=>............................] - ETA: 17s - loss: 1.1073 - accuracy: 0.7096Train on 36667 samples\n",
      "20192/36667 [===============>..............] - ETA: 2s - loss: 0.4740 - accuracy: 0.8729Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3756 - accuracy: 0.8967\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.4047 - accuracy: 0.8880\n",
      "30400/36667 [=======================>......] - ETA: 0s - loss: 0.5726 - accuracy: 0.8419Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3451 - accuracy: 0.9037\n",
      "36667/36667 [==============================] - 5s 132us/sample - loss: 0.5283 - accuracy: 0.8534\n",
      "Train on 36666 samples\n",
      "18400/36666 [==============>...............] - ETA: 2s - loss: 0.9642 - accuracy: 0.7291Train on 36666 samples\n",
      " 5440/36666 [===>..........................] - ETA: 8s - loss: 1.0388 - accuracy: 0.7162Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 109us/sample - loss: 0.7103 - accuracy: 0.7996\n",
      "36666/36666 [==============================] - 4s 121us/sample - loss: 0.4634 - accuracy: 0.8687\n",
      "23200/36666 [=================>............] - ETA: 2s - loss: 0.4055 - accuracy: 0.8862Train on 36667 samples\n",
      "31968/36666 [=========================>....] - ETA: 0s - loss: 0.3497 - accuracy: 0.9017Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 133us/sample - loss: 0.3451 - accuracy: 0.9011\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.3337 - accuracy: 0.9053\n",
      "21088/36667 [================>.............] - ETA: 1s - loss: 0.9648 - accuracy: 0.7065Train on 36667 samples\n",
      "22112/36667 [=================>............] - ETA: 1s - loss: 0.9442 - accuracy: 0.7134Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 103us/sample - loss: 0.7482 - accuracy: 0.7782\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.4325 - accuracy: 0.8818\n",
      "17920/36667 [=============>................] - ETA: 3s - loss: 0.4424 - accuracy: 0.8795Train on 36667 samples\n",
      "26336/36667 [====================>.........] - ETA: 1s - loss: 0.3795 - accuracy: 0.8948Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 202us/sample - loss: 0.3417 - accuracy: 0.9054\n",
      "36667/36667 [==============================] - 8s 212us/sample - loss: 0.3389 - accuracy: 0.9056\n",
      "15648/36667 [===========>..................] - ETA: 6s - loss: 0.6622 - accuracy: 0.8213Train on 36667 samples\n",
      "18080/36667 [=============>................] - ETA: 5s - loss: 0.6223 - accuracy: 0.8314Train on 36667 samples\n",
      "36667/36667 [==============================] - 8s 208us/sample - loss: 0.8019 - accuracy: 0.7625\n",
      "36667/36667 [==============================] - 8s 207us/sample - loss: 0.4551 - accuracy: 0.8739\n",
      " 8768/36667 [======>.......................] - ETA: 8s - loss: 0.6131 - accuracy: 0.8319Train on 36666 samples\n",
      "19008/36667 [==============>...............] - ETA: 4s - loss: 0.4511 - accuracy: 0.8736Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 196us/sample - loss: 0.3495 - accuracy: 0.9014\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3454 - accuracy: 0.9025\n",
      "20704/36666 [===============>..............] - ETA: 3s - loss: 0.5100 - accuracy: 0.8643Train on 36666 samples\n",
      "32800/36666 [=========================>....] - ETA: 0s - loss: 0.5650 - accuracy: 0.8487Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.5403 - accuracy: 0.8543\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.4161 - accuracy: 0.8856\n",
      "11328/36666 [========>.....................] - ETA: 5s - loss: 0.5373 - accuracy: 0.8588Train on 36667 samples\n",
      "17696/36666 [=============>................] - ETA: 3s - loss: 1.6509 - accuracy: 0.4711Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 1.4275 - accuracy: 0.5321\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.3446 - accuracy: 0.9036\n",
      "30976/36667 [========================>.....] - ETA: 0s - loss: 0.5387 - accuracy: 0.8560Train on 36667 samples\n",
      "31648/36667 [========================>.....] - ETA: 0s - loss: 0.5340 - accuracy: 0.8572Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.5083 - accuracy: 0.8632\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 0.4010 - accuracy: 0.8907\n",
      " 6720/36667 [====>.........................] - ETA: 7s - loss: 0.6578 - accuracy: 0.8247Train on 36667 samples\n",
      "14976/36667 [===========>..................] - ETA: 3s - loss: 1.7281 - accuracy: 0.4278Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 1.4352 - accuracy: 0.5355\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.3488 - accuracy: 0.9026\n",
      "32448/36667 [=========================>....] - ETA: 0s - loss: 0.5520 - accuracy: 0.8507Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.5242 - accuracy: 0.8576\n",
      "30688/36667 [========================>.....] - ETA: 0s - loss: 0.4417 - accuracy: 0.8802Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 133us/sample - loss: 0.4108 - accuracy: 0.8871\n",
      " 3520/36667 [=>............................] - ETA: 12s - loss: 0.9033 - accuracy: 0.7622Train on 36666 samples\n",
      "15040/36667 [===========>..................] - ETA: 3s - loss: 1.7499 - accuracy: 0.3279Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 1.4306 - accuracy: 0.4996\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.3663 - accuracy: 0.8965\n",
      "24640/36666 [===================>..........] - ETA: 1s - loss: 0.4227 - accuracy: 0.8840Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.5477 - accuracy: 0.8427\n",
      "34496/36666 [===========================>..] - ETA: 0s - loss: 0.3749 - accuracy: 0.8948Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.3669 - accuracy: 0.8971\n",
      " 7840/36666 [=====>........................] - ETA: 6s - loss: 0.6136 - accuracy: 0.8386Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5920/36666 [===>..........................] - ETA: 8s - loss: 0.6907 - accuracy: 0.8199Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.3460 - accuracy: 0.9026\n",
      "36666/36666 [==============================] - 6s 172us/sample - loss: 0.3493 - accuracy: 0.9012\n",
      "31936/36667 [=========================>....] - ETA: 0s - loss: 0.5504 - accuracy: 0.8534Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.5217 - accuracy: 0.8598\n",
      "35104/36667 [===========================>..] - ETA: 0s - loss: 0.3710 - accuracy: 0.8978Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.3663 - accuracy: 0.8991\n",
      " 7232/36667 [====>.........................] - ETA: 6s - loss: 0.6480 - accuracy: 0.8283Train on 36667 samples\n",
      "18112/36667 [=============>................] - ETA: 2s - loss: 0.4472 - accuracy: 0.8777Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3426 - accuracy: 0.9051\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.3394 - accuracy: 0.9054\n",
      "28704/36667 [======================>.......] - ETA: 1s - loss: 0.4221 - accuracy: 0.8856Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.5877 - accuracy: 0.8388\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3797 - accuracy: 0.8960\n",
      "  352/36667 [..............................] - ETA: 1:49 - loss: 1.9793 - accuracy: 0.3835 Train on 36667 samples\n",
      "11808/36667 [========>.....................] - ETA: 5s - loss: 0.5375 - accuracy: 0.8537Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.3446 - accuracy: 0.9037\n",
      "33472/36667 [==========================>...] - ETA: 0s - loss: 0.3612 - accuracy: 0.8988Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3480 - accuracy: 0.9024\n",
      "10944/36666 [=======>......................] - ETA: 9s - loss: 0.7410 - accuracy: 0.8071 Train on 36666 samples\n",
      "25280/36666 [===================>..........] - ETA: 2s - loss: 0.5251 - accuracy: 0.8578Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 172us/sample - loss: 0.4586 - accuracy: 0.8734\n",
      "18560/36666 [==============>...............] - ETA: 3s - loss: 0.7472 - accuracy: 0.7962Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 147us/sample - loss: 0.3663 - accuracy: 0.8946\n",
      "36256/36666 [============================>.] - ETA: 0s - loss: 0.5662 - accuracy: 0.8417Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 155us/sample - loss: 0.5637 - accuracy: 0.8426\n",
      " 5088/36667 [===>..........................] - ETA: 10s - loss: 0.7610 - accuracy: 0.7995Train on 36667 samples\n",
      "36666/36666 [==============================] - 8s 206us/sample - loss: 0.3300 - accuracy: 0.9050\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.4531 - accuracy: 0.8768\n",
      "16448/36667 [============>.................] - ETA: 3s - loss: 0.7857 - accuracy: 0.7823Train on 36667 samples\n",
      "36384/36667 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.9018Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.3499 - accuracy: 0.9021\n",
      "36667/36667 [==============================] - 5s 125us/sample - loss: 0.5637 - accuracy: 0.8422\n",
      " 4672/36667 [==>...........................] - ETA: 11s - loss: 1.2406 - accuracy: 0.6697Train on 36667 samples\n",
      "10784/36667 [=======>......................] - ETA: 6s - loss: 0.8317 - accuracy: 0.7814Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.3294 - accuracy: 0.9078\n",
      "36667/36667 [==============================] - 6s 175us/sample - loss: 0.4849 - accuracy: 0.8681\n",
      "26944/36667 [=====================>........] - ETA: 2s - loss: 0.4088 - accuracy: 0.8857Train on 36667 samples\n",
      "34624/36667 [===========================>..] - ETA: 0s - loss: 0.6133 - accuracy: 0.8318Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.5986 - accuracy: 0.8357\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3583 - accuracy: 0.8993\n",
      " 8000/36667 [=====>........................] - ETA: 5s - loss: 0.6007 - accuracy: 0.8356Train on 36666 samples\n",
      " 5792/36666 [===>..........................] - ETA: 8s - loss: 0.9338 - accuracy: 0.7655Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.3274 - accuracy: 0.9065\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 0.4307 - accuracy: 0.8809\n",
      "32576/36666 [=========================>....] - ETA: 0s - loss: 0.3572 - accuracy: 0.9006Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.3922 - accuracy: 0.8922\n",
      "35136/36666 [===========================>..] - ETA: 0s - loss: 0.3474 - accuracy: 0.9029Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 146us/sample - loss: 0.3416 - accuracy: 0.9045\n",
      " 5920/36666 [===>..........................] - ETA: 6s - loss: 0.6478 - accuracy: 0.8274Train on 36667 samples\n",
      " 6816/36666 [====>.........................] - ETA: 5s - loss: 0.6140 - accuracy: 0.8352Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.4429 - accuracy: 0.8783\n",
      "36666/36666 [==============================] - 5s 147us/sample - loss: 0.3249 - accuracy: 0.9081\n",
      "35872/36667 [============================>.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8890Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.4053 - accuracy: 0.8897\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.3357 - accuracy: 0.9069\n",
      " 6368/36667 [====>.........................] - ETA: 5s - loss: 0.9176 - accuracy: 0.7701Train on 36667 samples\n",
      " 5344/36667 [===>..........................] - ETA: 7s - loss: 0.6889 - accuracy: 0.8134Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.4362 - accuracy: 0.8828\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.3323 - accuracy: 0.9067\n",
      "30528/36667 [=======================>......] - ETA: 1s - loss: 0.3748 - accuracy: 0.8931Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3936 - accuracy: 0.8909\n",
      "35840/36667 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8998Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3485 - accuracy: 0.9006\n",
      " 1472/36667 [>.............................] - ETA: 22s - loss: 1.1649 - accuracy: 0.6943Train on 36666 samples\n",
      " 1504/36667 [>.............................] - ETA: 23s - loss: 1.1512 - accuracy: 0.6988Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.3376 - accuracy: 0.9035\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.3336 - accuracy: 0.9051\n",
      "36666/36666 [==============================] - 6s 163us/sample - loss: 0.5070 - accuracy: 0.8628\n",
      "36666/36666 [==============================] - 6s 167us/sample - loss: 0.3696 - accuracy: 0.8965\n",
      "Train on 36667 samples\n",
      "Train on 36666 samples\n",
      "   64/36667 [..............................] - ETA: 6:41 - loss: 2.2431 - accuracy: 0.1094 Train on 36667 samples\n",
      "  128/36667 [..............................] - ETA: 4:17 - loss: 2.1371 - accuracy: 0.2734Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 134us/sample - loss: 0.8063 - accuracy: 0.7647\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.3320 - accuracy: 0.9073\n",
      "36667/36667 [==============================] - 6s 152us/sample - loss: 0.4806 - accuracy: 0.8662\n",
      "32448/36667 [=========================>....] - ETA: 0s - loss: 0.3826 - accuracy: 0.8937Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.3661 - accuracy: 0.8980\n",
      "Train on 36667 samples\n",
      " 1088/36667 [..............................] - ETA: 32s - loss: 2.1265 - accuracy: 0.2399 Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1824/36667 [>.............................] - ETA: 21s - loss: 1.0524 - accuracy: 0.7111Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.7909 - accuracy: 0.7796\n",
      "30112/36667 [=======================>......] - ETA: 1s - loss: 0.4020 - accuracy: 0.8896Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.3344 - accuracy: 0.9051\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.4722 - accuracy: 0.8722\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.3709 - accuracy: 0.8972\n",
      " 4096/36667 [==>...........................] - ETA: 10s - loss: 1.7582 - accuracy: 0.3889Train on 36666 samples\n",
      " 7680/36667 [=====>........................] - ETA: 5s - loss: 1.5198 - accuracy: 0.4915Train on 36666 samples\n",
      "12448/36667 [=========>....................] - ETA: 3s - loss: 1.2814 - accuracy: 0.5803Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 126us/sample - loss: 0.8007 - accuracy: 0.7544\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 1.9519 - accuracy: 0.2419\n",
      "36666/36666 [==============================] - 5s 137us/sample - loss: 1.5377 - accuracy: 0.4515\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.3289 - accuracy: 0.9062\n",
      "Train on 36666 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 150us/sample - loss: 0.3315 - accuracy: 0.9070\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 1.6850 - accuracy: 0.4049\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 1.5521 - accuracy: 0.4092\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3323 - accuracy: 0.9068\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "  800/36667 [..............................] - ETA: 37s - loss: 1.5450 - accuracy: 0.6012  Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.3318 - accuracy: 0.9062\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 1.7499 - accuracy: 0.3300\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 1.4440 - accuracy: 0.5030\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3367 - accuracy: 0.9062\n",
      "Train on 36667 samples\n",
      " 3264/36667 [=>............................] - ETA: 6s - loss: 0.8736 - accuracy: 0.7641Train on 36666 samples\n",
      "13600/36667 [==========>...................] - ETA: 2s - loss: 0.4899 - accuracy: 0.8623Train on 36666 samples\n",
      "18112/36667 [=============>................] - ETA: 2s - loss: 0.4446 - accuracy: 0.87486Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 128us/sample - loss: 0.3358 - accuracy: 0.9045\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.3667 - accuracy: 0.8969\n",
      "36666/36666 [==============================] - 5s 126us/sample - loss: 1.1421 - accuracy: 0.6068\n",
      "26688/36666 [====================>.........] - ETA: 1s - loss: 0.4915 - accuracy: 0.8671Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.4345 - accuracy: 0.8801\n",
      "  832/36666 [..............................] - ETA: 41s - loss: 1.5207 - accuracy: 0.5962  Train on 36667 samples\n",
      " 3872/36666 [==>...........................] - ETA: 9s - loss: 0.8408 - accuracy: 0.7905 Train on 36667 samples\n",
      " 6528/36666 [====>.........................] - ETA: 6s - loss: 0.6706 - accuracy: 0.8290Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.3533 - accuracy: 0.9018\n",
      "36667/36667 [==============================] - 5s 139us/sample - loss: 1.3183 - accuracy: 0.5505\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.3612 - accuracy: 0.9012\n",
      "35520/36667 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.8801Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.4299 - accuracy: 0.8812\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "  352/36667 [..............................] - ETA: 1:18 - loss: 2.3135 - accuracy: 0.0540 Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 1.3511 - accuracy: 0.5374\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3478 - accuracy: 0.9017\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3716 - accuracy: 0.8986\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.4372 - accuracy: 0.8781\n",
      "Train on 36666 samples\n",
      "Train on 36667 samples\n",
      "Train on 36666 samples\n",
      "   32/36667 [..............................] - ETA: 12:49 - loss: 2.4516 - accuracy: 0.1250Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3565 - accuracy: 0.8996\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.3414 - accuracy: 0.9032\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.3851 - accuracy: 0.8925\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.4307 - accuracy: 0.8803\n",
      "Train on 36666 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      " 1920/36667 [>.............................] - ETA: 10s - loss: 1.0859 - accuracy: 0.7349Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 155us/sample - loss: 0.3678 - accuracy: 0.8989\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3294 - accuracy: 0.9081\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3862 - accuracy: 0.8955\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.4317 - accuracy: 0.8822\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.3658 - accuracy: 0.8985\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3365 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3975 - accuracy: 0.8897\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.4411 - accuracy: 0.8788\n",
      "Train on 36667 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 177us/sample - loss: 0.3688 - accuracy: 0.8970\n",
      "36666/36666 [==============================] - 7s 179us/sample - loss: 0.3412 - accuracy: 0.9024\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.3412 - accuracy: 0.9024\n",
      "36666/36666 [==============================] - 7s 188us/sample - loss: 0.5785 - accuracy: 0.8375\n",
      "Train on 36666 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.4109 - accuracy: 0.8852\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.5395 - accuracy: 0.8530\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3399 - accuracy: 0.9049\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.3399 - accuracy: 0.9049\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.4099 - accuracy: 0.8864\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.6178 - accuracy: 0.8258\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.3558 - accuracy: 0.9014\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.3558 - accuracy: 0.9014\n",
      "Train on 36667 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.4208 - accuracy: 0.8847\n",
      "36666/36666 [==============================] - 6s 165us/sample - loss: 0.3625 - accuracy: 0.8981\n",
      "36666/36666 [==============================] - 7s 181us/sample - loss: 0.3940 - accuracy: 0.8900\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.3373 - accuracy: 0.9045\n",
      "Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32/36667 [..............................] - ETA: 13:23 - loss: 2.4150 - accuracy: 0.1875Train on 36667 samples\n",
      "Train on 36666 samples\n",
      " 1664/36667 [>.............................] - ETA: 16s - loss: 1.2301 - accuracy: 0.6839 Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.3608 - accuracy: 0.8991\n",
      "36666/36666 [==============================] - 5s 140us/sample - loss: 1.4490 - accuracy: 0.5236\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.3711 - accuracy: 0.8968\n",
      "32576/36667 [=========================>....] - ETA: 0s - loss: 0.3483 - accuracy: 0.9031Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.3331 - accuracy: 0.9072\n",
      " 6560/36667 [====>.........................] - ETA: 6s - loss: 2.0458 - accuracy: 0.1976Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 1.5541 - accuracy: 0.4815\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.3638 - accuracy: 0.8985\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.3877 - accuracy: 0.8897\n",
      "21760/36667 [================>.............] - ETA: 2s - loss: 0.4122 - accuracy: 0.8846Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.3332 - accuracy: 0.9064\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 1.3910 - accuracy: 0.5154\n",
      "Train on 36666 samples\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.3969 - accuracy: 0.8892\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3810 - accuracy: 0.8957\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3928 - accuracy: 0.8915\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t50    \t0.893034\t0.441455\t0.940127\t0.0964546\n",
      "Train on 36666 samples\n",
      " 4992/36666 [===>..........................] - ETA: 3s - loss: 0.7471 - accuracy: 0.8047Train on 36666 samples\n",
      " 4224/36666 [==>...........................] - ETA: 9s - loss: 0.7874 - accuracy: 0.7926 Train on 36666 samples\n",
      "20512/36666 [===============>..............] - ETA: 1s - loss: 0.4228 - accuracy: 0.8828Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.3452 - accuracy: 0.9017\n",
      "15744/36666 [===========>..................] - ETA: 4s - loss: 0.4509 - accuracy: 0.8741Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 163us/sample - loss: 0.3363 - accuracy: 0.9050\n",
      "34944/36666 [===========================>..] - ETA: 0s - loss: 0.3435 - accuracy: 0.9017Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 173us/sample - loss: 0.3368 - accuracy: 0.9036\n",
      "36666/36666 [==============================] - 7s 178us/sample - loss: 0.3604 - accuracy: 0.8997\n",
      " 3040/36667 [=>............................] - ETA: 15s - loss: 0.8785 - accuracy: 0.7743Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 182us/sample - loss: 0.3437 - accuracy: 0.9040\n",
      "35488/36667 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.9059Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3321 - accuracy: 0.9072\n",
      " 3904/36667 [==>...........................] - ETA: 12s - loss: 0.8578 - accuracy: 0.7723Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3601 - accuracy: 0.9001\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3374 - accuracy: 0.9056\n",
      " 3264/36667 [=>............................] - ETA: 15s - loss: 0.9267 - accuracy: 0.7629Train on 36667 samples\n",
      " 5728/36667 [===>..........................] - ETA: 9s - loss: 0.7430 - accuracy: 0.8045 Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3505 - accuracy: 0.9007\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.3468 - accuracy: 0.9028\n",
      "22432/36667 [=================>............] - ETA: 2s - loss: 0.4107 - accuracy: 0.8837Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.3720 - accuracy: 0.8945\n",
      "36667/36667 [==============================] - 5s 142us/sample - loss: 0.3348 - accuracy: 0.9044\n",
      " 4000/36666 [==>...........................] - ETA: 12s - loss: 0.8492 - accuracy: 0.7765Train on 36666 samples\n",
      "17440/36666 [=============>................] - ETA: 2s - loss: 0.4711 - accuracy: 0.87035Train on 36666 samples\n",
      " 2272/36666 [>.............................] - ETA: 17s - loss: 1.0204 - accuracy: 0.7276Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.3725 - accuracy: 0.8935\n",
      "34112/36666 [==========================>...] - ETA: 0s - loss: 0.3454 - accuracy: 0.9011Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 139us/sample - loss: 0.3368 - accuracy: 0.9036\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.3677 - accuracy: 0.8960\n",
      "36666/36666 [==============================] - 5s 144us/sample - loss: 0.3242 - accuracy: 0.9086\n",
      " 6624/36667 [====>.........................] - ETA: 8s - loss: 0.7081 - accuracy: 0.8146Train on 36667 samples\n",
      "16768/36667 [============>.................] - ETA: 3s - loss: 0.4827 - accuracy: 0.8671Train on 36667 samples\n",
      "16256/36667 [============>.................] - ETA: 3s - loss: 0.4551 - accuracy: 0.8744Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 137us/sample - loss: 0.3620 - accuracy: 0.8992\n",
      " 5344/36667 [===>..........................] - ETA: 12s - loss: 0.6495 - accuracy: 0.8185Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 134us/sample - loss: 0.3374 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.3650 - accuracy: 0.8989\n",
      "21248/36667 [================>.............] - ETA: 2s - loss: 0.3935 - accuracy: 0.8889Train on 36667 samples\n",
      "   32/36667 [..............................] - ETA: 19:30 - loss: 2.4616 - accuracy: 0.0312Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3234 - accuracy: 0.9080\n",
      "18176/36667 [=============>................] - ETA: 3s - loss: 0.4427 - accuracy: 0.8754Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.3674 - accuracy: 0.8972\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.3348 - accuracy: 0.9044\n",
      "36667/36667 [==============================] - 6s 150us/sample - loss: 0.3677 - accuracy: 0.8983\n",
      "20704/36667 [===============>..............] - ETA: 2s - loss: 0.4270 - accuracy: 0.8799Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.3377 - accuracy: 0.9042\n",
      " 6784/36666 [====>.........................] - ETA: 6s - loss: 0.9037 - accuracy: 0.7680Train on 36666 samples\n",
      "17664/36666 [=============>................] - ETA: 2s - loss: 0.5954 - accuracy: 0.8427Train on 36666 samples\n",
      "   32/36666 [..............................] - ETA: 17:49 - loss: 2.3959 - accuracy: 0.0000e+00Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.4533 - accuracy: 0.8754\n",
      "31552/36666 [========================>.....] - ETA: 0s - loss: 0.3570 - accuracy: 0.9002Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 142us/sample - loss: 0.3384 - accuracy: 0.9045\n",
      "36666/36666 [==============================] - 6s 154us/sample - loss: 0.3646 - accuracy: 0.8981\n",
      "12608/36667 [=========>....................] - ETA: 4s - loss: 0.7156 - accuracy: 0.8128Train on 36667 samples\n",
      "  288/36667 [..............................] - ETA: 1:23 - loss: 1.9905 - accuracy: 0.4236 Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.3252 - accuracy: 0.9069\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.4659 - accuracy: 0.8737\n",
      " 7328/36667 [====>.........................] - ETA: 8s - loss: 0.6536 - accuracy: 0.8216Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 5s 139us/sample - loss: 0.3431 - accuracy: 0.9047\n",
      "14016/36667 [==========>...................] - ETA: 4s - loss: 0.4578 - accuracy: 0.8743Train on 36667 samples\n",
      "16288/36667 [============>.................] - ETA: 4s - loss: 0.4311 - accuracy: 0.8816Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.3611 - accuracy: 0.8976\n",
      "33984/36667 [==========================>...] - ETA: 0s - loss: 0.3256 - accuracy: 0.9089Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.3167 - accuracy: 0.9113\n",
      " 6368/36667 [====>.........................] - ETA: 9s - loss: 0.7750 - accuracy: 0.7946 Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 0.4736 - accuracy: 0.8703\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.3458 - accuracy: 0.9039\n",
      "19168/36667 [==============>...............] - ETA: 3s - loss: 0.4870 - accuracy: 0.8656Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.3741 - accuracy: 0.8958\n",
      "23776/36667 [==================>...........] - ETA: 2s - loss: 0.3954 - accuracy: 0.8883Train on 36666 samples\n",
      "15200/36666 [===========>..................] - ETA: 4s - loss: 0.4631 - accuracy: 0.8737Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.3315 - accuracy: 0.9061\n",
      "17824/36666 [=============>................] - ETA: 2s - loss: 0.5169 - accuracy: 0.8610Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 163us/sample - loss: 0.3372 - accuracy: 0.9050\n",
      " 5184/36666 [===>..........................] - ETA: 10s - loss: 0.7256 - accuracy: 0.8129Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 138us/sample - loss: 0.4000 - accuracy: 0.8876\n",
      "16864/36666 [============>.................] - ETA: 3s - loss: 0.4511 - accuracy: 0.8768Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.3576 - accuracy: 0.9000\n",
      " 2880/36667 [=>............................] - ETA: 20s - loss: 1.1116 - accuracy: 0.7125Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3441 - accuracy: 0.9028\n",
      "35776/36667 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.9066Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.3301 - accuracy: 0.9075\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.3831 - accuracy: 0.8930\n",
      " 4096/36667 [==>...........................] - ETA: 15s - loss: 0.7964 - accuracy: 0.7917Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3593 - accuracy: 0.9005\n",
      " 1408/36667 [>.............................] - ETA: 38s - loss: 1.2231 - accuracy: 0.6783Train on 36667 samples\n",
      "24384/36667 [==================>...........] - ETA: 2s - loss: 0.3964 - accuracy: 0.8892Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3404 - accuracy: 0.9041\n",
      "16160/36667 [============>.................] - ETA: 4s - loss: 0.4978 - accuracy: 0.8656Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.3427 - accuracy: 0.9025\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3869 - accuracy: 0.8924\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3617 - accuracy: 0.8998\n",
      "20800/36667 [================>.............] - ETA: 2s - loss: 0.4372 - accuracy: 0.8786Train on 36666 samples\n",
      "33856/36667 [==========================>...] - ETA: 0s - loss: 0.3593 - accuracy: 0.8993Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 135us/sample - loss: 0.3490 - accuracy: 0.9021\n",
      "12224/36666 [=========>....................] - ETA: 3s - loss: 0.6617 - accuracy: 0.8180Train on 36666 samples\n",
      "19840/36666 [===============>..............] - ETA: 2s - loss: 0.4086 - accuracy: 0.8867Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.4229 - accuracy: 0.8801\n",
      "35296/36666 [===========================>..] - ETA: 0s - loss: 0.3324 - accuracy: 0.9054Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3272 - accuracy: 0.9069\n",
      "36666/36666 [==============================] - 6s 173us/sample - loss: 0.3394 - accuracy: 0.9017\n",
      "29536/36666 [=======================>......] - ETA: 1s - loss: 0.3663 - accuracy: 0.8971Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.3388 - accuracy: 0.9040\n",
      "23040/36667 [=================>............] - ETA: 1s - loss: 0.5046 - accuracy: 0.8633Train on 36667 samples\n",
      "   64/36667 [..............................] - ETA: 12:09 - loss: 2.3068 - accuracy: 0.1875Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 122us/sample - loss: 0.4251 - accuracy: 0.8830\n",
      "23488/36667 [==================>...........] - ETA: 2s - loss: 0.3826 - accuracy: 0.8952Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3236 - accuracy: 0.9098\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3329 - accuracy: 0.9072\n",
      "19840/36667 [===============>..............] - ETA: 3s - loss: 0.5314 - accuracy: 0.8583Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 179us/sample - loss: 0.3380 - accuracy: 0.9061\n",
      " 2592/36667 [=>............................] - ETA: 17s - loss: 0.9266 - accuracy: 0.7515Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.4146 - accuracy: 0.8872\n",
      "14752/36667 [===========>..................] - ETA: 3s - loss: 0.4697 - accuracy: 0.8683Train on 36667 samples\n",
      "19936/36667 [===============>..............] - ETA: 2s - loss: 0.4200 - accuracy: 0.8816Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3293 - accuracy: 0.9063\n",
      "19584/36666 [===============>..............] - ETA: 3s - loss: 0.4128 - accuracy: 0.8869Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.3360 - accuracy: 0.9064\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.3516 - accuracy: 0.9014\n",
      "34464/36666 [===========================>..] - ETA: 0s - loss: 0.3409 - accuracy: 0.9036Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.3335 - accuracy: 0.9056\n",
      "13856/36666 [==========>...................] - ETA: 4s - loss: 0.4476 - accuracy: 0.8779Train on 36666 samples\n",
      "17120/36666 [=============>................] - ETA: 3s - loss: 0.4146 - accuracy: 0.8871Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3220 - accuracy: 0.9089\n",
      "21952/36667 [================>.............] - ETA: 2s - loss: 0.4017 - accuracy: 0.8884Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 176us/sample - loss: 0.3388 - accuracy: 0.9040\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3304 - accuracy: 0.9078\n",
      "36666/36666 [==============================] - 7s 186us/sample - loss: 0.3230 - accuracy: 0.9089\n",
      " 7744/36667 [=====>........................] - ETA: 7s - loss: 0.5722 - accuracy: 0.8481Train on 36667 samples\n",
      "19136/36667 [==============>...............] - ETA: 2s - loss: 0.4076 - accuracy: 0.88835Train on 36667 samples\n",
      " 1376/36667 [>.............................] - ETA: 28s - loss: 1.2736 - accuracy: 0.6672Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.3208 - accuracy: 0.9105\n",
      "19040/36667 [==============>...............] - ETA: 3s - loss: 0.4390 - accuracy: 0.8765Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 0.3380 - accuracy: 0.9061\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3391 - accuracy: 0.9040\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3244 - accuracy: 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7328/36667 [====>.........................] - ETA: 8s - loss: 0.6194 - accuracy: 0.8259Train on 36667 samples\n",
      "19520/36667 [==============>...............] - ETA: 2s - loss: 0.4278 - accuracy: 0.8787Train on 36667 samples\n",
      "10464/36667 [=======>......................] - ETA: 5s - loss: 0.5527 - accuracy: 0.8509Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.3354 - accuracy: 0.9042\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.3516 - accuracy: 0.9014\n",
      "22560/36666 [=================>............] - ETA: 2s - loss: 0.3834 - accuracy: 0.8938Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3255 - accuracy: 0.9069\n",
      "36666/36666 [==============================] - 6s 167us/sample - loss: 0.3223 - accuracy: 0.9087\n",
      "10944/36666 [=======>......................] - ETA: 4s - loss: 0.5242 - accuracy: 0.8607Train on 36666 samples\n",
      " 3264/36666 [=>............................] - ETA: 11s - loss: 0.8705 - accuracy: 0.7825Train on 36667 samples\n",
      " 6688/36666 [====>.........................] - ETA: 6s - loss: 0.6391 - accuracy: 0.8348Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 121us/sample - loss: 0.3356 - accuracy: 0.9064\n",
      " 1696/36667 [>.............................] - ETA: 54s - loss: 1.0600 - accuracy: 0.7370 Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 0.3346 - accuracy: 0.9061\n",
      "22592/36667 [=================>............] - ETA: 3s - loss: 0.3849 - accuracy: 0.8927Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 143us/sample - loss: 0.4905 - accuracy: 0.8645\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.3215 - accuracy: 0.9098\n",
      "24704/36667 [===================>..........] - ETA: 1s - loss: 0.3944 - accuracy: 0.8885Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 138us/sample - loss: 0.3439 - accuracy: 0.9027\n",
      " 4416/36667 [==>...........................] - ETA: 22s - loss: 0.7522 - accuracy: 0.7982Train on 36667 samples\n",
      " 9920/36667 [=======>......................] - ETA: 7s - loss: 0.5326 - accuracy: 0.8531Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.4835 - accuracy: 0.8673\n",
      "36667/36667 [==============================] - 8s 224us/sample - loss: 0.3432 - accuracy: 0.9028\n",
      "33952/36667 [==========================>...] - ETA: 0s - loss: 0.3301 - accuracy: 0.9066Train on 36667 samples\n",
      "14432/36667 [==========>...................] - ETA: 4s - loss: 0.4870 - accuracy: 0.8619Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 201us/sample - loss: 0.3204 - accuracy: 0.9093\n",
      " 7488/36667 [=====>........................] - ETA: 8s - loss: 0.6258 - accuracy: 0.8361Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3416 - accuracy: 0.9020\n",
      "10912/36666 [=======>......................] - ETA: 5s - loss: 0.5694 - accuracy: 0.8439Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.4783 - accuracy: 0.8715\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.3426 - accuracy: 0.9046\n",
      "16832/36666 [============>.................] - ETA: 3s - loss: 0.4746 - accuracy: 0.8705Train on 36666 samples\n",
      "18304/36666 [=============>................] - ETA: 3s - loss: 0.4593 - accuracy: 0.8742Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 150us/sample - loss: 0.3662 - accuracy: 0.8959\n",
      "35136/36666 [===========================>..] - ETA: 0s - loss: 0.3653 - accuracy: 0.8967Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 128us/sample - loss: 0.3592 - accuracy: 0.8984\n",
      "19296/36666 [==============>...............] - ETA: 2s - loss: 0.7177 - accuracy: 0.8094Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 149us/sample - loss: 0.5467 - accuracy: 0.8505\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3440 - accuracy: 0.9021\n",
      "22080/36667 [=================>............] - ETA: 2s - loss: 0.4372 - accuracy: 0.8801Train on 36667 samples\n",
      "33088/36667 [==========================>...] - ETA: 0s - loss: 0.3798 - accuracy: 0.8964Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.3655 - accuracy: 0.9003\n",
      "36667/36667 [==============================] - 5s 146us/sample - loss: 0.3621 - accuracy: 0.9003\n",
      "11040/36667 [========>.....................] - ETA: 4s - loss: 0.9464 - accuracy: 0.7505Train on 36667 samples\n",
      "14144/36667 [==========>...................] - ETA: 4s - loss: 0.4802 - accuracy: 0.8707Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.5562 - accuracy: 0.8493\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3418 - accuracy: 0.9051\n",
      "22624/36667 [=================>............] - ETA: 2s - loss: 0.4414 - accuracy: 0.8769Train on 36667 samples\n",
      "29696/36667 [=======================>......] - ETA: 1s - loss: 0.3949 - accuracy: 0.8900Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3718 - accuracy: 0.8957\n",
      "36667/36667 [==============================] - 6s 155us/sample - loss: 0.3614 - accuracy: 0.8988\n",
      "36667/36667 [==============================] - 4s 108us/sample - loss: 0.5673 - accuracy: 0.8464\n",
      "36667/36667 [==============================] - 4s 115us/sample - loss: 0.3393 - accuracy: 0.9050\n",
      "1  \t32    \t0.931965\t0.901418\t0.940127\t0.0081826\n",
      "Train on 36666 samples\n",
      " 3104/36666 [=>............................] - ETA: 7s - loss: 0.8209 - accuracy: 0.7883Train on 36666 samples\n",
      "17120/36666 [=============>................] - ETA: 2s - loss: 0.4166 - accuracy: 0.8853Train on 36666 samples\n",
      "28224/36666 [======================>.......] - ETA: 1s - loss: 0.3541 - accuracy: 0.9003Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 0.3238 - accuracy: 0.9074\n",
      "36666/36666 [==============================] - 6s 159us/sample - loss: 0.3312 - accuracy: 0.9048\n",
      "22944/36666 [=================>............] - ETA: 2s - loss: 0.3854 - accuracy: 0.8920Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.3275 - accuracy: 0.9066\n",
      "Train on 36667 samples\n",
      "35776/36666 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.9051Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 175us/sample - loss: 0.3270 - accuracy: 0.9062\n",
      "21280/36667 [================>.............] - ETA: 2s - loss: 0.4002 - accuracy: 0.8886Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3250 - accuracy: 0.9108\n",
      "36667/36667 [==============================] - 5s 150us/sample - loss: 0.3308 - accuracy: 0.9070\n",
      "25856/36667 [====================>.........] - ETA: 1s - loss: 0.3748 - accuracy: 0.8942Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 149us/sample - loss: 0.3308 - accuracy: 0.9063\n",
      " 1536/36667 [>.............................] - ETA: 32s - loss: 1.1935 - accuracy: 0.6751 Train on 36667 samples\n",
      " 1216/36667 [..............................] - ETA: 43s - loss: 1.3269 - accuracy: 0.6628 Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3296 - accuracy: 0.9076\n",
      "23360/36667 [==================>...........] - ETA: 2s - loss: 0.4028 - accuracy: 0.8862Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 187us/sample - loss: 0.3322 - accuracy: 0.9063\n",
      "33376/36667 [==========================>...] - ETA: 0s - loss: 0.3468 - accuracy: 0.9030Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.3336 - accuracy: 0.9064\n",
      " 2432/36666 [>.............................] - ETA: 21s - loss: 0.9824 - accuracy: 0.7336Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.3342 - accuracy: 0.9049\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.3338 - accuracy: 0.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26656/36666 [====================>.........] - ETA: 1s - loss: 0.3844 - accuracy: 0.8914Train on 36666 samples\n",
      "29504/36666 [=======================>......] - ETA: 1s - loss: 0.3707 - accuracy: 0.8945Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.3440 - accuracy: 0.9014\n",
      "36666/36666 [==============================] - 6s 156us/sample - loss: 0.3428 - accuracy: 0.9018\n",
      "12032/36666 [========>.....................] - ETA: 4s - loss: 0.5063 - accuracy: 0.8625Train on 36667 samples\n",
      " 2816/36667 [=>............................] - ETA: 19s - loss: 0.9100 - accuracy: 0.7756Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.3440 - accuracy: 0.9014\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.3438 - accuracy: 0.9028\n",
      " 9536/36667 [======>.......................] - ETA: 6s - loss: 0.5494 - accuracy: 0.8531Train on 36667 samples\n",
      "26592/36667 [====================>.........] - ETA: 1s - loss: 0.3812 - accuracy: 0.8939Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.3405 - accuracy: 0.9049\n",
      "13248/36667 [=========>....................] - ETA: 5s - loss: 0.4843 - accuracy: 0.8693Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3370 - accuracy: 0.9054\n",
      "31136/36667 [========================>.....] - ETA: 0s - loss: 0.3594 - accuracy: 0.8998Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3405 - accuracy: 0.9049\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.3355 - accuracy: 0.9073\n",
      "10752/36667 [=======>......................] - ETA: 5s - loss: 0.5301 - accuracy: 0.8553Train on 36667 samples\n",
      "11296/36667 [========>.....................] - ETA: 5s - loss: 0.5197 - accuracy: 0.8576Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.3362 - accuracy: 0.9052\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.3337 - accuracy: 0.9063\n",
      "25344/36667 [===================>..........] - ETA: 2s - loss: 0.3978 - accuracy: 0.8868Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 157us/sample - loss: 0.3362 - accuracy: 0.9052\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.3398 - accuracy: 0.9035\n",
      "Train on 36666 samples\n",
      " 5376/36666 [===>..........................] - ETA: 16s - loss: 0.7153 - accuracy: 0.8088Train on 36666 samples\n",
      "14560/36666 [==========>...................] - ETA: 6s - loss: 0.4772 - accuracy: 0.8677Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.3326 - accuracy: 0.9043\n",
      "36666/36666 [==============================] - 7s 198us/sample - loss: 0.3443 - accuracy: 0.9020\n",
      "19424/36666 [==============>...............] - ETA: 4s - loss: 0.4242 - accuracy: 0.8833Train on 36667 samples\n",
      "21504/36666 [================>.............] - ETA: 4s - loss: 0.4089 - accuracy: 0.8864Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 168us/sample - loss: 0.3248 - accuracy: 0.9080\n",
      "36666/36666 [==============================] - 8s 212us/sample - loss: 0.3438 - accuracy: 0.9028\n",
      "18432/36667 [==============>...............] - ETA: 2s - loss: 0.4397 - accuracy: 0.8800Train on 36667 samples\n",
      "21984/36667 [================>.............] - ETA: 2s - loss: 0.4142 - accuracy: 0.8861Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.3435 - accuracy: 0.9039\n",
      "17152/36667 [=============>................] - ETA: 4s - loss: 0.4399 - accuracy: 0.8800Train on 36667 samples\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.3245 - accuracy: 0.9100\n",
      "34432/36667 [===========================>..] - ETA: 0s - loss: 0.3424 - accuracy: 0.9055Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.3357 - accuracy: 0.9073\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.3355 - accuracy: 0.9073\n",
      " 4288/36667 [==>...........................] - ETA: 14s - loss: 0.7795 - accuracy: 0.7875Train on 36667 samples\n",
      "23104/36667 [=================>............] - ETA: 2s - loss: 0.4262 - accuracy: 0.8801Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.3493 - accuracy: 0.9019\n",
      "18592/36667 [==============>...............] - ETA: 3s - loss: 0.4428 - accuracy: 0.8760Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3308 - accuracy: 0.9051\n",
      "31904/36667 [=========================>....] - ETA: 0s - loss: 0.3600 - accuracy: 0.8978Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 177us/sample - loss: 0.3379 - accuracy: 0.9050\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3398 - accuracy: 0.9035\n",
      "23136/36666 [=================>............] - ETA: 2s - loss: 0.3825 - accuracy: 0.8942Train on 36666 samples\n",
      " 9888/36666 [=======>......................] - ETA: 6s - loss: 0.6393 - accuracy: 0.8300Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 163us/sample - loss: 0.3248 - accuracy: 0.9080\n",
      "33536/36666 [==========================>...] - ETA: 0s - loss: 0.3948 - accuracy: 0.8894Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.3831 - accuracy: 0.8922\n",
      "34336/36666 [===========================>..] - ETA: 0s - loss: 0.3472 - accuracy: 0.9015Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 164us/sample - loss: 0.3493 - accuracy: 0.9022\n",
      "36666/36666 [==============================] - 6s 153us/sample - loss: 0.3390 - accuracy: 0.9039\n",
      "18592/36667 [==============>...............] - ETA: 3s - loss: 0.4332 - accuracy: 0.8816Train on 36667 samples\n",
      " 6016/36667 [===>..........................] - ETA: 8s - loss: 0.7926 - accuracy: 0.7914Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3357 - accuracy: 0.9073\n",
      "35744/36667 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8926Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.3860 - accuracy: 0.8933\n",
      "36480/36667 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.9033Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.3435 - accuracy: 0.9035\n",
      "36667/36667 [==============================] - 5s 145us/sample - loss: 0.3446 - accuracy: 0.9042\n",
      " 1984/36667 [>.............................] - ETA: 26s - loss: 1.3023 - accuracy: 0.6583Train on 36667 samples\n",
      "18848/36667 [==============>...............] - ETA: 3s - loss: 0.4399 - accuracy: 0.8768Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 147us/sample - loss: 0.3379 - accuracy: 0.9050\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3941 - accuracy: 0.8898\n",
      "29024/36667 [======================>.......] - ETA: 1s - loss: 0.3797 - accuracy: 0.8936Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3518 - accuracy: 0.8993\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3437 - accuracy: 0.9035\n",
      " 6656/36666 [====>.........................] - ETA: 8s - loss: 0.6384 - accuracy: 0.8320Train on 36666 samples\n",
      "22400/36666 [=================>............] - ETA: 2s - loss: 0.3938 - accuracy: 0.8907Train on 36666 samples\n",
      "18976/36666 [==============>...............] - ETA: 2s - loss: 0.4075 - accuracy: 0.8884Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 136us/sample - loss: 0.3298 - accuracy: 0.9067\n",
      "36666/36666 [==============================] - 5s 131us/sample - loss: 0.3256 - accuracy: 0.9083\n",
      " 7008/36666 [====>.........................] - ETA: 9s - loss: 0.6492 - accuracy: 0.8315 Train on 36667 samples\n",
      "   32/36667 [..............................] - ETA: 21:38 - loss: 2.2959 - accuracy: 0.0938Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 176us/sample - loss: 0.3379 - accuracy: 0.9039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 7s 189us/sample - loss: 0.3470 - accuracy: 0.9027\n",
      "26176/36667 [====================>.........] - ETA: 2s - loss: 0.3767 - accuracy: 0.8964Train on 36667 samples\n",
      "33920/36667 [==========================>...] - ETA: 0s - loss: 0.3432 - accuracy: 0.9048Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.3340 - accuracy: 0.9074\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.3312 - accuracy: 0.9077\n",
      "14304/36667 [==========>...................] - ETA: 4s - loss: 0.4574 - accuracy: 0.8740Train on 36667 samples\n",
      "10784/36667 [=======>......................] - ETA: 6s - loss: 0.5413 - accuracy: 0.8513Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.3240 - accuracy: 0.9089\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.3472 - accuracy: 0.9020\n",
      "25536/36667 [===================>..........] - ETA: 2s - loss: 0.4044 - accuracy: 0.8847Train on 36667 samples\n",
      "   32/36667 [..............................] - ETA: 24:57 - loss: 2.3634 - accuracy: 0.0938Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.3492 - accuracy: 0.9004\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.3352 - accuracy: 0.9060\n",
      " 2112/36667 [>.............................] - ETA: 25s - loss: 1.1586 - accuracy: 0.7008Train on 36666 samples\n",
      " 9792/36667 [=======>......................] - ETA: 6s - loss: 0.6042 - accuracy: 0.8386Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.3396 - accuracy: 0.9052\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3587 - accuracy: 0.8996\n",
      "29184/36666 [======================>.......] - ETA: 1s - loss: 0.3568 - accuracy: 0.8990Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 197us/sample - loss: 0.3281 - accuracy: 0.9068\n",
      "34272/36666 [===========================>..] - ETA: 0s - loss: 0.3362 - accuracy: 0.9043Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 192us/sample - loss: 0.3281 - accuracy: 0.9068\n",
      " 6208/36666 [====>.........................] - ETA: 6s - loss: 0.6482 - accuracy: 0.8288Train on 36667 samples\n",
      " 3616/36666 [=>............................] - ETA: 12s - loss: 0.8053 - accuracy: 0.7860Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 170us/sample - loss: 0.3345 - accuracy: 0.9057\n",
      "36666/36666 [==============================] - 7s 194us/sample - loss: 0.3256 - accuracy: 0.9083\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3221 - accuracy: 0.9087\n",
      "28864/36667 [======================>.......] - ETA: 1s - loss: 0.3505 - accuracy: 0.9011Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.3221 - accuracy: 0.9087\n",
      "Train on 36667 samples\n",
      " 1888/36667 [>.............................] - ETA: 18s - loss: 1.0635 - accuracy: 0.7288     Train on 36667 samples\n",
      " 2880/36667 [=>............................] - ETA: 13s - loss: 0.8692 - accuracy: 0.7750Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.3289 - accuracy: 0.9072\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.3217 - accuracy: 0.9096\n",
      "35808/36667 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.9059Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3293 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 7s 198us/sample - loss: 0.3293 - accuracy: 0.9068\n",
      "Train on 36667 samples\n",
      "24192/36667 [==================>...........] - ETA: 1s - loss: 0.4022 - accuracy: 0.8882Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 141us/sample - loss: 0.3383 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 5s 144us/sample - loss: 0.3304 - accuracy: 0.9068\n",
      "36666/36666 [==============================] - 4s 120us/sample - loss: 0.3259 - accuracy: 0.9074\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 0.3233 - accuracy: 0.9092\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.3267 - accuracy: 0.9082\n",
      "Train on 36666 samples\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 0.3493 - accuracy: 0.9010\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.3480 - accuracy: 0.9034\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 0.3581 - accuracy: 0.8987\n",
      "2  \t26    \t0.937006\t0.926691\t0.940127\t0.00216912\n",
      "Train on 36666 samples\n",
      "11104/36666 [========>.....................] - ETA: 3s - loss: 0.5152 - accuracy: 0.8578Train on 36666 samples\n",
      " 2816/36666 [=>............................] - ETA: 16s - loss: 0.9030 - accuracy: 0.7610Train on 36666 samples\n",
      "   32/36666 [..............................] - ETA: 21:03 - loss: 2.3387 - accuracy: 0.0625Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 127us/sample - loss: 0.3369 - accuracy: 0.9041\n",
      "15264/36666 [===========>..................] - ETA: 4s - loss: 0.4467 - accuracy: 0.8780Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3256 - accuracy: 0.9083\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.3277 - accuracy: 0.9071\n",
      "36666/36666 [==============================] - 6s 159us/sample - loss: 0.3221 - accuracy: 0.9084\n",
      " 8640/36667 [======>.......................] - ETA: 12s - loss: 0.5725 - accuracy: 0.8514Train on 36667 samples\n",
      "11392/36667 [========>.....................] - ETA: 8s - loss: 0.5101 - accuracy: 0.8661Train on 36667 samples\n",
      "  576/36667 [..............................] - ETA: 1:11 - loss: 1.6748 - accuracy: 0.5260 Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.3278 - accuracy: 0.9095\n",
      "30176/36667 [=======================>......] - ETA: 1s - loss: 0.3459 - accuracy: 0.9034Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3217 - accuracy: 0.9096\n",
      "36667/36667 [==============================] - 6s 161us/sample - loss: 0.3222 - accuracy: 0.9099\n",
      "36667/36667 [==============================] - 6s 169us/sample - loss: 0.3201 - accuracy: 0.9106\n",
      " 9344/36667 [======>.......................] - ETA: 6s - loss: 0.5705 - accuracy: 0.8477Train on 36667 samples\n",
      "10752/36667 [=======>......................] - ETA: 5s - loss: 0.5344 - accuracy: 0.8560Train on 36667 samples\n",
      "21472/36667 [================>.............] - ETA: 2s - loss: 0.4155 - accuracy: 0.88555Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 151us/sample - loss: 0.3338 - accuracy: 0.9069\n",
      "31744/36667 [========================>.....] - ETA: 0s - loss: 0.3500 - accuracy: 0.9017Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.3304 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.3313 - accuracy: 0.9051\n",
      "36667/36667 [==============================] - 7s 188us/sample - loss: 0.3361 - accuracy: 0.9040\n",
      "10912/36666 [=======>......................] - ETA: 6s - loss: 0.5354 - accuracy: 0.8551Train on 36666 samples\n",
      "21088/36666 [================>.............] - ETA: 2s - loss: 0.4136 - accuracy: 0.88576Train on 36666 samples\n",
      "26272/36666 [====================>.........] - ETA: 1s - loss: 0.3868 - accuracy: 0.8929Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 147us/sample - loss: 0.3411 - accuracy: 0.9041\n",
      "13280/36666 [=========>....................] - ETA: 5s - loss: 0.4619 - accuracy: 0.8736Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 154us/sample - loss: 0.3411 - accuracy: 0.9041\n",
      "36666/36666 [==============================] - 6s 172us/sample - loss: 0.3243 - accuracy: 0.9082\n",
      "12000/36667 [========>.....................] - ETA: 5s - loss: 0.4966 - accuracy: 0.8645Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 171us/sample - loss: 0.3237 - accuracy: 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25216/36667 [===================>..........] - ETA: 1s - loss: 0.3769 - accuracy: 0.89519Train on 36667 samples\n",
      "28064/36667 [=====================>........] - ETA: 1s - loss: 0.3626 - accuracy: 0.8987Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 148us/sample - loss: 0.3290 - accuracy: 0.9082\n",
      "15040/36667 [===========>..................] - ETA: 4s - loss: 0.4533 - accuracy: 0.8754Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3290 - accuracy: 0.9082\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.3229 - accuracy: 0.9089\n",
      "16480/36667 [============>.................] - ETA: 4s - loss: 0.4664 - accuracy: 0.8683Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3249 - accuracy: 0.9079\n",
      "25952/36667 [====================>.........] - ETA: 2s - loss: 0.3940 - accuracy: 0.88882Train on 36667 samples\n",
      " 5024/36667 [===>..........................] - ETA: 9s - loss: 0.7425 - accuracy: 0.7958 Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.3419 - accuracy: 0.9036\n",
      "11264/36667 [========>.....................] - ETA: 7s - loss: 0.5062 - accuracy: 0.8580Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 166us/sample - loss: 0.3419 - accuracy: 0.9036\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3249 - accuracy: 0.9072\n",
      "36667/36667 [==============================] - 7s 187us/sample - loss: 0.3315 - accuracy: 0.9056\n",
      "17408/36666 [=============>................] - ETA: 4s - loss: 0.4193 - accuracy: 0.8847Train on 36666 samples\n",
      "27072/36666 [=====================>........] - ETA: 1s - loss: 0.3622 - accuracy: 0.8990Train on 36666 samples\n",
      " 4640/36666 [==>...........................] - ETA: 10s - loss: 0.6961 - accuracy: 0.8170Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 162us/sample - loss: 0.3237 - accuracy: 0.9078\n",
      " 7072/36666 [====>.........................] - ETA: 9s - loss: 0.6196 - accuracy: 0.8351Train on 36667 samples\n",
      "36666/36666 [==============================] - 7s 193us/sample - loss: 0.3221 - accuracy: 0.9084\n",
      "36666/36666 [==============================] - 8s 210us/sample - loss: 0.3264 - accuracy: 0.9063\n",
      "24032/36667 [==================>...........] - ETA: 2s - loss: 0.3797 - accuracy: 0.8932Train on 36667 samples\n",
      "36666/36666 [==============================] - 8s 212us/sample - loss: 0.3412 - accuracy: 0.9032\n",
      "35712/36667 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.9072Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 177us/sample - loss: 0.3249 - accuracy: 0.9079\n",
      " 4864/36667 [==>...........................] - ETA: 10s - loss: 0.6727 - accuracy: 0.8228Train on 36667 samples\n",
      "12032/36667 [========>.....................] - ETA: 4s - loss: 0.4783 - accuracy: 0.8706Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 175us/sample - loss: 0.3201 - accuracy: 0.9106\n",
      "30112/36667 [=======================>......] - ETA: 1s - loss: 0.3539 - accuracy: 0.9013Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 179us/sample - loss: 0.3358 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.3315 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 8s 215us/sample - loss: 0.3291 - accuracy: 0.9082\n",
      " 3808/36667 [==>...........................] - ETA: 12s - loss: 0.7923 - accuracy: 0.7857Train on 36667 samples\n",
      "10368/36667 [=======>......................] - ETA: 5s - loss: 0.5341 - accuracy: 0.8509Train on 36667 samples\n",
      " 2912/36667 [=>............................] - ETA: 16s - loss: 0.9365 - accuracy: 0.7527Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.3361 - accuracy: 0.9040\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.3421 - accuracy: 0.9035\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.3415 - accuracy: 0.9038\n",
      "36666/36666 [==============================] - 6s 175us/sample - loss: 0.3358 - accuracy: 0.9043\n",
      "Train on 36666 samples\n",
      " 4128/36666 [==>...........................] - ETA: 7s - loss: 0.7560 - accuracy: 0.8011Train on 36666 samples\n",
      " 4960/36666 [===>..........................] - ETA: 6s - loss: 0.6955 - accuracy: 0.8153Train on 36667 samples\n",
      "12736/36666 [=========>....................] - ETA: 3s - loss: 0.4783 - accuracy: 0.86785Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3243 - accuracy: 0.9082\n",
      "36667/36667 [==============================] - 7s 184us/sample - loss: 0.3240 - accuracy: 0.9105\n",
      "32000/36666 [=========================>....] - ETA: 0s - loss: 0.3390 - accuracy: 0.9035Train on 36667 samples\n",
      "36666/36666 [==============================] - 7s 178us/sample - loss: 0.3229 - accuracy: 0.9077\n",
      "36666/36666 [==============================] - 8s 218us/sample - loss: 0.3245 - accuracy: 0.9084\n",
      " 3616/36667 [=>............................] - ETA: 12s - loss: 0.8071 - accuracy: 0.7895Train on 36667 samples\n",
      " 5504/36667 [===>..........................] - ETA: 10s - loss: 0.6731 - accuracy: 0.8198Train on 36667 samples\n",
      "  448/36667 [..............................] - ETA: 1:07 - loss: 1.7575 - accuracy: 0.4308Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 158us/sample - loss: 0.3229 - accuracy: 0.9089\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.3393 - accuracy: 0.9039\n",
      "25472/36667 [===================>..........] - ETA: 2s - loss: 0.3674 - accuracy: 0.8979Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 179us/sample - loss: 0.3319 - accuracy: 0.9073\n",
      "36667/36667 [==============================] - 7s 179us/sample - loss: 0.3219 - accuracy: 0.9101\n",
      " 4448/36667 [==>...........................] - ETA: 11s - loss: 0.7249 - accuracy: 0.8026Train on 36666 samples\n",
      " 9792/36667 [=======>......................] - ETA: 5s - loss: 0.5382 - accuracy: 0.8498Train on 36667 samples\n",
      "12608/36667 [=========>....................] - ETA: 4s - loss: 0.4853 - accuracy: 0.8632Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 160us/sample - loss: 0.3249 - accuracy: 0.9072\n",
      "27232/36667 [=====================>........] - ETA: 1s - loss: 0.3653 - accuracy: 0.8974Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 188us/sample - loss: 0.3245 - accuracy: 0.9084\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.3229 - accuracy: 0.9087\n",
      "36667/36667 [==============================] - 6s 174us/sample - loss: 0.3339 - accuracy: 0.9052\n",
      "12832/36666 [=========>....................] - ETA: 4s - loss: 0.4780 - accuracy: 0.8692Train on 36667 samples\n",
      "13440/36666 [=========>....................] - ETA: 4s - loss: 0.4685 - accuracy: 0.8720Train on 36666 samples\n",
      "14144/36666 [==========>...................] - ETA: 4s - loss: 0.4585 - accuracy: 0.8741Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 161us/sample - loss: 0.3275 - accuracy: 0.9070\n",
      "25632/36666 [===================>..........] - ETA: 2s - loss: 0.3810 - accuracy: 0.8939Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 180us/sample - loss: 0.3219 - accuracy: 0.9101\n",
      "36666/36666 [==============================] - 7s 177us/sample - loss: 0.3344 - accuracy: 0.9051\n",
      "36666/36666 [==============================] - 7s 182us/sample - loss: 0.3392 - accuracy: 0.9020\n",
      " 1568/36667 [>.............................] - ETA: 55s - loss: 1.1895 - accuracy: 0.6875 Train on 36667 samples\n",
      " 2272/36667 [>.............................] - ETA: 38s - loss: 1.0136 - accuracy: 0.7320Train on 36667 samples\n",
      " 4768/36667 [==>...........................] - ETA: 18s - loss: 0.7284 - accuracy: 0.8003Train on 36667 samples\n",
      "36667/36667 [==============================] - 8s 223us/sample - loss: 0.3348 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 7s 191us/sample - loss: 0.3339 - accuracy: 0.9052\n",
      "36032/36667 [============================>.] - ETA: 0s - loss: 0.3444 - accuracy: 0.9037Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.3429 - accuracy: 0.9043\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.3360 - accuracy: 0.9058\n",
      " 4192/36667 [==>...........................] - ETA: 7s - loss: 0.7720 - accuracy: 0.7977Train on 36667 samples\n",
      " 6656/36667 [====>.........................] - ETA: 5s - loss: 0.6505 - accuracy: 0.8235Train on 36667 samples\n",
      "30880/36667 [========================>.....] - ETA: 0s - loss: 0.3630 - accuracy: 0.8982Train on 36666 samples\n",
      "36667/36667 [==============================] - 5s 131us/sample - loss: 0.3384 - accuracy: 0.9050\n",
      "31424/36667 [========================>.....] - ETA: 0s - loss: 0.3587 - accuracy: 0.8987Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3422 - accuracy: 0.9026\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3361 - accuracy: 0.9044\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.3226 - accuracy: 0.9101\n",
      "19488/36666 [==============>...............] - ETA: 2s - loss: 0.4037 - accuracy: 0.8868Train on 36666 samples\n",
      "31904/36666 [=========================>....] - ETA: 0s - loss: 0.3403 - accuracy: 0.9032Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 135us/sample - loss: 0.3241 - accuracy: 0.9075\n",
      "17888/36666 [=============>................] - ETA: 2s - loss: 0.4260 - accuracy: 0.8813Train on 36667 samples\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 0.3293 - accuracy: 0.9060\n",
      "36064/36667 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.9036Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 168us/sample - loss: 0.3415 - accuracy: 0.9041\n",
      "36667/36667 [==============================] - 5s 143us/sample - loss: 0.3361 - accuracy: 0.9059\n",
      " 4192/36667 [==>...........................] - ETA: 8s - loss: 0.7473 - accuracy: 0.8037Train on 36667 samples\n",
      "   32/36667 [..............................] - ETA: 13:19 - loss: 2.2088 - accuracy: 0.2500Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 140us/sample - loss: 0.3397 - accuracy: 0.9047\n",
      "28192/36667 [======================>.......] - ETA: 1s - loss: 0.3660 - accuracy: 0.8969Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.3418 - accuracy: 0.9033\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3258 - accuracy: 0.9081\n",
      " 6656/36667 [====>.........................] - ETA: 5s - loss: 0.6618 - accuracy: 0.8218Train on 36666 samples\n",
      "36667/36667 [==============================] - 4s 117us/sample - loss: 0.3407 - accuracy: 0.9036\n",
      "27552/36666 [=====================>........] - ETA: 1s - loss: 0.3576 - accuracy: 0.8999Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.3221 - accuracy: 0.9087\n",
      " 6688/36666 [====>.........................] - ETA: 6s - loss: 0.6267 - accuracy: 0.8313Train on 36667 samples\n",
      "36666/36666 [==============================] - 4s 119us/sample - loss: 0.3367 - accuracy: 0.9037\n",
      "34208/36667 [==========================>...] - ETA: 0s - loss: 0.3302 - accuracy: 0.9089Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 109us/sample - loss: 0.3220 - accuracy: 0.9111\n",
      " 6400/36667 [====>.........................] - ETA: 4s - loss: 0.6275 - accuracy: 0.8286Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 97us/sample - loss: 0.3352 - accuracy: 0.9053\n",
      "33504/36667 [==========================>...] - ETA: 0s - loss: 0.3408 - accuracy: 0.9023Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 102us/sample - loss: 0.3286 - accuracy: 0.9055\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 0.3319 - accuracy: 0.9061\n",
      "Train on 36666 samples\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.3208 - accuracy: 0.9089\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 0.3231 - accuracy: 0.9096\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3324 - accuracy: 0.9054\n",
      "3  \t33    \t0.938317\t0.935036\t0.940218\t0.00129488\n",
      "Train on 36666 samples\n",
      " 4544/36666 [==>...........................] - ETA: 4s - loss: 0.7176 - accuracy: 0.8077Train on 36666 samples\n",
      " 4864/36666 [==>...........................] - ETA: 8s - loss: 0.6922 - accuracy: 0.8187Train on 36666 samples\n",
      "15840/36666 [===========>..................] - ETA: 3s - loss: 0.4327 - accuracy: 0.8809Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 116us/sample - loss: 0.3281 - accuracy: 0.9062\n",
      "36666/36666 [==============================] - 6s 151us/sample - loss: 0.3221 - accuracy: 0.9087\n",
      "12192/36666 [========>.....................] - ETA: 6s - loss: 0.4846 - accuracy: 0.8668Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 157us/sample - loss: 0.3281 - accuracy: 0.9062\n",
      " 3488/36667 [=>............................] - ETA: 14s - loss: 0.7977 - accuracy: 0.7884Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3249 - accuracy: 0.9077\n",
      "18144/36667 [=============>................] - ETA: 3s - loss: 0.4197 - accuracy: 0.8823Train on 36667 samples\n",
      "13728/36667 [==========>...................] - ETA: 4s - loss: 0.4655 - accuracy: 0.8754Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.3247 - accuracy: 0.9088\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3220 - accuracy: 0.9111\n",
      "14336/36667 [==========>...................] - ETA: 5s - loss: 0.4624 - accuracy: 0.8732Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3247 - accuracy: 0.9088\n",
      " 4160/36667 [==>...........................] - ETA: 13s - loss: 0.7362 - accuracy: 0.8041Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.3275 - accuracy: 0.9087\n",
      " 3776/36667 [==>...........................] - ETA: 13s - loss: 0.7991 - accuracy: 0.7834Train on 36667 samples\n",
      "24512/36667 [===================>..........] - ETA: 2s - loss: 0.3813 - accuracy: 0.8930Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3229 - accuracy: 0.9089\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3286 - accuracy: 0.9055\n",
      "36667/36667 [==============================] - 6s 162us/sample - loss: 0.3229 - accuracy: 0.9089\n",
      "33504/36667 [==========================>...] - ETA: 0s - loss: 0.3392 - accuracy: 0.9039Train on 36666 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3264 - accuracy: 0.9073\n",
      " 2624/36666 [=>............................] - ETA: 12s - loss: 0.9120 - accuracy: 0.7679Train on 36666 samples\n",
      " 9632/36666 [======>.......................] - ETA: 4s - loss: 0.5241 - accuracy: 0.8581Train on 36666 samples\n",
      " 3872/36666 [==>...........................] - ETA: 11s - loss: 0.7935 - accuracy: 0.7869Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 141us/sample - loss: 0.3180 - accuracy: 0.9096\n",
      "36666/36666 [==============================] - 6s 173us/sample - loss: 0.3367 - accuracy: 0.9037\n",
      "29664/36666 [=======================>......] - ETA: 1s - loss: 0.3482 - accuracy: 0.9017Train on 36667 samples\n",
      "36666/36666 [==============================] - 7s 187us/sample - loss: 0.3211 - accuracy: 0.9083\n",
      "36666/36666 [==============================] - 7s 177us/sample - loss: 0.3180 - accuracy: 0.9096\n",
      "   32/36667 [..............................] - ETA: 28:13 - loss: 2.3290 - accuracy: 0.1562Train on 36667 samples\n",
      " 9664/36667 [======>.......................] - ETA: 7s - loss: 0.5357 - accuracy: 0.8530Train on 36667 samples\n",
      " 1760/36667 [>.............................] - ETA: 36s - loss: 1.0653 - accuracy: 0.7284Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3201 - accuracy: 0.9092\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3352 - accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32416/36667 [=========================>....] - ETA: 0s - loss: 0.3409 - accuracy: 0.9045Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3258 - accuracy: 0.9082\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.3201 - accuracy: 0.9092\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "  928/36667 [..............................] - ETA: 20s - loss: 1.4240 - accuracy: 0.6272 Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.3319 - accuracy: 0.9061\n",
      "36667/36667 [==============================] - 9s 240us/sample - loss: 0.3330 - accuracy: 0.9064\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3330 - accuracy: 0.9064\n",
      "36667/36667 [==============================] - 8s 208us/sample - loss: 0.3218 - accuracy: 0.9079\n",
      "Train on 36666 samples\n",
      " 8192/36666 [=====>........................] - ETA: 3s - loss: 0.5569 - accuracy: 0.8514Train on 36666 samples\n",
      "20512/36666 [===============>..............] - ETA: 1s - loss: 0.3899 - accuracy: 0.8915Train on 36666 samples\n",
      "11072/36666 [========>.....................] - ETA: 4s - loss: 0.4996 - accuracy: 0.8632Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 125us/sample - loss: 0.3180 - accuracy: 0.9096\n",
      "28160/36666 [======================>.......] - ETA: 1s - loss: 0.3596 - accuracy: 0.8978Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.3285 - accuracy: 0.9059\n",
      "36666/36666 [==============================] - 7s 186us/sample - loss: 0.3285 - accuracy: 0.9059\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.3430 - accuracy: 0.9018\n",
      "13856/36667 [==========>...................] - ETA: 5s - loss: 0.4634 - accuracy: 0.8719Train on 36667 samples\n",
      "28000/36667 [=====================>........] - ETA: 1s - loss: 0.3549 - accuracy: 0.8996Train on 36667 samples\n",
      " 6624/36667 [====>.........................] - ETA: 6s - loss: 0.6543 - accuracy: 0.8258Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3201 - accuracy: 0.9092\n",
      "19872/36667 [===============>..............] - ETA: 3s - loss: 0.4061 - accuracy: 0.8860Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 189us/sample - loss: 0.3220 - accuracy: 0.9090\n",
      "36667/36667 [==============================] - 6s 154us/sample - loss: 0.3399 - accuracy: 0.9052\n",
      " 5568/36667 [===>..........................] - ETA: 21s - loss: 0.7021 - accuracy: 0.8134Train on 36667 samples\n",
      "34816/36667 [===========================>..] - ETA: 0s - loss: 0.3271 - accuracy: 0.9074Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.3220 - accuracy: 0.9090\n",
      " 2400/36667 [>.............................] - ETA: 22s - loss: 1.0207 - accuracy: 0.7354Train on 36667 samples\n",
      "36667/36667 [==============================] - 9s 256us/sample - loss: 0.3330 - accuracy: 0.9064\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.3275 - accuracy: 0.9078\n",
      "36667/36667 [==============================] - 8s 209us/sample - loss: 0.3451 - accuracy: 0.9030\n",
      "36667/36667 [==============================] - 7s 190us/sample - loss: 0.3275 - accuracy: 0.9078\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      " 5568/36666 [===>..........................] - ETA: 8s - loss: 0.6482 - accuracy: 0.8301Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 183us/sample - loss: 0.3266 - accuracy: 0.9074\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.3285 - accuracy: 0.9059\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.3345 - accuracy: 0.9042\n",
      "30976/36666 [========================>.....] - ETA: 1s - loss: 0.3422 - accuracy: 0.9031Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "32192/36666 [=========================>....] - ETA: 0s - loss: 0.3369 - accuracy: 0.9043Train on 36667 samples\n",
      "36666/36666 [==============================] - 7s 182us/sample - loss: 0.3211 - accuracy: 0.9083\n",
      "  352/36667 [..............................] - ETA: 1:08 - loss: 1.9026 - accuracy: 0.4091Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 203us/sample - loss: 0.3298 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.3220 - accuracy: 0.9090\n",
      "36667/36667 [==============================] - 7s 204us/sample - loss: 0.3347 - accuracy: 0.9061\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.3258 - accuracy: 0.9082\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3264 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 6s 170us/sample - loss: 0.3275 - accuracy: 0.9078\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3218 - accuracy: 0.9079\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.3331 - accuracy: 0.9063\n",
      "Train on 36666 samples\n",
      " 2688/36666 [=>............................] - ETA: 6s - loss: 0.9359 - accuracy: 0.7522Train on 36666 samples\n",
      "15424/36666 [===========>..................] - ETA: 2s - loss: 0.4553 - accuracy: 0.8725Train on 36666 samples\n",
      "12672/36666 [=========>....................] - ETA: 4s - loss: 0.4772 - accuracy: 0.86879Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.3398 - accuracy: 0.9022\n",
      "34560/36666 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.9064Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 169us/sample - loss: 0.3211 - accuracy: 0.9083\n",
      "35712/36666 [============================>.] - ETA: 0s - loss: 0.3435 - accuracy: 0.9011Train on 36667 samples\n",
      "36666/36666 [==============================] - 7s 185us/sample - loss: 0.3398 - accuracy: 0.9022\n",
      "36666/36666 [==============================] - 7s 179us/sample - loss: 0.3286 - accuracy: 0.9073\n",
      " 4864/36667 [==>...........................] - ETA: 12s - loss: 0.7066 - accuracy: 0.8111Train on 36667 samples\n",
      "27552/36667 [=====================>........] - ETA: 1s - loss: 0.3567 - accuracy: 0.9015Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 165us/sample - loss: 0.3207 - accuracy: 0.9106\n",
      "29184/36667 [======================>.......] - ETA: 1s - loss: 0.3542 - accuracy: 0.9009Train on 36667 samples\n",
      "36667/36667 [==============================] - 8s 211us/sample - loss: 0.3258 - accuracy: 0.9082\n",
      "36667/36667 [==============================] - 9s 244us/sample - loss: 0.3207 - accuracy: 0.9106\n",
      "14688/36667 [===========>..................] - ETA: 7s - loss: 0.4785 - accuracy: 0.8694Train on 36667 samples\n",
      "36667/36667 [==============================] - 9s 249us/sample - loss: 0.3275 - accuracy: 0.9083\n",
      "26944/36667 [=====================>........] - ETA: 2s - loss: 0.3836 - accuracy: 0.8930Train on 36667 samples\n",
      " 7008/36667 [====>.........................] - ETA: 12s - loss: 0.6167 - accuracy: 0.8296Train on 36667 samples\n",
      "36667/36667 [==============================] - 9s 251us/sample - loss: 0.3366 - accuracy: 0.9053\n",
      "36667/36667 [==============================] - 8s 213us/sample - loss: 0.3218 - accuracy: 0.9079\n",
      "36667/36667 [==============================] - 7s 186us/sample - loss: 0.3366 - accuracy: 0.9053\n",
      "32032/36667 [=========================>....] - ETA: 0s - loss: 0.3512 - accuracy: 0.9001Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 192us/sample - loss: 0.3322 - accuracy: 0.9055\n",
      "14944/36666 [===========>..................] - ETA: 3s - loss: 0.4580 - accuracy: 0.8727Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 114us/sample - loss: 0.3381 - accuracy: 0.9031\n",
      "25888/36666 [====================>.........] - ETA: 1s - loss: 0.3742 - accuracy: 0.8965Train on 36667 samples\n",
      "36666/36666 [==============================] - 4s 115us/sample - loss: 0.3282 - accuracy: 0.9070\n",
      "15520/36667 [===========>..................] - ETA: 2s - loss: 0.4478 - accuracy: 0.8772Train on 36667 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 4s 121us/sample - loss: 0.3225 - accuracy: 0.9101\n",
      "23936/36667 [==================>...........] - ETA: 1s - loss: 0.3748 - accuracy: 0.8953Train on 36667 samples\n",
      "36667/36667 [==============================] - 5s 124us/sample - loss: 0.3187 - accuracy: 0.9104\n",
      "13536/36667 [==========>...................] - ETA: 3s - loss: 0.4860 - accuracy: 0.8622Train on 36667 samples\n",
      "36667/36667 [==============================] - 4s 118us/sample - loss: 0.3356 - accuracy: 0.9050\n",
      "36667/36667 [==============================] - 4s 110us/sample - loss: 0.3389 - accuracy: 0.9044\n",
      "4  \t32    \t0.938879\t0.935164\t0.940291\t0.00102613\n",
      "Train on 36666 samples\n",
      " 7872/36666 [=====>........................] - ETA: 3s - loss: 0.5854 - accuracy: 0.8448Train on 36666 samples\n",
      "20704/36666 [===============>..............] - ETA: 1s - loss: 0.4020 - accuracy: 0.8892Train on 36666 samples\n",
      "31712/36666 [========================>.....] - ETA: 0s - loss: 0.3464 - accuracy: 0.9033Train on 36666 samples\n",
      "36666/36666 [==============================] - 4s 117us/sample - loss: 0.3294 - accuracy: 0.9074\n",
      "12192/36666 [========>.....................] - ETA: 5s - loss: 0.4718 - accuracy: 0.8688Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 158us/sample - loss: 0.3294 - accuracy: 0.9074\n",
      "36666/36666 [==============================] - 6s 166us/sample - loss: 0.3294 - accuracy: 0.9074\n",
      "32672/36666 [=========================>....] - ETA: 0s - loss: 0.3359 - accuracy: 0.9039Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 154us/sample - loss: 0.3220 - accuracy: 0.9074\n",
      "18880/36667 [==============>...............] - ETA: 3s - loss: 0.4209 - accuracy: 0.8809Train on 36667 samples\n",
      " 7360/36667 [=====>........................] - ETA: 8s - loss: 0.6011 - accuracy: 0.8337Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3302 - accuracy: 0.9061\n",
      "17568/36667 [=============>................] - ETA: 3s - loss: 0.4168 - accuracy: 0.8817Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 171us/sample - loss: 0.3302 - accuracy: 0.9061\n",
      "36667/36667 [==============================] - 6s 172us/sample - loss: 0.3302 - accuracy: 0.9061\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3205 - accuracy: 0.9088\n",
      " 9280/36667 [======>.......................] - ETA: 7s - loss: 0.5564 - accuracy: 0.8480Train on 36667 samples\n",
      "20128/36667 [===============>..............] - ETA: 2s - loss: 0.4209 - accuracy: 0.8826Train on 36667 samples\n",
      "23776/36667 [==================>...........] - ETA: 2s - loss: 0.3980 - accuracy: 0.8884Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 167us/sample - loss: 0.3321 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.3321 - accuracy: 0.9068\n",
      "29248/36667 [======================>.......] - ETA: 1s - loss: 0.3692 - accuracy: 0.8967Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 194us/sample - loss: 0.3321 - accuracy: 0.9068\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.3355 - accuracy: 0.9056\n",
      "Train on 36666 samples\n",
      "  736/36666 [..............................] - ETA: 49s - loss: 1.5531 - accuracy: 0.5489 Train on 36666 samples\n",
      "  832/36666 [..............................] - ETA: 42s - loss: 2.0738 - accuracy: 0.2740  Train on 36666 samples\n",
      "36666/36666 [==============================] - 5s 130us/sample - loss: 0.3337 - accuracy: 0.9047\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.6538 - accuracy: 0.8125\n",
      "34720/36666 [===========================>..] - ETA: 0s - loss: 0.3356 - accuracy: 0.9056Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36666/36666 [==============================] - 8s 208us/sample - loss: 0.3286 - accuracy: 0.9073\n",
      "20352/36666 [===============>..............] - ETA: 5s - loss: 0.4010 - accuracy: 0.8889Train on 36667 samples\n",
      "36666/36666 [==============================] - 10s 265us/sample - loss: 0.3286 - accuracy: 0.9073\n",
      "30208/36667 [=======================>......] - ETA: 1s - loss: 0.3585 - accuracy: 0.8992Train on 36667 samples\n",
      "36667/36667 [==============================] - 8s 216us/sample - loss: 0.5891 - accuracy: 0.8381\n",
      "36667/36667 [==============================] - 9s 236us/sample - loss: 0.3344 - accuracy: 0.9058\n",
      "30336/36667 [=======================>......] - ETA: 1s - loss: 0.3505 - accuracy: 0.9022Train on 36667 samples\n",
      "36667/36667 [==============================] - 9s 235us/sample - loss: 0.3275 - accuracy: 0.9083\n",
      "Train on 36667 samples\n",
      "24864/36667 [===================>..........] - ETA: 2s - loss: 0.3790 - accuracy: 0.8950Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 159us/sample - loss: 0.3275 - accuracy: 0.9083\n",
      "20800/36667 [================>.............] - ETA: 2s - loss: 0.4314 - accuracy: 0.8803Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 164us/sample - loss: 0.7338 - accuracy: 0.7865\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3420 - accuracy: 0.9041\n",
      "20992/36667 [================>.............] - ETA: 3s - loss: 0.4151 - accuracy: 0.8828Train on 36666 samples\n",
      "36667/36667 [==============================] - 7s 193us/sample - loss: 0.3322 - accuracy: 0.9055\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3322 - accuracy: 0.9055\n",
      "15648/36666 [===========>..................] - ETA: 4s - loss: 0.4391 - accuracy: 0.8777Train on 36666 samples\n",
      "23200/36666 [=================>............] - ETA: 2s - loss: 0.3841 - accuracy: 0.8916Train on 36666 samples\n",
      " 2144/36666 [>.............................] - ETA: 22s - loss: 1.0431 - accuracy: 0.7309Train on 36666 samples\n",
      "36666/36666 [==============================] - 6s 159us/sample - loss: 0.3271 - accuracy: 0.9065\n",
      "14816/36666 [===========>..................] - ETA: 4s - loss: 0.8946 - accuracy: 0.7572Train on 36667 samples\n",
      "36666/36666 [==============================] - 6s 160us/sample - loss: 0.3282 - accuracy: 0.9070\n",
      "36666/36666 [==============================] - 6s 155us/sample - loss: 0.3317 - accuracy: 0.9060\n",
      "36666/36666 [==============================] - 5s 148us/sample - loss: 0.6062 - accuracy: 0.8312\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "   32/36667 [..............................] - ETA: 9:47 - loss: 2.3970 - accuracy: 0.15628Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3187 - accuracy: 0.9104\n",
      "36667/36667 [==============================] - 9s 256us/sample - loss: 0.3282 - accuracy: 0.9088\n",
      "36667/36667 [==============================] - 7s 181us/sample - loss: 0.3247 - accuracy: 0.9090\n",
      "36667/36667 [==============================] - 7s 185us/sample - loss: 0.6136 - accuracy: 0.8248\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 153us/sample - loss: 0.5981 - accuracy: 0.8278\n",
      "36667/36667 [==============================] - 6s 177us/sample - loss: 0.3271 - accuracy: 0.9074\n",
      "36667/36667 [==============================] - 7s 178us/sample - loss: 0.3389 - accuracy: 0.9044\n",
      "36667/36667 [==============================] - 6s 176us/sample - loss: 0.3323 - accuracy: 0.9059\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "Train on 36666 samples\n",
      "36666/36666 [==============================] - 7s 184us/sample - loss: 0.3220 - accuracy: 0.9074\n",
      "36666/36666 [==============================] - 7s 194us/sample - loss: 0.3334 - accuracy: 0.9050\n",
      "36666/36666 [==============================] - 7s 197us/sample - loss: 0.3220 - accuracy: 0.9074\n",
      "36666/36666 [==============================] - 7s 199us/sample - loss: 0.3252 - accuracy: 0.9088\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 7s 183us/sample - loss: 0.3205 - accuracy: 0.9088\n",
      "36667/36667 [==============================] - 7s 197us/sample - loss: 0.3180 - accuracy: 0.9105\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3246 - accuracy: 0.9083\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3205 - accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 6s 163us/sample - loss: 0.3355 - accuracy: 0.9056\n",
      "36667/36667 [==============================] - 6s 173us/sample - loss: 0.3337 - accuracy: 0.9038\n",
      "36667/36667 [==============================] - 7s 199us/sample - loss: 0.3283 - accuracy: 0.9075\n",
      "36667/36667 [==============================] - 7s 200us/sample - loss: 0.3355 - accuracy: 0.9056\n",
      "Train on 36666 samples\n",
      "36666/36666 [==============================] - 3s 86us/sample - loss: 0.3236 - accuracy: 0.9072\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 0.3230 - accuracy: 0.9082\n",
      "Train on 36667 samples\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3255 - accuracy: 0.9081\n",
      "5  \t33    \t0.936616\t0.890618\t0.940291\t0.00887551\n",
      "Best individual is: {'n_neurons': 100}\n",
      "with fitness: 0.9402181818181818\n",
      "Train on 55000 samples\n",
      "55000/55000 [==============================] - 3s 62us/sample - loss: 0.2804 - accuracy: 0.9213s - loss: 0.2835 - accuracy: 0.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "grid_cv.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17.82 minutes ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- {round((time.time() - start_time)/60,2)} minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid_cv = GridSearchCV(estimator=keras_clf, param_grid=param_grid,cv=3,verbose = 2)\n",
    "# grid_cv.fit(train_images, train_labels, epochs=30,\n",
    "#                   validation_data=(val_images, val_labels),\n",
    "#                   callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of neurons that produced the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's get the results to compare the performance of the 100 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['param_index', 'index', 'params', 'mean_test_score', 'std_test_score', 'min_test_score', 'max_test_score', 'nan_test_score?'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neurons\n",
       "0         62\n",
       "1         87\n",
       "2         90\n",
       "3         63\n",
       "4         90"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(results['params'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    78\n",
       "85     17\n",
       "99     17\n",
       "90     10\n",
       "78      4\n",
       "87      4\n",
       "76      3\n",
       "59      3\n",
       "77      2\n",
       "73      2\n",
       "12      1\n",
       "19      1\n",
       "44      1\n",
       "20      1\n",
       "10      1\n",
       "32      1\n",
       "41      1\n",
       "64      1\n",
       "57      1\n",
       "62      1\n",
       "63      1\n",
       "74      1\n",
       "81      1\n",
       "83      1\n",
       "89      1\n",
       "9       1\n",
       "Name: n_neurons, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.n_neurons.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>max_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936909</td>\n",
       "      <td>0.936909</td>\n",
       "      <td>0.936909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932909</td>\n",
       "      <td>0.932909</td>\n",
       "      <td>0.932909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937418</td>\n",
       "      <td>0.937418</td>\n",
       "      <td>0.937418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938964</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>0.938964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_test_score  mean_test_score  max_test_score\n",
       "0        0.936909         0.936909        0.936909\n",
       "1        0.933000         0.933000        0.933000\n",
       "2        0.932909         0.932909        0.932909\n",
       "3        0.937418         0.937418        0.937418\n",
       "4        0.938964         0.938964        0.938964"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['min_test_score','mean_test_score','max_test_score']\n",
    "df2=pd.DataFrame(zip(results['min_test_score'],results['mean_test_score'],results['max_test_score']),columns=col)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>min_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>max_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>0.936909</td>\n",
       "      <td>0.936909</td>\n",
       "      <td>0.936909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>0.932909</td>\n",
       "      <td>0.932909</td>\n",
       "      <td>0.932909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>0.937418</td>\n",
       "      <td>0.937418</td>\n",
       "      <td>0.937418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>0.938964</td>\n",
       "      <td>0.938964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neurons  min_test_score  mean_test_score  max_test_score\n",
       "0         62        0.936909         0.936909        0.936909\n",
       "1         87        0.933000         0.933000        0.933000\n",
       "2         90        0.932909         0.932909        0.932909\n",
       "3         63        0.937418         0.937418        0.937418\n",
       "4         90        0.938964         0.938964        0.938964"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>min_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>max_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>10</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>100</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>100</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "      <td>0.940291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_neurons  min_test_score  mean_test_score  max_test_score\n",
       "154         10        0.940291         0.940291        0.940291\n",
       "131        100        0.940291         0.940291        0.940291\n",
       "129        100        0.940291         0.940291        0.940291\n",
       "149        100        0.940291         0.940291        0.940291\n",
       "139        100        0.940291         0.940291        0.940291"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='mean_test_score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_cv.best_estimator_.model\n",
    "keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/sample - loss: 0.1579 - accuracy: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1579398089684546, 0.9538]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further explortion...\n",
    "\n",
    "Try the following grid parameters:\n",
    "\n",
    "```python\n",
    "param_grid = {'n_neurons': range(100,900,100)}\n",
    "param_grid\n",
    "```\n",
    "\n",
    "Were you able to get accuracies over 99 percent? How many epochs are needed to train the model before it starts overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best model\n",
    "\n",
    "**N.B**: Note that I ran the code three times with a different numbr of nodes each and time with higher test accuracy (~99.6%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_cv.best_estimator_.model\n",
    "keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"mnist_model_best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "The model with 500 neurons gets a test accuracy of 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.1579 - accuracy: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1579398089684546, 0.9538]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Let us see what the confusion matrix looks like. Using both `sklearn.metrics` and `tensorflow`. Then we visualize the confusion matrix and see what that tells us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes:\n",
    "pred_classes = best_model.predict_classes(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5349,    1,    3,    4,   12,   13,   13,    2,   44,    3],\n",
       "       [   1, 6052,   18,   14,    8,   10,    2,   10,   51,   13],\n",
       "       [  28,   22, 5057,   75,   40,   12,   28,   72,  125,   11],\n",
       "       [  14,   16,   45, 5262,    5,   79,    5,   29,  146,   37],\n",
       "       [   9,   12,   13,    2, 5088,    9,   25,    5,   35,  109],\n",
       "       [  32,   13,    6,   63,   13, 4754,   16,    6,   58,   26],\n",
       "       [  46,   16,    4,    3,   33,  102, 5172,    4,   37,    0],\n",
       "       [   7,   21,   20,   30,   36,   12,    2, 5488,   21,   78],\n",
       "       [  14,   31,    9,   36,   12,   34,    9,    5, 5206,   33],\n",
       "       [  22,    8,    0,   49,   96,   25,    1,   67,   50, 5136]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_max = confusion_matrix(train_labels,pred_classes)\n",
    "conf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_max.sum(axis=1, keepdims=True)\n",
    "norm_conf_max = conf_max / row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there were 38 threes confused as eights. You can see this in the heat map for the error below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the confusion matrix\n",
    "\n",
    "We use code from chapter 3 of Hands on Machine Learning (A. Geron) (cf. https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb) to display a \"heat map\" of the confusion matrix. Then we normalize the confusion matrix so we can compare error rates. \n",
    "\n",
    "See https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch03.html#classification_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(conf_max, cmap=plt.cm.gray)\n",
    "plt.xlabel(\"Predicted Classes\")\n",
    "plt.ylabel(\"Actual Classes\")\n",
    "# plt.savefig(\"confusion_matrix_plot_mnist\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The confusion matrix looks better than the one in in the previous experiments, doesn' it? Let us normalize the confusion matrix to get the error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_max.sum(axis=1, keepdims=True)\n",
    "norm_conf_max = conf_max / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.fill_diagonal(norm_conf_max, 0)\n",
    "plt.matshow(norm_conf_max, cmap=plt.cm.gray)\n",
    "plt.xlabel(\"Predicted Classes\")\n",
    "plt.ylabel(\"Actual Classes\")\n",
    "# plt.savefig(\"confusion_matrix_errors_plot_mnist_val\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Looks like a lot of digits were still misclassified as 8's. Let's plot examples of 3's and 8's to try to determine what went wrong here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, pos, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    pos.imshow(image, cmap = 'binary', **options)\n",
    "    pos.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl_a, cl_b = 3,8\n",
    "X_aa = train_images[(train_labels == cl_a) & (pred_classes == cl_a)]\n",
    "X_ab = train_images[(train_labels == cl_a) & (pred_classes == cl_b)]\n",
    "X_ba = train_images[(train_labels == cl_b) & (pred_classes == cl_a)]\n",
    "X_bb = train_images[(train_labels == cl_b) & (pred_classes == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "p1 = plt.subplot(221)\n",
    "p2 = plt.subplot(222)\n",
    "p3 = plt.subplot(223)\n",
    "p4 = plt.subplot(224)\n",
    "\n",
    "plot_digits(X_aa[:25], p1, images_per_row=5);\n",
    "plot_digits(X_ab[:25], p2, images_per_row=5);\n",
    "plot_digits(X_ba[:25], p3, images_per_row=5);\n",
    "plot_digits(X_bb[:25], p4, images_per_row=5);\n",
    "\n",
    "\n",
    "p1.set_title(f\"{cl_a}'s classified as {cl_a}'s\")\n",
    "p2.set_title(f\"{cl_a}'s classified as {cl_b}'s\")\n",
    "p3.set_title(f\"{cl_b}'s classified as {cl_a}'s\")\n",
    "p4.set_title(f\"{cl_b}'s classified as {cl_b}'s\")\n",
    "\n",
    "# plt.savefig(\"error_analysis_digits_plot_EXP1_valid\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display 50 of the 3's classified correctly\n",
    "plot_digits(X_aa[:50],plt,images_per_row = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x3600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all the 3's classified as 8's\n",
    "num = X_ab.shape[0]\n",
    "plt.figure(figsize=(50,50))\n",
    "plot_digits(X_ab[:num],plt, images_per_row = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display 50 of the 8's classified correctly\n",
    "plot_digits(X_bb[:50],plt, images_per_row = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all the 8's classified as 3's\n",
    "num = X_ba.shape[0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_digits(X_ba[:num],plt, images_per_row = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two hidden layer grid search\n",
    "\n",
    "This part is working for `GridSearchCV` (but extremely slow) but not working for `EvolutionaryAlgorithmSearchCV`. It seems to hang..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach works for regular grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model=build_model2(n_neurons=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(test_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf2 = KerasClassifier(build_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': [(1, 1), (1, 1), (2, 1), (2, 2)]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations_with_replacement \n",
    "lst  = [(t[1],t[0]) for t in combinations_with_replacement([1,2], 3)] # first layer has less neurons than second\n",
    "param_grid2 = {'n_neurons': lst}\n",
    "param_grid2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ordinary grid search on a very small search space (which still takes 5 minutes to search...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 46us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "[CV] ................................. n_neurons=(1, 1), total=   5.0s\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 44us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "[CV] ................................. n_neurons=(1, 1), total=   7.8s\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.9805 - accuracy: 0.2184 - val_loss: 1.8827 - val_accuracy: 0.2386\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.8254 - accuracy: 0.2669 - val_loss: 1.7744 - val_accuracy: 0.2914\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7383 - accuracy: 0.2974 - val_loss: 1.7038 - val_accuracy: 0.2972\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6895 - accuracy: 0.3074 - val_loss: 1.6702 - val_accuracy: 0.3066\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6625 - accuracy: 0.3317 - val_loss: 1.6456 - val_accuracy: 0.3674\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6384 - accuracy: 0.3757 - val_loss: 1.6104 - val_accuracy: 0.3902\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6067 - accuracy: 0.3913 - val_loss: 1.5846 - val_accuracy: 0.3892\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5848 - accuracy: 0.3851 - val_loss: 1.5629 - val_accuracy: 0.4056\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5722 - accuracy: 0.3852 - val_loss: 1.5502 - val_accuracy: 0.3944\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5639 - accuracy: 0.3835 - val_loss: 1.5463 - val_accuracy: 0.3986\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5587 - accuracy: 0.3822 - val_loss: 1.5401 - val_accuracy: 0.3974\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5541 - accuracy: 0.3843 - val_loss: 1.5432 - val_accuracy: 0.3834\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5506 - accuracy: 0.3872 - val_loss: 1.5328 - val_accuracy: 0.3804\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5478 - accuracy: 0.3836 - val_loss: 1.5317 - val_accuracy: 0.4020\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5453 - accuracy: 0.3886 - val_loss: 1.5299 - val_accuracy: 0.3992\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5435 - accuracy: 0.3847 - val_loss: 1.5280 - val_accuracy: 0.3834\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5413 - accuracy: 0.3879 - val_loss: 1.5330 - val_accuracy: 0.3938\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5402 - accuracy: 0.3861 - val_loss: 1.5222 - val_accuracy: 0.3990\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5387 - accuracy: 0.3886 - val_loss: 1.5233 - val_accuracy: 0.4008\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5371 - accuracy: 0.3908 - val_loss: 1.5249 - val_accuracy: 0.3998\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 1.5082 - accuracy: 0.3982\n",
      "[CV] ................................. n_neurons=(1, 1), total=  27.1s\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "[CV] ................................. n_neurons=(1, 1), total=   5.1s\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 2.0049 - accuracy: 0.2072 - val_loss: 1.9233 - val_accuracy: 0.2386\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.8756 - accuracy: 0.2576 - val_loss: 1.8636 - val_accuracy: 0.2650\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.8211 - accuracy: 0.2871 - val_loss: 1.8084 - val_accuracy: 0.2828\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7536 - accuracy: 0.3002 - val_loss: 1.7522 - val_accuracy: 0.2976\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.7004 - accuracy: 0.3102 - val_loss: 1.7039 - val_accuracy: 0.3088\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6704 - accuracy: 0.3215 - val_loss: 1.6775 - val_accuracy: 0.3308\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6518 - accuracy: 0.3392 - val_loss: 1.6640 - val_accuracy: 0.3506\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6402 - accuracy: 0.3458 - val_loss: 1.6571 - val_accuracy: 0.3534\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6315 - accuracy: 0.3519 - val_loss: 1.6476 - val_accuracy: 0.3450\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6248 - accuracy: 0.3531 - val_loss: 1.6472 - val_accuracy: 0.3460\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6196 - accuracy: 0.3553 - val_loss: 1.6369 - val_accuracy: 0.3494\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6152 - accuracy: 0.3580 - val_loss: 1.6358 - val_accuracy: 0.3596\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6128 - accuracy: 0.3583 - val_loss: 1.6288 - val_accuracy: 0.3564\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6093 - accuracy: 0.3614 - val_loss: 1.6310 - val_accuracy: 0.3564\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6065 - accuracy: 0.3602 - val_loss: 1.6266 - val_accuracy: 0.3644\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6041 - accuracy: 0.3658 - val_loss: 1.6277 - val_accuracy: 0.3632\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6016 - accuracy: 0.3685 - val_loss: 1.6246 - val_accuracy: 0.3716\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5991 - accuracy: 0.3730 - val_loss: 1.6161 - val_accuracy: 0.3728\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5963 - accuracy: 0.3748 - val_loss: 1.6150 - val_accuracy: 0.37661.6026 - \n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5942 - accuracy: 0.3799 - val_loss: 1.6100 - val_accuracy: 0.3790\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5914 - accuracy: 0.3831 - val_loss: 1.6176 - val_accuracy: 0.3746\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5882 - accuracy: 0.3851 - val_loss: 1.6013 - val_accuracy: 0.3882\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5848 - accuracy: 0.3871 - val_loss: 1.5987 - val_accuracy: 0.3970\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5823 - accuracy: 0.3865 - val_loss: 1.6032 - val_accuracy: 0.3852ss: 1.5855 - ac - ETA: 0s - loss: 1.5848 - accu\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5793 - accuracy: 0.3852 - val_loss: 1.5934 - val_accuracy: 0.3906\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5761 - accuracy: 0.3895 - val_loss: 1.5901 - val_accuracy: 0.3926\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5732 - accuracy: 0.3880 - val_loss: 1.5845 - val_accuracy: 0.3920\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5686 - accuracy: 0.3859 - val_loss: 1.5811 - val_accuracy: 0.3856\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5661 - accuracy: 0.3858 - val_loss: 1.5754 - val_accuracy: 0.3814\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5626 - accuracy: 0.3791 - val_loss: 1.5711 - val_accuracy: 0.3778\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 1.5910 - accuracy: 0.3786\n",
      "[CV] ................................. n_neurons=(1, 1), total=  40.9s\n",
      "[CV] n_neurons=(1, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.9949 - accuracy: 0.2007 - val_loss: 1.8531 - val_accuracy: 0.2360\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.8261 - accuracy: 0.2482 - val_loss: 1.7738 - val_accuracy: 0.2558\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.7699 - accuracy: 0.2727 - val_loss: 1.7354 - val_accuracy: 0.2984\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.7419 - accuracy: 0.2921 - val_loss: 1.7169 - val_accuracy: 0.2998\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7245 - accuracy: 0.3026 - val_loss: 1.7009 - val_accuracy: 0.3250\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7138 - accuracy: 0.3119 - val_loss: 1.6978 - val_accuracy: 0.3218\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.7061 - accuracy: 0.3171 - val_loss: 1.6912 - val_accuracy: 0.3206\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.7013 - accuracy: 0.3218 - val_loss: 1.6858 - val_accuracy: 0.3380\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6967 - accuracy: 0.3247 - val_loss: 1.6805 - val_accuracy: 0.3426\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6941 - accuracy: 0.3297 - val_loss: 1.6789 - val_accuracy: 0.3396\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6914 - accuracy: 0.3308 - val_loss: 1.6749 - val_accuracy: 0.3454\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6889 - accuracy: 0.3317 - val_loss: 1.6815 - val_accuracy: 0.3330\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6872 - accuracy: 0.3349 - val_loss: 1.6826 - val_accuracy: 0.3414\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.6894 - accuracy: 0.3352\n",
      "[CV] ................................. n_neurons=(1, 1), total=  18.5s\n",
      "[CV] n_neurons=(2, 1) ................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 21us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "[CV] ................................. n_neurons=(2, 1), total=   4.7s\n",
      "[CV] n_neurons=(2, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "[CV] ................................. n_neurons=(2, 1), total=   7.3s\n",
      "[CV] n_neurons=(2, 1) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 2.0833 - accuracy: 0.1976 - val_loss: 1.9635 - val_accuracy: 0.2358\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.9021 - accuracy: 0.2501 - val_loss: 1.8294 - val_accuracy: 0.2642\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.8211 - accuracy: 0.2657 - val_loss: 1.7835 - val_accuracy: 0.2760\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.7812 - accuracy: 0.3299 - val_loss: 1.7397 - val_accuracy: 0.3814\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.7387 - accuracy: 0.3708 - val_loss: 1.6968 - val_accuracy: 0.4054\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.7032 - accuracy: 0.3826 - val_loss: 1.6703 - val_accuracy: 0.4078\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6804 - accuracy: 0.3887 - val_loss: 1.6568 - val_accuracy: 0.4248\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6666 - accuracy: 0.3978 - val_loss: 1.6475 - val_accuracy: 0.4162\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6552 - accuracy: 0.4019 - val_loss: 1.6360 - val_accuracy: 0.4146\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.6451 - accuracy: 0.4040 - val_loss: 1.6299 - val_accuracy: 0.4232\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6370 - accuracy: 0.4066 - val_loss: 1.6244 - val_accuracy: 0.4268\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.6288 - accuracy: 0.4081 - val_loss: 1.6137 - val_accuracy: 0.4276\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.6186 - accuracy: 0.4081 - val_loss: 1.6079 - val_accuracy: 0.4248\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.6076 - accuracy: 0.4069 - val_loss: 1.6002 - val_accuracy: 0.4190\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5967 - accuracy: 0.4028 - val_loss: 1.5889 - val_accuracy: 0.4152\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5854 - accuracy: 0.3990 - val_loss: 1.5795 - val_accuracy: 0.4098\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5775 - accuracy: 0.3977 - val_loss: 1.5746 - val_accuracy: 0.4220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5705 - accuracy: 0.4004 - val_loss: 1.5675 - val_accuracy: 0.4148\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5628 - accuracy: 0.4034 - val_loss: 1.5623 - val_accuracy: 0.4314\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5552 - accuracy: 0.4161 - val_loss: 1.5579 - val_accuracy: 0.4336\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5507 - accuracy: 0.4227 - val_loss: 1.5545 - val_accuracy: 0.4330\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5458 - accuracy: 0.4280 - val_loss: 1.5492 - val_accuracy: 0.4334\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5397 - accuracy: 0.4271 - val_loss: 1.5501 - val_accuracy: 0.4442\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5359 - accuracy: 0.4338 - val_loss: 1.5437 - val_accuracy: 0.4452\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5342 - accuracy: 0.4345 - val_loss: 1.5461 - val_accuracy: 0.4468\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5323 - accuracy: 0.4379 - val_loss: 1.5453 - val_accuracy: 0.4486\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 1.5536 - accuracy: 0.4333\n",
      "[CV] ................................. n_neurons=(2, 1), total=  34.5s\n",
      "[CV] n_neurons=(2, 2) ................................................\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 2.0093 - accuracy: 0.2066 - val_loss: 1.8370 - val_accuracy: 0.2528\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.7505 - accuracy: 0.2965 - val_loss: 1.6059 - val_accuracy: 0.3848\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.4673 - accuracy: 0.4714 - val_loss: 1.3460 - val_accuracy: 0.5458\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.2563 - accuracy: 0.5858 - val_loss: 1.1861 - val_accuracy: 0.6164\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.1436 - accuracy: 0.6312 - val_loss: 1.1042 - val_accuracy: 0.6536\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.0853 - accuracy: 0.6467 - val_loss: 1.0621 - val_accuracy: 0.6590\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.0555 - accuracy: 0.6553 - val_loss: 1.0467 - val_accuracy: 0.6526\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.0385 - accuracy: 0.6562 - val_loss: 1.0473 - val_accuracy: 0.6598\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.0279 - accuracy: 0.6581 - val_loss: 1.0227 - val_accuracy: 0.6666\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.0202 - accuracy: 0.6577 - val_loss: 1.0196 - val_accuracy: 0.6644\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.0144 - accuracy: 0.6590 - val_loss: 1.0180 - val_accuracy: 0.6686\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0108 - accuracy: 0.6610 - val_loss: 1.0109 - val_accuracy: 0.6666\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.0076 - accuracy: 0.6596 - val_loss: 1.0138 - val_accuracy: 0.6626\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0038 - accuracy: 0.6616 - val_loss: 1.0129 - val_accuracy: 0.6602\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 1.0302 - accuracy: 0.6481\n",
      "[CV] ................................. n_neurons=(2, 2), total=  19.8s\n",
      "[CV] n_neurons=(2, 2) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.9555 - accuracy: 0.2260 - val_loss: 1.8497 - val_accuracy: 0.2552\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6947 - accuracy: 0.3506 - val_loss: 1.5710 - val_accuracy: 0.3774\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4334 - accuracy: 0.4492 - val_loss: 1.3246 - val_accuracy: 0.4952\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.2643 - accuracy: 0.5034 - val_loss: 1.2276 - val_accuracy: 0.5078\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.2009 - accuracy: 0.5144 - val_loss: 1.1806 - val_accuracy: 0.5220\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1714 - accuracy: 0.5260 - val_loss: 1.1583 - val_accuracy: 0.5288\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.1536 - accuracy: 0.5339 - val_loss: 1.1442 - val_accuracy: 0.5382\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1408 - accuracy: 0.5430 - val_loss: 1.1468 - val_accuracy: 0.5462\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1301 - accuracy: 0.5536 - val_loss: 1.1228 - val_accuracy: 0.5518\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1184 - accuracy: 0.5608 - val_loss: 1.1169 - val_accuracy: 0.5654\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.1082 - accuracy: 0.5697 - val_loss: 1.1052 - val_accuracy: 0.5702\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0990 - accuracy: 0.5755 - val_loss: 1.1022 - val_accuracy: 0.5732\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0925 - accuracy: 0.5810 - val_loss: 1.1027 - val_accuracy: 0.5842\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0847 - accuracy: 0.5860 - val_loss: 1.0813 - val_accuracy: 0.5852\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0755 - accuracy: 0.5934 - val_loss: 1.0731 - val_accuracy: 0.5894\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0658 - accuracy: 0.6021 - val_loss: 1.0720 - val_accuracy: 0.6008\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0542 - accuracy: 0.6150 - val_loss: 1.0706 - val_accuracy: 0.6184\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0400 - accuracy: 0.6238 - val_loss: 1.0316 - val_accuracy: 0.6314\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0274 - accuracy: 0.6301 - val_loss: 1.0230 - val_accuracy: 0.6352\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0169 - accuracy: 0.6380 - val_loss: 1.0117 - val_accuracy: 0.6430\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0068 - accuracy: 0.6430 - val_loss: 0.9993 - val_accuracy: 0.6530\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9994 - accuracy: 0.6458 - val_loss: 0.9976 - val_accuracy: 0.6544\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9908 - accuracy: 0.6518 - val_loss: 0.9894 - val_accuracy: 0.6692\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9861 - accuracy: 0.6553 - val_loss: 0.9823 - val_accuracy: 0.6598\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9797 - accuracy: 0.6566 - val_loss: 0.9725 - val_accuracy: 0.6632\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9752 - accuracy: 0.6607 - val_loss: 0.9701 - val_accuracy: 0.6684\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9714 - accuracy: 0.6606 - val_loss: 0.9655 - val_accuracy: 0.6554\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9658 - accuracy: 0.6632 - val_loss: 0.9651 - val_accuracy: 0.6658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9620 - accuracy: 0.6642 - val_loss: 0.9540 - val_accuracy: 0.6646\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9585 - accuracy: 0.6651 - val_loss: 0.9590 - val_accuracy: 0.6674\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.9959 - accuracy: 0.6547\n",
      "[CV] ................................. n_neurons=(2, 2), total=  39.4s\n",
      "[CV] n_neurons=(2, 2) ................................................\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.9021 - accuracy: 0.2841 - val_loss: 1.6322 - val_accuracy: 0.4032\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.4654 - accuracy: 0.4488 - val_loss: 1.3405 - val_accuracy: 0.4902\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.3089 - accuracy: 0.5007 - val_loss: 1.2539 - val_accuracy: 0.5198\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.2475 - accuracy: 0.5185 - val_loss: 1.2108 - val_accuracy: 0.5220\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.2146 - accuracy: 0.5265 - val_loss: 1.1848 - val_accuracy: 0.5340\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1921 - accuracy: 0.5344 - val_loss: 1.1637 - val_accuracy: 0.5534\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.1653 - accuracy: 0.5644 - val_loss: 1.1405 - val_accuracy: 0.5868\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1352 - accuracy: 0.5922 - val_loss: 1.1095 - val_accuracy: 0.6106\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.1092 - accuracy: 0.6049 - val_loss: 1.0903 - val_accuracy: 0.6220\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0906 - accuracy: 0.6140 - val_loss: 1.0737 - val_accuracy: 0.6288\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0753 - accuracy: 0.6194 - val_loss: 1.0727 - val_accuracy: 0.6270\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0643 - accuracy: 0.6237 - val_loss: 1.0619 - val_accuracy: 0.6376\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0543 - accuracy: 0.6378 - val_loss: 1.0428 - val_accuracy: 0.6456\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0453 - accuracy: 0.6446 - val_loss: 1.0341 - val_accuracy: 0.6536\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0374 - accuracy: 0.6507 - val_loss: 1.0287 - val_accuracy: 0.65940\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0306 - accuracy: 0.6564 - val_loss: 1.0199 - val_accuracy: 0.6660\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0246 - accuracy: 0.6578 - val_loss: 1.0113 - val_accuracy: 0.6758\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0198 - accuracy: 0.6602 - val_loss: 1.0039 - val_accuracy: 0.6724\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0150 - accuracy: 0.6626 - val_loss: 1.0185 - val_accuracy: 0.6634\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0122 - accuracy: 0.6633 - val_loss: 1.0163 - val_accuracy: 0.6738\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 1.0026 - accuracy: 0.6615\n",
      "[CV] ................................. n_neurons=(2, 2), total=  26.9s\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 2s 38us/sample - loss: 1.7711 - accuracy: 0.3132 - val_loss: 1.4318 - val_accuracy: 0.4484\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 1.3260 - accuracy: 0.5079 - val_loss: 1.2280 - val_accuracy: 0.5522\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 1.1892 - accuracy: 0.5828 - val_loss: 1.1328 - val_accuracy: 0.6156\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 1.1206 - accuracy: 0.6123 - val_loss: 1.0745 - val_accuracy: 0.6590\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 1.0660 - accuracy: 0.6568 - val_loss: 1.0381 - val_accuracy: 0.6794\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 1.0355 - accuracy: 0.6687 - val_loss: 1.0140 - val_accuracy: 0.6948\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 1.0188 - accuracy: 0.6738 - val_loss: 1.0058 - val_accuracy: 0.6974\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 1.0079 - accuracy: 0.6766 - val_loss: 0.9954 - val_accuracy: 0.6976\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9999 - accuracy: 0.6796 - val_loss: 0.9955 - val_accuracy: 0.6908\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.9950 - accuracy: 0.6793 - val_loss: 0.9874 - val_accuracy: 0.6958\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9890 - accuracy: 0.6807 - val_loss: 0.9875 - val_accuracy: 0.7014\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 2s 32us/sample - loss: 0.9842 - accuracy: 0.6820 - val_loss: 0.9851 - val_accuracy: 0.6980\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.9811 - accuracy: 0.6813 - val_loss: 0.9839 - val_accuracy: 0.7004\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9782 - accuracy: 0.6800 - val_loss: 0.9758 - val_accuracy: 0.7052\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.9756 - accuracy: 0.6808 - val_loss: 0.9755 - val_accuracy: 0.6832\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9733 - accuracy: 0.6816 - val_loss: 0.9746 - val_accuracy: 0.6912\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9705 - accuracy: 0.6790 - val_loss: 0.9738 - val_accuracy: 0.6882\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.9690 - accuracy: 0.6779 - val_loss: 0.9724 - val_accuracy: 0.6820\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.9672 - accuracy: 0.6773 - val_loss: 0.9780 - val_accuracy: 0.6886ss: 0.9651 - accura\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.9652 - accuracy: 0.6743 - val_loss: 0.9752 - val_accuracy: 0.6814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x1a4e9bd6d0>,\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neurons': [(1, 1), (1, 1), (2, 1), (2, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_cv2 = GridSearchCV(estimator=keras_clf2, param_grid=param_grid2,cv=3,verbose = 2)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_cv2.fit(train_images, train_labels, epochs=30,\n",
    "                  validation_data=(val_images, val_labels),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.57 minutes ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- {round((time.time() - start_time)/60,2)} minutes ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': (2, 2)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv2.best_params_ # parameters of best model obtain from GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAGVCAYAAAAi4jCfAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVQUV/o38G9Lg6goqCEGAwb3BXeHCBqjJigjS0BEEUlMBgXi+hOjRifoeDhuGU1cBomiiDGKYREXgnEbFokDoqBx1ygBRSAsijYomzzvH77Uselu6KYbutHnc06fY9+6de+tkn5obt16SkREBMYYY7okqpW2R8AYY0wWB2fGGNNBHJwZY0wHcXBmjDEdJK5bkJKSgu+//14bY2GMsTdSVFSUTJnMN+cHDx4gOjq6WQbEWHOJjo5GTk6Otoeh83Jycvjz34zqO98y35xryYvkjLVUIpEI/v7+mDZtmraHotMiIyPh4eHBn/9mUnu+5eE5Z8YY00EcnBljTAdxcGaMMR3EwZkxxnQQB2fGGNNBCldrMMakZWZmYs2aNQgMDIS5ubm2h6MzsrKykJKSIrzv06cPRowYIVWnuroaaWlpGDVqFAAgNzcX4eHhKCgogL29PcaNGwc9PT2V+r1w4QLu3r0rd5uNjQ26d+8OACgtLUVkZCSysrJgY2ODCRMmQF9fv962i4uLERISghUrVgAAMjIy0LlzZ7z33ntS9TIzM3H+/Hnhfd++fTF8+HCVjkMhqiMiIoLkFDPWogGgiIgItdqIiooiAHT8+HENjUr3NObzv3//fgJABw8epLy8PHr69KnU9pKSElq3bp1Qfu3aNZozZw7l5uZSSkoKjRo1irp27UrZ2dlK91lTU0M9e/YkAHJf6enpRER069Yt6tWrF8XFxZFEIqHw8HDq1q0bJSUl1du+q6srdenSRXhfVVVFX375pcx+paWllJWVRcnJyaSvr0/+/v5KHwNRvec7kqc1GFOSu7s7CgsLMWnSJK2OY9++fVrtX5FJkybhnXfeQfv27YWyhw8f4rPPPsPcuXOF8rVr16JPnz4wMzODjY0N1q5di9zcXGzcuFHpvs6cOQNHR0f8+eefqKioEF6nTp2CpaWl8O3V398fY8eOhYODA4yMjODp6Ynx48cjICBAYdu7du3C9evXpcrEYjGCgoKwYcMGXL16VShv164d3nvvPXzwwQd49913lR6/Mjg4M6aCt956S6v9x8fHC39qtwSLFy/G5MmTYWxsLJQZGhpi9+7dwnsbGxsAQF5entLtGhkZYfPmzbC0tISBgYHwOnr0KKZMmSLUy8vLkwm0rVu3RkVFhdx279y5g0uXLsHJyUlmm56eHhYvXgxfX1+lx6kODs6MKammpgYJCQm4cOGCUPbgwQNs3boVNTU1uHbtGtauXYuffvoJNTU1Uvvm5OQgODgYRITExESsWLECQUFBeP78OQAgNjYWW7ZsEYKWRCLB9u3bsWXLFkRERAAAEhIS4OrqitLSUuzcuROxsbEAgKKiIqxfvx5//fVXc5wGpaWlpSEuLg7u7u5S5cHBwYiLixPeZ2dnAwDGjx+vdNu2trZo1Uo6fNXU1CAmJgZubm5CmZubG1JTU7F//34AL+efDx8+jEWLFsm0WVVVhYCAAHz77bcK+7Wzs4NEIkFMTIzSY200FeZAGGuxoOac8/Xr18nd3Z0A0A8//EBERMeOHSNTU1MCQJs3b6Z//OMf5OTkRABo3bp1wr779++njh07Ups2bejLL78kb29vcnBwIABkbW1NlZWVRERkZWVF5ubmwn5Pnz6lDh06kK2tLRERXbp0iUaPHk2mpqaUkJBAly5dIiKiXbt2EQDatm1bo4+vljpzziUlJVLlU6ZMITs7uwb337BhAw0YMIAqKipU6reus2fPUteuXammpkYoy8/Pp759+xIA8vf3p4kTJ1JMTIzc/QMCAujcuXNEROTv7y815/wqX19fGjZsmEy5paUlzzkz1twGDBiAVatWSZU5Oztj1qxZAIBBgwZhz549iI2NxfDhw3Ho0CGhnpeXFxwdHVFeXo758+cjNDQUcXFxWLlyJS5cuIA9e/YAAPr37y/Vfvv27dGrVy/h/dChQ2FqagpDQ0OMGzcOQ4cOBQB4enoiPDwcX3zxRVMceqNduXIFXbt2rbcOESEsLAy7d++GgYGBWv1FRUVh8uTJEIlEQlmXLl2QnJyMnj17YvPmzZBIJMKKkVclJSVBLBbL3VaXlZUVrl69isrKSrXG2xAOzowpqXXr1jJlbdq0AQD069dPKBswYADu378vVa9du3YQi8WwsrISypYvXw6xWIyzZ8+qNI5Xg09t256enlIX4rStsrISmZmZMDMzq7femTNnYG9vD1tbW7X6IyIcOnRIar65VmhoKMaOHQtvb2+kpKRg5MiRUv8/JSUlCAoKwjfffKNUX8bGxqiurla4jE9TeJ0zYxqmp6cHUuK5yW3btoW5uTkKCwtVar9ucNZFjx49wosXL4RfXorEx8cjMDBQ7f7OnTuHyspKfPjhh1LlYWFhiIiIwIULFyAWizF69Gj4+flh3rx5wpy9v78/rK2tcezYMWG/P/74A+Xl5YiJiYGJiQk++ugjYZuRkRGAl9cRBgwYoPbYFeHgzJiWVFRUID8/H/b29irt1xKC8zvvvAMTExNIJJJ661laWkqt5Gis6OhouLi4yNzI8uOPP2LSpEkQi1+GOm9vb1y8eBGhoaEoKSmBiYkJCgsLcfr0aan9njx5gmfPnmHhwoWwsrKSCs6PHz8GAFhYWKg97vrwtAZjWpKamory8nJh2ZZYLEZ5eXm9+4hEIrx48aI5hqc2KysrFBQU1FvHz89P7X6ICNHR0XKnNK5cuYKSkhKpMhcXF1RWVgqrW3755Rfk5ORIvebMmQNTU1Pk5OTg5MmTUvvn5eVBJBIJdyA2FQ7OjCmpdm1sUVGRUPb06VMAkLo4VFRUhIqKCpmpjerqaty8eVN4Hx0djbFjxwrBeeLEiSgqKkJYWBjKysoQFhaG4uJiZGZmCt/WzMzMkJ+fj8zMTNy7dw9lZWVIT0/H+++/j8TExCY57sYaM2aM1A0bdSUnJ8PJyUlmfr6Wr68vHBwcGlwimJKSgtLSUnz88ccy21xdXXH48GGppY2pqakYPHgwevfureSRSMvKysLEiRNhaGjYqP2VxcGZMSWcP39emBuNiIhAXFwckpKScPjwYQDAunXrkJ+fj59//hnJycmQSCQIDAxEdXW10EarVq0QHByMZcuWwdPTE9nZ2cK8JwBMnToVNjY28Pb2hrW1NUxMTDBixAgMHTpUWP0xdepUEBFGjBiB48ePo127dsjOzsbFixeb/AKVqpYtW4bc3Fzcu3dP7va0tDQcP35c4fb4+Hj8+uuvwhplRaKiouDs7Cx3tUdQUBAcHR0xZMgQbN26FT4+PsjIyMCRI0dk1kkro7KyEkePHsWSJUtU3ldlKqy7Y6zFggZya6jDz8+P9PX1iYjo/v379OTJE4V1CwoKhH8/f/5cZntJSYlM/or62lOFJtc5ExHt2LGD5s2bp3Df4uJihdvKy8spIiKCjh49Wm//mZmZVFRUVG+dsrIyunHjBj169Kjeeg2JjIwkFxcXudt4nTNjLZyFhQU6dOigcLupqanwb3l/OhsbG8ssm6uvveYi75ZoHx8fFBcX49KlS3L36dSpU73tpaSkwMHBod5+u3fvjs6dO9dbp23btujfvz86duxYb7363Lp1CwcOHMDBgwflbtf0tQBercFYM3j27Bmqq6tRWloqLMV6Xejr66NDhw6YPXs2bG1tYW1tDTs7OwAvp3L27t2LBQsWwMfHB9bW1kq3m5aWhnXr1gkrLbQpOzsb69evx549e6SWB167dg0nTpzA/fv38fTpU43OQ2vkqF+nPLf5+fm4desWxo0bJ3d7XFyccBEIeJlbYf78+Wjbtq1S7Z89exYPHz6UKjMxMdF6prNap06dQnFxsVTZ4MGDpW6eYKo5cOAATp06BSLC119/DR8fH+HuvtfBtGnT6n2qeevWrRESEqLwwp8itQFeFxgYGGDv3r0yyxgHDhyIgQMHAgC2bdum2U5VmANR6HXIc1tQUEBfffUVtWnThhYuXCi3zs2bN0kkEknljZ0+fbpK/VRUVNDhw4eF/bdt20bPnj3TxCFoREFBAS1cuJAAkJ6eHsXHx6ud80AXQItzziUlJfT48WPhpUv/33XxNafm1eRzzq9DntusrCzMnDlTyBImz/fff4/4+Hjcv39feIWFhanUj4GBAVxcXGBiYgIA+PTTTxu8i6op1T1npqammDlzJoCXuRzGjx+vds6DN52xsTFMTEyElzb/v1nLobELgi09z621tbVUfoS68vPzceXKFfTq1QsWFhbCqzFzTCKRSLigo4m7oxpL0TmrHVu7du2ae0iMsf9PI3PONTU1SEpKgpGRkTDh/+DBA8TExGDBggW4ceMGjh49im7dusHLy0tqfWFOTg6OHTuGOXPmICkpCSdPnsS7776LWbNmoU2bNoiNjcW9e/dgZGSE2bNnQyKRYN++faiqqoKZmRk8PDyEPLcikQg7d+5E165d4ezsrIlDE/znP//B+fPnYWFhge7du2PVqlX4/PPPpeagioqKsGvXLnh7e6NLly4q99FSz9mdO3eQmpqKK1euYPTo0Zg8eTIA4L///S8ePHgA4OW8o5ubG1q3bo20tDTcuHEDHTt2hIuLi9BObm4uTpw4gZycHIwePVrqpoLHjx/j4MGDmDt3Ln799VdcuXIFX331lU5cLGKsSagwByKXLue5VVVFRQUBkDvnfPLkSVq6dCl98MEHpK+vTwDIzs6OqqurhTqq5NW1sLAgAPTixQudO2e3b98mAPThhx82eBybN2+mcePGUU1NDf35559kaWlJwcHBRPRybamVlRUBoHv37knt169fP7p9+7bwPj4+nnx8fCgjI4MiIyPJyMiI5s6dS0REe/fupbZt25JYLKb//Oc/NGTIEAJAv//+e4PjqwUtr3NuKXjOuXnVN+eskQuCV65ckQrORETLly8nAHTmzBmhbPjw4TRixAipfT/99FMSiUR07do1oWzlypUEgHbs2EFERO7u7lKBprat2kBD9PKBjBYWFiqNu676gvOrLl++TP369SMAtH79eqG8tLSUwsPDZW4QkKducCbSnXOmSnDu1auX1E0Grq6u5ODgILw/duwYAaBdu3YJZbm5ueTu7i68l0gk1KNHDyotLRXKZs2aRQAoJSWFiIi8vLwIgJAo/ebNmw2O7VUcnJXDwbl5NfkFQV3Nc9tUhgwZgvT0dJibm0stSFc3r25LPGeJiYlYs2YNAODGjRt48OAB/vjjD2G7k5MT+vfvj++//17INREeHi5cdASAgwcP4vnz51i2bBnmzZuHefPmIS8vDz179hRuSa5N2l47DVLf9QFFPDw8IBKJ+FXPy8PDAwC0Po435VV7vuVp1gm71ynPbdu2beHi4iI8xaKp6Po5e/fdd3Hq1Cn88ssvGDt2LHr27In09HSp9pcuXQpvb28cP34cjo6OOHPmDP7v//5PqHP9+nWYmZlh+/btCvupnXNvTD6EWosWLVI7qfvrLiUlReq5haxp1Z5veXTyakpLyXPbr18/9OnTp1n7VKS5z1lBQQGMjY2xZs0a4aJkmzZtpB7PVMvLywsrV67Ed999B0tLS1hZWUldyNPT08Pt27dRVVUFfX39Ro1HGba2tvXeLMFe2rJlC5+nZqQoOOtkbo2Wkuf28OHDUqsNtKm5z5mPjw/u37+PNWvWSK3VrvvUaeDl2u5FixYhISEBS5cuxT/+8Q+p7UOGDEFZWRl27NghVV5SUoLg4OBGjY+xlk4jwVlX89yqqratukHtzp07WLRokVTyluvXr6OsrAwBAQFCmSp5dWvPz6u3guvKOat9VL28B1jWPh3i1eB/8OBBPH36FMnJyTh79iweP36M0tJSqadg+Pn5wdjYGEVFRTK3gnt4eMDCwgJLlizBxo0bcfPmTURGRsLX1xefffYZAAhjq3trOWOvLRWuHsqVmpoqLKUbOHAg/fLLL5SYmEg9evQgADR79mzKy8ujgwcPUocOHQgArV69mqqqqojoZSpFPT09mj9/Pi1dupSmT59Ozs7OUiseJBIJ2djYEADq378/xcTEkJubG9nb2wurABISEkgsFpOJiUmjHhF//Phx8vDwIAD09ttv065duygvL4+IiNLT08nY2JgA0Pjx4+nrr7+mb7/9VuY23EOHDpFIJJJamVDX6dOnafbs2cLt225ubnTo0CGdOWcHDhyg999/nwCQSCSikSNH0scff0yjRo0iKysrYRlhSEgIERF5e3uTWCymXr160Y4dOyg6OpoMDAzoo48+kkkH+eWXX9L27dvlnpcbN25Qnz59hPNiZWVFGRkZRES0e/duevfddwkATZs2jc6fP6/0/2st8GoNpfBqjebV5Evp1NHUeW41pby8nO7cuUM5OTn11tNUXt366No5q7t/eXm53HoTJkygx48f19tWVlYWZWdnqzUeeTg4K4eDc/OqLzjr1AXBhh6YqEye21pz585tsD9fX1+ls4O1bt1aqcfaNHdeXU2es8aqu3RQ3tLK33//HT169BByiijy3nvvqT0exl4HWg/OTZXndvz48Q3WeTVwtSQtJTdweno6li1bhkGDBiExMRFHjhzR9pBYE8jKykJKSorwvk+fPhgxYoRUnerqaqSlpWHUqFEAXt6qHx4ejoKCAtjb22PcuHEyT85uyIULFxQ+msvGxga1D2AtLS1FZGQksrKyYGNjgwkTJjS4Kqi4uBghISFC7pmMjAx07txZ5stDZmYmzp8/L7zv27cvhg8frtJxKKTC12yN279/P3Xp0oUA0Ny5cxt92/WbpCWds7S0NGrfvj0ZGxtTZGSkVscCntZQijqPqTp48CDl5eXJTHOVlJTQunXrhPJr167RnDlzKDc3l1JSUmjUqFHUtWtXlaazampqqGfPnlLpe199paenExHRrVu3qFevXhQXF0cSiYTCw8OpW7dulJSUVG/7rq6u1KVLF+F9VVUVffnllzL7lZaWUlZWFiUnJ5O+vr5GH1Ol1eDckvLc6oqWds6qqqqkblHXFm0H5x9//LFFtK/pZwjm5OSQs7Oz1DZPT0/avHmz8D4hIYEA0Pz585Xu89SpU7Rw4UL6888/qaKiQnidOnWKLC0thXqTJk2iWbNmSe37+eef05gxYxS2HRISQr1795YKzkRE1dXVNGnSJLpy5Yrc/Sxfp2cIcp5b1bW0cyYWi9W6q+91oG46W223r47Fixdj8uTJUtc2DA0NsXv3buG9jY0NACAvL0/pdo2MjLB582ZYWlrCwMBAeB09ehRTpkwR6uXl5eH69etS+7Zu3Vru8w6Bl8tmL126JCxJfZWenh4WL14MX19fpcepjjf7U8NYPSQSCSIiIrB69WqEhoYK6U9rxcbGYsuWLUKgkUgk2L59u9Ttz7WpWUtLS7Fz507ExsYCeJn2NTg4GESExMRErFixAkFBQVIPe1Cn/aKiIqxfvx5//fVX056keqSlpSEuLg7u7u5S5cHBwYiLixPe166rV+Y6US1bW1uZX/o1NTWIiYmBm5ubUObm5obU1FTs378fwMv558OHD2PRokUybVZVVSEgIADffvutwn7t7OwgkUgQExOj9FgbTYWv2Yy1WFBxWuPy5cs0aNAgOnToEBUUFNCmTZvIyMhIZvqgMalZlU372tj2iVRLX/sqTU5rTJkyhezs7Brcf8OGDTRgwAC1H4d29uxZ6tq1K9XU1Ahl+fn51LdvXwJA/v7+NHHiRCGzYV0BAQF07tw5IiLy9/eXmdao5evrS8OGDZMpf62mNRjTRZWVlZg+fTomT54MNzc3mJqa4quvvsInn3wCHx8f3LhxQ6jbv39/qX3bt2+PXr16Ce+HDh0KU1NTGBoaYty4cRg6dCi8vLzg6OiI8vJyzJ8/H6GhoYiLi8PKlStx4cIFqWRajWkfADw9PREeHo4vvvhCk6dGJVeuXBGyCSpCRAgLC8Pu3bvVfhxaVFQUJk+eLJUvpkuXLkhOTkbPnj2xefNmSCQSYcXIq5KSkiAWi+Vuq8vKygpXr16VewetJnFwZqyOEydO4NatW8JcaC17e3tUVlYiNDRU5TbrJpjSZNpXRe2rk75WXZWVlcjMzISZmVm99c6cOQN7e3u1swUSEQ4dOiQ131wrNDQUY8eOhbe3N1JSUjBy5EipNLwlJSUICgrCN998o1RfxsbGqK6uVriMT1O0vs6ZMV1T+8247hryMWPGAIBUThNlKZP9r7FpX5Vtvzk9evQIL168aPCCdXx8PAIDA9Xu79y5c6isrMSHH34oVR4WFoaIiAhcuHABYrEYo0ePhp+fH+bNmyfMz/v7+8Pa2hrHjh0T9vvjjz9QXl6OmJgYmJiY4KOPPhK21f5c5OTkYMCAAWqPXREOzozV0alTJwAvc+3WBmTg5d2L+vr66Nixo8ptKhM8G5v2Vdn2m9M777wDExMTqeRX8lhaWmrkLtXo6Gi4uLjI3Mjy448/YtKkSUKKWm9vb1y8eBGhoaEoKSmBiYkJCgsLcfr0aan9njx5IiT5srKykgrOtYnDGro7V108rcFYHSNHjgQAmemFa9euoaqqSupPcE2mZq2b9lXT7Tc3KysrFBQU1FvHz89P7X6ICNHR0XKnNK5cuYKSkhKpMhcXF1RWVgorWX755Rfk5ORIvebMmQNTU1Pk5OTg5MmTUvvn5eVBJBIJdyA2FQ7OjNUxZMgQfP755zh79qzU3ORvv/2G3r17S61zVSc1a0NpX9VpX5X0tU1lzJgxuHr1qsLtycnJcHJyknkMWy1fX184ODg0uBwwJSUFpaWlUk9rr+Xq6orDhw9L5RlPTU3F4MGDlcqVI09WVhYmTpwoN1eNJnFwZkyOHTt2YObMmXBwcMCPP/6I0NBQHD9+HP/973+lVhVMnToVNjY28Pb2hrW1NUxMTDBixAgMHTpUeCrM1KlTQUQYMWIEjh8/jnbt2gF4+cit4OBgLFu2DJ6ensjOzhbmQdVtPzs7GxcvXmzyi1b1WbZsGXJzc3Hv3j2529PS0nD8+HGF2+Pj4/Hrr78Ka5QViYqKgrOzs9zVHkFBQXB0dMSQIUOwdetW+Pj4ICMjA0eOHGnUzVGVlZU4evQolixZovK+KlNh3R1jLRYaeft2SUkJnTt3jh48eFBvPVVTs6qS9rUx7RM1Ln2tpm/f3rFjh9TT2euqm/P7VeXl5RQREUFHjx6tt//MzEwqKiqqt05ZWRnduHGDHj16VG+9hkRGRpKLi4vcbbzOmbFmZGxsjFGjRsHc3LzeesqkZlW0rM3CwqLBVLONab+509fKuyXax8cHxcXFUk8RelXtxVdF7aWkpMDBwaHefrt3747OnTvXW6dt27bo379/oy7m1rp16xYOHDiAgwcPyt2u6Xl/Xq3BmBa0lLSvytDX10eHDh0we/Zs2NrawtraGnZ2dgBeTt3s3bsXCxYsgI+PD6ytrZVuNy0tDevWrZN6GLC2ZGdnY/369dizZ4/U8sBr167hxIkTuH//Pp4+farReWjtHzVjb5gDBw7g1KlTICJ8/fXX8PHxUfqhD7po2rRp9T6tu3Xr1ggJCVF44U+R2gCvCwwMDLB3716ZJYsDBw7EwIEDAQDbtm3TaJ8cnBlrZk5OTnB0dBTey3tyzOuoW7du2h5CozV0p2NT4ODMWDPTxE0X7PXHFwQZY0wHcXBmjDEdxMGZMcZ0kMI558jIyOYcB2NN7tUnRDP5as8Rf/6bR30/kyIiolcLIiMj4eHh0eSDYowx9lKdMAwAUTLBmbGWqPZLBf84s9dEFM85M8aYDuLgzBhjOoiDM2OM6SAOzowxpoM4ODPGmA7i4MwYYzqIgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjDGmgzg4M8aYDuLgzBhjOoiDM2OM6SAOzowxpoM4ODPGmA7i4MwYYzqIgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjDGmgzg4M8aYDuLgzBhjOoiDM2OM6SAOzowxpoM4ODPGmA7i4MwYYzqIgzNjjOkgDs6MMaaDODgzxpgOEmt7AIypKicnB59//jlevHghlD1+/Bjt27fHuHHjpOr27dsXO3fubOYRMqY+Ds6sxTE3N0d2djbu3bsnsy0pKUnq/Ycffthcw2JMo3hag7VIM2fOhL6+foP1pk+f3gyjYUzzODizFsnLywvV1dX11rGyssKAAQOaaUSMaRYHZ9Yi9ezZE4MHD4ZIJJK7XV9fH59//nkzj4oxzeHgzFqsmTNnQk9PT+626upqTJ06tZlHxJjmcHBmLZanpydqampkylu1agUbGxtYWlo2/6AY0xAOzqzFMjMzw+jRo9GqlfSPcatWrTBz5kwtjYoxzeDgzFq0zz77TKaMiODm5qaF0TCmORycWYvm7u4uNe+sp6cHOzs7vP3221ocFWPq4+DMWrSOHTtiwoQJQoAmInz66adaHhVj6uPgzFq8Tz/9VLgwqK+vD1dXVy2PiDH1cXBmLd4nn3yC1q1bAwCcnZ1hZGSk5RExpj4OzqzFa9eunfBtmac02OtCRETUHB1FRkbCw8OjObpijLEm0UzhEgCimj0rXURERHN3yV5jHh4eWLRoEd5//31ERERgxowZ2h6STkpJScGWLVv489dIteevOTV7cJ42bVpzd8leYx4eHrC1tcW0adMwefJkGBoaantIOmvLli38+VNDcwdnnnNmrw0OzOx1wsGZMcZ0EAdnxhjTQRycGWNMB3FwZowxHcQPeGVvvMzMTKxZswaBgYEwNzfX9nB0UnV1NdLS0jBq1CgAQG5uLsLDw1FQUAB7e3uMGzdO4YMPFLlw4QLu3r0rd5uNjQ26d+8OACgtLUVkZCSysrJgY2ODCRMmNPj8yOLiYoSEhGDFihUAgIyMDHTu3BnvvfeeSmPUKmomERER1IzdsTcEAIqIiFCrjaioKAJAx48f19CodI86n7+SkhJat24dPX36lIiIrnWYm/cAACAASURBVF27RnPmzKHc3FxKSUmhUaNGUdeuXSk7O1vpNmtqaqhnz54EQO4rPT2diIhu3bpFvXr1ori4OJJIJBQeHk7dunWjpKSkett3dXWlLl26CO+rqqroyy+/bHA/RbQQvyJ5WoO98dzd3VFYWIhJkyZpdRz79u3Tav/yPHz4EJ999hnmzp2L9u3bAwDWrl2LPn36wMzMDDY2Nli7di1yc3OxceNGpds9c+YMHB0d8eeff6KiokJ4nTp1CpaWlhg+fDgAwN/fH2PHjoWDgwOMjIzg6emJ8ePHIyAgQGHbu3btwvXr16XKxGIxgoKCsGHDBly9erURZ6L5cXBmDMBbb72l1f7j4+OFP8F1yeLFizF58mQYGxsLZYaGhti9e7fw3sbGBgCQl5endLtGRkbYvHkzLC0tYWBgILyOHj2KKVOmCPXy8vJkAm3r1q1RUVEht907d+7g0qVLcHJyktmmp6eHxYsXw9fXV+lxahMHZ/bGq6mpQUJCAi5cuCCUPXjwAFu3bkVNTQ2uXbuGtWvX4qeffpJ5ZmFOTg6Cg4NBREhMTMSKFSsQFBSE58+fAwBiY2OxZcsWIZhJJBJs375d6lbqhIQEuLq6orS0FDt37kRsbCwAoKioCOvXr8dff/3VHKdBRlpaGuLi4uDu7i5VHhwcjLi4OOF9dnY2AGD8+PFKt21rayvzeLGamhrExMRIPcXGzc0Nqamp2L9/P4CX88+HDx/GokWLZNqsqqpCQEAAvv32W4X92tnZQSKRICYmRumxak1zTaDwnDNrClBzzvn69evk7u5OAOiHH34gIqJjx46RqakpAaDNmzfTP/7xD3JyciIAtG7dOmHf/fv3U8eOHalNmzb05Zdfkre3Nzk4OBAAsra2psrKSiIisrKyInNzc2G/p0+fUocOHcjW1paIiC5dukSjR48mU1NTSkhIoEuXLhER0a5duwgAbdu2rdHHV6sxn78pU6aQnZ1dg/U2bNhAAwYMoIqKisYOj4iIzp49S127dqWamhqhLD8/n/r27UsAyN/fnyZOnEgxMTFy9w8ICKBz584REZG/v7/UnPOrfH19adiwYSqNjeecGWtmAwYMwKpVq6TKnJ2dMWvWLADAoEGDsGfPHsTGxmL48OE4dOiQUM/LywuOjo4oLy/H/PnzERoairi4OKxcuRIXLlzAnj17AAD9+/eXar99+/bo1auX8H7o0KEwNTWFoaEhxo0bh6FDhwJ4+XTx8PBwfPHFF01x6A26cuUKunbtWm8dIkJYWBh2794NAwMDtfqLiorC5MmTIRKJhLIuXbogOTkZPXv2xObNmyGRSIQVI69KSkqCWCyWu60uKysrXL16FZWVlWqNt6lxcGZvvNpE/a9q06YNAKBfv35C2YABA3D//n2peu3atYNYLIaVlZVQtnz5cojFYpw9e1alcbwalGrb9vT0FC7ENafKykpkZmbCzMys3npnzpyBvb09bG1t1eqPiHDo0CGp+eZaoaGhGDt2LLy9vZGSkoKRI0dK/T+UlJQgKCgI33zzjVJ9GRsbo7q6WuEyPl3B65wZU5Kenp5S+Xzbtm0Lc3NzFBYWqtR+3eCsTY8ePcKLFy+EX1KKxMfHIzAwUO3+zp07h8rKSnz44YdS5WFhYYiIiMCFCxcgFosxevRo+Pn5Yd68ecLcvL+/P6ytrXHs2DFhvz/++APl5eWIiYmBiYkJPvroI2Fb7ZNycnJyMGDAALXH3lQ4ODOmYRUVFcjPz4e9vb1K++lScH7nnXdgYmICiURSbz1LS0uplRyNFR0dDRcXF5kbWX788UdMmjQJYvHLUOXt7Y2LFy8iNDQUJSUlMDExQWFhIU6fPi2135MnT/Ds2TMsXLgQVlZWUsH58ePHAAALCwu1x92UeFqDMQ1LTU1FeXm5sJxLLBajvLy83n1EIhFevHjRHMNTmpWVFQoKCuqt4+fnp3Y/RITo6Gi5UxpXrlxBSUmJVJmLiwsqKyuFVSy//PILcnJypF5z5syBqakpcnJycPLkSan98/LyIBKJhDsQdRUHZ/bGq10zW1RUJJQ9ffoUAKQuGhUVFaGiokJmaqO6uho3b94U3kdHR2Ps2LFCcJ44cSKKiooQFhaGsrIyhIWFobi4GJmZmcK3ODMzM+Tn5yMzMxP37t1DWVkZ0tPT8f777yMxMbFJjrshY8aMqfeGjeTkZDg5OcnMw9fy9fWFg4NDg0sBU1JSUFpaio8//lhmm6urKw4fPiy1hDE1NRWDBw9G7969lTwSaVlZWZg4caLO5//m4MzeaOfPnxfmTCMiIhAXF4ekpCQcPnwYALBu3Trk5+fj559/RnJyMiQSCQIDA1FdXS200apVKwQHB2PZsmXw9PREdna2MB8KAFOnToWNjQ28vb1hbW0NExMTjBgxAkOHDhVWf0ydOhVEhBEjRuD48eNo164dsrOzcfHiRa1duFq2bBlyc3Nx7949udvT0tJw/Phxhdvj4+Px66+/CmuUFYmKioKzs7Pc1R5BQUFwdHTEkCFDsHXrVvj4+CAjIwNHjhyRWSetjMrKShw9ehRLlixRed9m11yL9nidM2sK0EBuDXX4+fmRvr4+ERHdv3+fnjx5orBuQUGB8O/nz5/LbC8pKRHyV9Sqrz1VNPbzt2PHDpo3b57C7cXFxQq3lZeXU0REBB09erTePjIzM6moqKjeOmVlZXTjxg169OhR/QNuQGRkJLm4uKi8H69zZqwFs7CwQIcOHRRuNzU1Ff4t709qY2NjmWVz9bXXHHx8fFBcXIxLly7J3d6pUyeF+1ZUVCAlJQUODg719tG9e3d07ty53jpt27ZF//790bFjx4YHrcCtW7dw4MABHDx4sNFtNKcWtVqjtLQUCQkJ+O233+q9RbOlqJvWsK78/HzcunUL48aNU7nts2fP4uHDh1Jl+vr6MDU1RdeuXRs9X8ekPXv2DNXV1SgtLRWWaL1OWrVqhb1792LBggXw8fGBtbW10vumpaVh3bp1wkoLbcrOzsb69euxZ8+eBpcH6ooW9c35xIkTWLhwIX7++WdtD0UjZs+eja1bt8qUFxYWYsmSJejRo4cw96mqwYMH4969e5gxYwa++OILPH36FIWFhYiNjYWHhwe6d++OgIAAVFVVqXsYb6wDBw7g1KlTICJ8/fXXuHz5sraH1CRat26NkJAQdOnSRaX97OzsdCYQGhgYYO/evfV+09c12v+VpgJ3d3dERUXh4sWL2h6K2uSlNayVlZWFmTNn4rvvvmt0+yYmJvjiiy+wcuVK9OzZU2rJE/3/u7FmzZqFtLQ0HDp0SCt3obV0Tk5OcHR0FN7Lu9PwddKtWzdtD6HRGrrTURe1qOAMvPwzqzFXaXXJq2kNw8PDZbZbW1tr5L5/RfOVIpEI7u7uePHiBaZPn44xY8YgLS1N7dwIbxpN3HzBmCI6H5wfPXqE6OhoZGVl4W9/+xuISOZOqtzcXJw4cQI5OTkYPXq0zHrJBw8eICYmBgsWLMCNGzdw9OhRdOvWDV5eXkKgJyIkJSXh8uXL0NPTQ79+/TBhwgSl+1BWbVrD0NBQ/Otf/2pUG8DLNbe7du2Ct7e3yn9u1vLw8MC+fftw/PhxpKWl4YMPPhC21Xe8mjifDfXB2JtOp7+C3r59G3//+98xaNAgBAYGoqioCEeOHJEKzgkJCVi9ejWGDRuG/v37w9XVFfPmzRO2x8bGYsSIEVi0aBG2bduG77//HqmpqZg5c6bURcWAgADcvXsXixYtgq2trdSTFhrqQxWBgYFYtGiR2tMIR44cwT//+U9ERkaq1U5tovTk5GShrL7j1cT5bKgPxhh0e53zyJEjaenSpcL7mpoa6tGjB/Xp04eIiCQSCfXo0YNKS0uFOrNmzSIAlJKSIpQtX76cANCZM2eEsuHDh9OIESOEdt966y1KSEgQtq9Zs0alPpSRmJhIq1evFt7Xl3O2oqKCANDChQvlbi8tLaXw8HCZdbGvevLkCQGg/v37K6wTExNDAGjSpElEpNzxqnM+le1DWdDyOueWgu8zUI821jnr7LRGfHw8zp8/L/Wnv0gkgrW1tXBV/ODBg3j+/DmWLVsm1MnLy0PPnj1x9+5d4VuhovSPtffci0Qi9O3bFx4eHggJCYGLi4twB5GyfTSkNq2hptZY1qaTVFdpaanQHqDc8apzPpXtQxUpKSkqHvWbp/YcqfuX1ptKGz9jOhucf//9dwDAwIEDpcpfndK4fv06zMzMsH37dpXbr5v+MSgoCFOnToWrqys+/vhjHDhwAF26dFGrj1epmtawuWRkZAAARo4cCaDx51TZ86lOH4ps2bIFW7Zs0UhbrzsPDw9tD4EpSWeDc23imfPnz8uk9qsN0Hp6erh9+zaqqqqgr6+vVn9Dhw5FRkYGli9fjp07d2L48OG4evWqxvpQNa1hcyAiJCcnQ09PT7hYp6njVXQ+O3XqpNH/N+BlToxp06ap3c7rLDIyEh4eHkrlo2ayas9fc9LZC4KDBg0C8HJ6Q5EhQ4agrKwMO3bskCovKSlBcHCw0n1VVFTgp59+Qvv27bF9+3bExcUhLy8PMTExGutD1bSGzcHf3x/p6enYuHEjhgwZAkAz57S+86mpPhh77TXX7LaqE+pVVVXUr18/MjIyoqSkJCIievjwIZmZmZGRkRH9/vvvVFpaShYWFmRgYED//ve/6caNGxQREUFTp06VulD21VdfEQDKzMwUyhwdHal9+/ZUU1NDz58/p1GjRgkPlqypqSFTU1M6fPgwlZeXK9VHYyxdulThBcH8/HwCQL6+vnK3X7x4kaytraUuutX1+++/EwCytLSUKv/zzz9p7ty5JBKJaMGCBVLblDledc6nsn0oC3xBUCl8QVA92rggqLPBmehlELG2tiYA1KNHD5oxYwY5OzvTBx98QD/88AM9f/6cbty4QX369CEABICsrKwoIyNDaCMxMZF69OhBAGj27NmUl5dHBw8epA4dOhAAWr16NUkkEjIzM6Pp06dTVFQUbdq0iVatWiW00VAfjaUoOB8/fpw8PDwIAL399tu0a9cuysvLk6pz6NAhEolEtGvXLrltHzt2jMaNGyeM2dbWliZMmECOjo7k4uJCX331FV24cEHuvvUdrybOZ0N9qIKDs3I4OKtHG8FZRNQ8k1DqzHkVFhaibdu2aNeuncIEM9nZ2RCJRI2+xbS6uho1NTXIz89X2Ia6fWja06dPmzRrmTrHq8z5VLcP4OX1B55zbhjPOatHC+cvSmcvCL7q1VSLijJ/vffee2r1UZs5q74goaiPuXPnNti+r6+v8Mh7TWnqdJLqnFNlzqe6fTD2OmsRwVnXjR8/vsE6r/6CYYyxhnBw1oCpU6dqewiMaV11dTXS0tIwatQooSw3Nxfh4eEoKCiAvb09xo0bJ/OE7YZIJBKEh4fjzz//RK9evTBjxgy0bdtW2J6RkYHOnTu/dn+F6exSOsZYy/HkyRNs3LhRWAILvLzZaM2aNfDy8oKbmxtWrVqFbt26KXwgrDy3b99Gnz598N1332Hz5s3w8fHB4MGDkZ+fL9QZPHgwNmzYgLNnz2r0mLSNgzNjati3b1+Lbl8THj58iM8++wxz586VSui1du1a9OnTB2ZmZrCxscHatWuRm5uLjRs3Kt22v78/Tp48iTt37iAnJwezZ8/GvXv38M033wh1xGIxgoKCsGHDhnqfFt7ScHBmrJHi4+MVPmKsJbSvKYsXL8bkyZNl8lsbGhpi9+7dwvvanCl5eXlKtZueng4vLy8MHjwYwMvrNoGBgWjVqhX+97//SdXV09PD4sWL4evrq86h6BSec2ZvHIlEguPHj+PmzZuwsLDAxIkTpVIExMbG4t69ezAyMsLs2bMhkUiwb98+VFVVwczMDB4eHkhISICrqytEIhF27tyJrl27wtnZGTk5OTh27BjmzJmDpKQknDx5Eu+++y5mzZolJIxSp31N5PHWpLS0NMTFxUkF4VrBwcH466+/hPfZ2dkAlLuADgCWlpYYPny4VJmZmRlGjBgh97mEdnZ2WLRoEWJiYuDm5qbKYeim5lpRzYvgWVOAijehXL58mQYNGkSHDh2igoIC2rRpExkZGdGPP/4oVc/KyorMzc2F90+fPqUOHTqQra0tERFdunSJRo8eTaamppSQkECXLl2i/fv3U8eOHalNmzb05Zdfkre3Nzk4OBAAsra2psrKSrXaJyLatWsXAaBt27apdJ6a6vM3ZcoUsrOzU6ruhg0baMCAAVRRUaFWn++88w4FBgbK3ebr60vDhg1Tq315+A5BxlSkSnCuqKigfv36ydytOGPGDDIwMKDr168LZe7u7lLBk+hlzura4ElE5OrqShYWFlJ1Pv30UxKJRHTt2jWhbOXKlQSAduzYoXb7yuTxlqepPn+9e/emmTNnNlivpqaG+vbtS//73//U6i8pKYnMzc1JIpHI3b5161YSi8Vq/wKoSxvBmeec2RvjxIkTuHXrlky+aHt7e1RWViI0NFTlNus+Mq1du3YQi8WwsrISypYvXw6xWNyo1QTy2vf09NSJB/JWVlYiMzNTqYennjlzBvb29rC1tW10fy9evMCqVatw7NgxhTejGRsbo7q6Gnfv3m10P7qCgzN7Y9y4cQOA7F2mY8aMAQDcvHlT5TbrBk952rZtC3NzcxQWFjZJ+9ry6NEjvHjxQphLr098fDwCAwPV6m/JkiVYvHgxhg0bprBO7f9tTk6OWn3pAg7O7I3RqVMnALJPtXjvvfegr6+Pjh07qtymMsGzoqIC+fn56NGjR5O0ry3vvPMOTExMIJFIGqxraWmp1tPKQ0JCMGzYMHzyySf11nv8+DEAyOSAb4k4OLM3Ru3TXupOL1y7dg1VVVVSf3KLxWKUl5fX255IJMKLFy8a7Dc1NRXl5eVwcnJqkva1ycrKCgUFBQ3W8/Pza3Qfhw8fBhFh5syZUuVJSUkydfPy8iASidC9e/dG96crODizN8aQIUPw+eef4+zZs1J3qf3222/o3bu31BrZiRMnoqioCGFhYSgrK0NYWBiKi4uRmZkpfDszMzNDfn4+MjMzce/ePZSVlQF4eRvzq1Mk0dHRGDt2rFRwbmz76enpeP/995GYmNiUp0ppY8aMafDGj+TkZDg5Ocm9M9DX1xcODg5SS+5edebMGXz77beoqqpCUFAQgoKCsHXrVvj5+eHKlSsy9bOysjBx4kQYGho27oB0SXNdeuTVGqwpQMWldM+fP6d58+aRlZUV7d27l3bv3k2Ojo50//59qXoSiYRsbGyEp5fHxMSQm5sb2dvbCzm0ExISSCwWk4mJibC0zc/Pj/T09Gj+/Pm0dOlSmj59Ojk7O8usrmhs+w3l8VakqT5/jx49orfffpvu3r2rsM6mTZtIJBJRfHy8zLaePXsSANq0aZPMtvT0dGrXrp2Q8/vVl6GhIRUXF0vVr6iooM6dO9Pp06fVP7A6eCkdYypSNTjXKikpoXPnztGDBw/qrVdQUCD8+/nz53LbeTXw+vn5kb6+PhER3b9/n548eaLR9omowTblacrP344dO2jevHn11qkbSGuVl5dTREQEHT16VO1xREZGkouLi9rtyMNL6RhrJsbGxhg1ahTMzc3rrfdqqld5fyobGxsrXNZmYWHRYM7txrTf1Hm8VeXj44Pi4mJcunRJYZ3ai7F1VVRUICUlBQ4ODmqN4datWzhw4AAOHjyoVju6hIMzYxr07NkzVFdXo7S0VNtDaTatWrXC3r178cMPP+DChQsq7ZuWloZ169bJvR1bWdnZ2Vi/fj327Nmj1LK+loKDM2MacuDAAZw6dQpEhK+//hqXL1/W9pCaTevWrRESEqJyvg87Ozu1A6qBgQH27t2r8Nt5S8WJjxjTECcnJzg6OgrvW7durcXRaIc2nq+pzB2KLREHZ8Y0RJ2bLBiri6c1GGNMB3FwZowxHcTBmTHGdFCzzznzk6qZpm3evBlRUVHaHoZOq83Sxp+/xtFGljsREVFzdJSSkoLvv/++Obpib6D8/HxcunQJkyZN0vZQ2GusGb8ERDVbcGasKUVGRsLDwwP848xeE1E858wYYzqIgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjDGmgzg4M8aYDuLgzBhjOoiDM2OM6SAOzowxpoM4ODPGmA7i4MwYYzqIgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjDGmgzg4M8aYDuLgzBhjOoiDM2OM6SAOzowxpoM4ODPGmA7i4MwYYzqIgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjDGmgzg4M8aYDhJrewCMqaqqqgqlpaVSZWVlZQCAx48fS5WLRCKYmJg029gY0xQOzqzFefToEd599128ePFCZlunTp2k3o8fPx7x8fHNNTTGNIanNViL06VLF3z44Ydo1ar+H1+RSARPT89mGhVjmsXBmbVIn332WYN19PT04Obm1gyjYUzzODizFmnKlCkQixXPyunp6eHvf/87Onfu3IyjYkxzODizFqlDhw6YNGmSwgBNRPj000+beVSMaQ4HZ9Ziffrpp3IvCgKAgYEBnJycmnlEjGkOB2fWYjk5OaFt27Yy5fr6+pg8eTLatWunhVExphkcnFmLZWhoCDc3N+jr60uVV1VVwcvLS0ujYkwzODizFm3GjBmoqqqSKuvQoQMmTJigpRExphkcnFmLZmdnJ3Xjib6+Pjw9PWFgYKDFUTGmPg7OrEUTi8Xw9PQUpjaqqqowY8YMLY+KMfVxcGYtnqenpzC10aVLF3zwwQdaHhFj6uPgzFq8UaNG4d133wUAzJw5s8HbuhlrCXQu8VFkZKS2h8BaIGtrazx8+BCdO3fmnyGmMgsLC9ja2mp7GFJERETaHsSrRCKRtofAGHvDuLu7IyoqStvDeFWUzn1zBoCIiAhMmzZN28NgLUx0dDTc3d1lyqdOnQoAuvbh00kikeiN+/zV/nzoGp6cY68NeYGZsZaKgzNjjOkgDs6MMaaDODgzxpgO4uDMGGM6iIMzY4zpIA7OjCkhMzMT3t7eyMnJ0fZQdFZ1dTX+97//SZXl5uZi06ZNWLZsGf773/8qfDhCfSQSCXbu3Inly5dj9+7dePbsmdT2jIwMZGdnqzV2XcTBmTElZGRkICwsDFevXtX2UHTSkydPsHHjRgwaNEgou379OtasWQMvLy+4ublh1apV6NatG+7fv690u7dv30afPn3w3XffYfPmzfDx8cHgwYORn58v1Bk8eDA2bNiAs2fPavSYtI2DM2NKcHd3R2FhISZNmqTtoWDfvn3aHoKUhw8f4rPPPsPcuXPRvn17oXzt2rXo06cPzMzMYGNjg7Vr1yI3NxcbN25Uum1/f3+cPHkSd+7cQU5ODmbPno179+7hm2++EeqIxWIEBQVhw4YNr9UvTw7OjCnprbfe0vYQEB8fjxUrVmh7GFIWL16MyZMnw9jYWKrc0NAQu3fvFt7b2NgAAPLy8pRqNz09HV5eXhg8eDAAwNTUFIGBgWjVqpXM9Imenh4WL14MX19fdQ5Fp3BwZkwJNTU1SEhIwIULF6TKHzx4gK1bt6KmpgbXrl3D2rVr8dNPP6Gmpkaok5OTg+DgYBAREhMTsWLFCgQFBeH58+cAgNjYWGzZskUIZBKJBNu3b8eWLVsQEREhtJOQkABXV1eUlpZi586diI2NBQAUFRVh/fr1+Ouvv5r6NMhIS0tDXFyc3Lszg4ODERcXJ7yvnRceP368Um1bWlrK5OY2MzPDiBEj0LFjR5n6dnZ2kEgkiImJUeUQdJZO5tZgTJfcuHED//rXvxAdHY0ffvgB1tbWAF4G1VmzZqGwsBBEhCtXrqCwsBABAQHIycnBihUrcODAASxYsADl5eW4evUqKisrkZ+fjw0bNmDfvn04d+4cnJ2dMXDgQDx58gSzZ89G+/btMXPmTJibm8PKygoeHh4AgI4dO2Lw4MG4c+cO+vbtCxMTEwDAkSNH8M9//hNGRkZYsGBBs56bf//737C1tZWazqhlaGiI9957T3h/5MgRDBgwAD4+Pkq13blzZ7nlDx48wNy5c+VuGz16NNasWQM3Nzel+tBl/M2ZsQYMGDAAq1atkil3dnbGrFmzAACDBg3Cnj17EBsbi+HDh+PQoUMAAC8vLzg6OqK8vBzz589HaGgo4uLisHLlSly4cAF79uwBAPTv31+q7fbt26NXr15SZUOHDoWpqSkMDQ0xbtw4DB06FMDLhw2Eh4fjiy++0PShN+jKlSvo2rVrg/WICGFhYdi9e7dajxA7e/YsxGIx/P395W63srISfgm2dBycGVNC69at5Za3adMGANCvXz+hbMCAAVIrEtq1awexWAwrKyuhbPny5RCLxY1aYVA3rW67du3g6ekp99trU6qsrERmZibMzMwarHvmzBnY29urlTP5xYsXWLVqFY4dOwYjIyO5dYyNjVFdXY27d+82uh9dwcGZMQ3T09NDQ2nS27ZtC3NzcxQWFqrcvq7kPH/06BFevHgh/IKqT3x8PAIDA9Xqb8mSJVi8eDGGDRumsE5t0H4d1qNzcGZMCyoqKpCfn48ePXqovK+uBOd33nkHJiYmkEgkDda1tLSUWc2hipCQEAwbNgyffPJJvfUeP34M4OWTTVo6Ds6MaUFqairKy8vh5OQE4OVa3fLy8gb3E4lEjbrLrqlYWVmhoKCgwXp+fn6N7uPw4cMgIsycOVOqPCkpSaZuXl4eRCIRunfv3uj+dAUHZ8aUUFFRAeDlsrVXPX36FACkLkAVFRWhoqJCamqjuroaN2/eFN5HR0dj7NixQnCeOHEiioqKEBYWhrKyMoSFhaG4uBiZmZnCt0Hg5VKy/Px8ZGZm4t69eygrK0N6ejref/99JCYmavy4GzJmzJgGb/xITk6Gk5OT3DsDfX194eDgoHAZBFJcLQAAIABJREFU4JkzZ/Dtt9+iqqoKQUFBCAoKwtatW+Hn54crV67I1M/KysLEiRNhaGjYuAPSJaRjAFBERIS2h8FeI+7u7uTu7t7o/VNTU8nd3Z0A0MCBA+mXX34hIqLExETq0aMHAaDZs2dTXl4eHTx4kDp06EAAaPXq1VRVVUV+fn6kp6dH8+fPp6VLl9L06dPJ2dmZnj59KvQhkUjIxsaGAFD//v0pJiaG3NzcyN7ennbt2iXUS0hIILFYTCYmJrRt2zYiIjp06BCJRCKpeo2l6ufv0aNH9Pbbb9Pdu3cV1tm0aROJRCKKj4+X2dazZ08CQJs2bZLZlp6eTu3atSMAMi9DQ0MqLi6Wql9RUUGdO3em06dPKz1+IvV/PppIJAdn9trT9ofPz8+P9PX1iYjo/v379OTJE4V1CwoKhH8/f/5cbp2SkhKpwE5E9bapisZ8/nbs2EHz5s2rt07dQFqrvLycIiIi6OjRoyr1KU9kZCS5uLiovJ+2fz4UiORpDcaakYWFBTp06KBwu6mpqfBvRX+aGxsbyyybq6/Npubj44Pi4mJcunRJYZ1OnTrJLa+oqEBKSgocHBzUGsOtW7dw4MABHDx4UK12dMlrd4dgaWkpEhIS8Ntvv+Hbb7/V9nDUVlxcjJCQELn5FCQSCcLDw/Hnn3+iV69emDFjBtq2batS+2fPnsXDhw+lyvT19WFqaoquXbuid+/eao2fAc+ePUN1dTVKS0sVrs9tyVq1aoW9e/diwYIF8PHxEe6gVEZaWhrWrVsHsbjxoSg7Oxvr16/Hnj17lFrW11K8dt+cT5w4gYULF+Lnn3/W9lA0Yvbs2di6datMuTKpFJUxePBg3Lt3DzNmzMAXX3yBp0+forCwELGxsfDw8ED37t0REBCAqqoqTR3SG+XAgQM4deoUiAhff/01Ll++rO0hNYnWrVsjJCQEXbp0UWk/Ozs7tQOqgYEB9u7dq/DbeYul7YmVuqCBOedp06ZRjx49NDQi7QkJCaHevXtTly5dZLZNmjSJfv/9dyJ6OU85e/ZsAkDe3t4q9/PgwQPhQtSrampqKCoqijp06EATJkyQmedsKbQ5p1hSUkKPHz8WXs+ePdPKOJSlic9fS8Nzzs2oVatWaNWqZR/anTt3cOnSJWGp1atUSaWoDEXzlSKRCO7u7ggJCcHp06cxZsyY1yJnQXMyNjaGiYmJ8Hqd/uxmTeu1mHN+9OgRoqOjkZWVhb/97W8gIrl3UeXm5uLEiRPIycnB6NGj8fHHHwvbHjx4gJiYGCxYsAA3btzA0aNH0a1bN3h5eQmBnoiQlJSEy5cvQ09PD/369cOECROU7kNZVVVVCAgIQGhoKP71r3/JbLe0tMTw4cOlympTKb46d1dUVIRdu3bB29tb5T83X+Xh4YF9+/bh+PHjSEtLwwcffABA/fMJNHxONXE+GWuJWvbXS7yce/373/+OQYMGITAwEEVFRThy5IhMcE5ISMDq1asxbNgw9O/fH66urpg3bx6Al6kfR4wYgUWLFmHbtm34/vvvkZqaipkzZ0pdVAwICMDdu3exaNEi2NraIiAgQOk+VBEYGIhFixYpTGTTuXNnub98Hjx4IPWkjtpUkpGRkSqPoa7aROnJyckANHM+gfrPqabOJ2MtkpbnVWRAxTmvkSNH0tKlS4X3NTU11KNHD+rTp49QJpFIqEePHlRaWiqUzZo1iwBQSkoKEREtX76cANCZM2eEOsOHD6cRI0YI7b711luUkJAgbF+zZo1KfSgjMTGRVq9eLbz39/eXO+dcV1JSEpmbm5NEIhHKSktLKTw8vMG54idPnsidc35VTEwMAaBJkyZp5HwS1X9ONXU+iXR2TlEnqfr5ex3o6M9HZIue1oiPj8f58+el/vQXiUSwtraWuip+8OBBPH/+HMuWLRPK8vLy0LNnT9y9exc2NjYKUz+ePHlSaLdv377w8PBASEgIXFxcsGTJEpX6aEhJSQmCgoJUXqupKJVibSpJTSgtLRXa1MT5BOo/p5o4n69KTU3F1KlTVT/wN9DmzZsRFRWl7WE0m9TUVJV/nppDiw7Ov//+OwBg4MCBUuV1/+S/fv06zMzMsH37dpXar5v6MSgoCFOnToWrqys+/vhjHDhwQJjLbWwfr/L394e1tTWOHTsmlP3xxx8oLy9HTEwMTExM8NFHH8nsp0wqRXVlZGQAAEaOHKmx8wkoPqeaOJ+MtWQtOjjXJp05f/68TIrAVwO0np4ebt++jaqqKujr6ze6v6FDhyIjIwPLly/Hzp07MXz4cFy9ehWdOnXSSB+FhYU4ffq0VNmTJ0/w7NkzLFy4EFZWVjLBWdlUiuogIiQnJ0NPTw8TJkzAvn37NHI+AcXnVFP/Z7VsbGzeqG+DjSUSieDv749p06ZpeyjNRlf/omrRFwQHDRoE4OX0Rn2GDBmCsrIy7NixQ6q8pKQEwcHBSvVVUVGBn376Ce3bt8f27dsRFxeHvLw84WGSmujjl19+QU5OjtRrzpw5MDU1RU5OjtSUAKBaKkV1+Pv7Iz09HRs3bsSQIUM0cqxA/edUU30w1mJpd85bFlS4IFFVVUX9+vUjIyMjSkpKIqL/196dR0V1pH8D/7Y0iwIBY1AxokaNRol7UNQ4YqJwIuBCcBAdl6jAiJhfXGOMmozjLjPRBFERxJhgBlRciMYtoKjBgOKOxhEiiIIsCoLSTbc87x8O96VZu+mGvo3P55ycY9etrqqu0A+XunWfS/TgwQOytbUlCwsLunr1KikUCpLJZGRnZ0cmJia0YcMGSklJocjISJowYYJwsWzBggUEgNLS0oT2XV1dydLSksrKyqikpISGDBlCZWVlRPTyYpaNjQ0dOHCAiEitPupj0aJF1V4QPHnyJA0aNIi+++474b9NmzaRr6+vkK3s4sWL5ODgoHLBrTpXr14lANSpUyeV8j///JP8/f1JIpHQ3LlzhXJdzCcR1TqnupxPkV7wESVNvn9NhUh/Pgw/K92ff/5JDg4OBIA6d+5MkyZNInd3d3r//fdp69atQmavlJQU6tatm5By0N7enpKTk4lIvdSPRUVFZGtrSxMnTqS9e/dSYGAgrVixQmUstfVRX9UFZ3VTKaqTSvLw4cPk5OQkvH/w4ME0atQocnV1pbFjx9KCBQsoKSmpyvu0nU+FQkElJSW1zqmu5lOkXz5R4uAsGlESojoedtbIJBIJIiMjNV7zys3NRYsWLWBubl5rgpn09HRIJBJ06NBB47EplUqUlZUhOzu71vdr04euPX36tEEzlmn7WdWZU237KF9T5DXnutX3+2fIRPrzsdegLwhWVDHVYm2Zvzp27FjvPsrvvqsrSFTXh7+/f53t+/r6Co+715WGTiWpzXwC6s2ptn0wZoiaTHAWuxEjRtRZp+IvGMYMjVKpRGJiIoYMGSKUPXz4EHv27EFOTg5cXFzg5OQEIyMjjdqtKzVucnIyWrVq1eR+iXNwbiRi3a7DmC4UFhYiODgYAQEBQtnNmzexZcsWLF++HOnp6ViwYAHu3buHhIQEtZeo/vjjDzg5OcHS0hLp6ekoLS3FunXrcO7cObRt2xbAy7S3c+fOhbe3N/7yl780yOfTB4PeSseYIdi9e7dBt1+XBw8eYMqUKfD391fJB7N69Wp069YNtra2cHR0xOrVq/Hw4UNs3LhR7bbnzZuH48eP486dO8jMzMSsWbOQmpqKL7/8UqgjlUoRFBSEdevW1fmwWUPCwZmxBhQbG1vtU2wMpX11zJ8/H+PHj4eVlZVKuZmZGUJDQ4XX5bdIZ2VlqdWuJqlxjYyMMH/+fPj6+mrzUUSFlzUYq0FRURGOHj2KW7duwc7ODs7OzsKdqDExMUhNTYWFhQVmzZqFoqIi7N69GwqFAra2tvDy8kJcXBzGjRsHiUSC7du3o127dnB3dwcAZGZm4vDhw5g9ezbOnDmD48eP480338TMmTPRvHlzrdrXVapYdSQmJuLIkSMqQbhccHAwHj16JLxOT08HoN71F0D91LjlRo4cic8++wzR0dHw8PDQ5GOIk74381WGV3CfJWtY9dnHeuXKFerVqxft37+fcnJyKDAwkCwsLOj7778X6tjb21P79u2F10+fPqXXXnuNBg8eTEREly9fpqFDh5KNjQ3FxcXR5cuXiYjoxx9/pJYtW1Lz5s3p73//O82YMYNGjx5NAMjBwYFKS0u1an/Hjh0EQLgZSROafv8+/vhjGjlypFp1161bRz179iS5XK7xuCpq27YtrVy5stpjvr6+1K9fP43aE+s+Z17WYKyS0tJSTJw4EePHj4eHhwdsbGywYMECjBkzBj4+PkhJSQEA9OjRQ+V9lpaW6Nq1q/C6b9++sLGxgZmZGZycnIRtkpMnT4arqytkMhkCAgIQFhaGI0eOYPny5UhKSsLOnTu1at/b2xt79uzB9OnTdT43lV27dg3t2rWrsx4RITw8HKGhoTAxMal3f/Hx8ZBKpZg3b161x+3t7XH9+vUm8cQeDs6MVXLs2DHcvn27ShpJFxcXlJaWIiwsTKP2qnswgrm5OaRSKezt7YWyJUuWQCqVIj4+Xqv2y1PF1vSwBl0pLS1FWloabG1t66x76tQpuLi4YPDgwfXur6bUuBVZWVlBqVTi7t279e5HLDg4M1ZJ+Zlx5QAwbNgwAMCtW7c0aq+64FydFi1aoH379sjNzW2Q9nXt8ePHePHihVrPRYyNjcXKlSu16k+d1Ljl/88yMzO16ksMODgzVsnrr78OAEhISFAp79ixI4yNjdGyZUuN2lM3eMrlcmRnZ6Nz584N0r6utW3bFtbW1igqKqqzbqdOnars5tCEuqlxnzx5AgBVUggbIg7OjFUyaNAgAKiyvHDjxg0oFArhT3OpVAqZTFZrWxKJBC9evFCr3wsXLkAmkwlPXNd1+w3B3t4eOTk5ddbz8/Ordx+apMbNysqCRCLBW2+9Ve/+xIKDM2OV9OnTB9OmTUN8fDwyMjKE8nPnzuHtt98W9tI6OzsjLy8P4eHhePbsGcLDw5Gfn4+0tDThDM7W1hbZ2dlIS0tDamoqnj17JrSnVCpVlkj27duH4cOHC8G5vu1funQJAwcOxOnTpxt6qjBs2LA6b/w4e/Ys3NzcVOaynK+vL0aPHq2y5a6iU6dOYf369VAoFAgKCkJQUBA2b94MPz8/XLt2rUr9e/fuwdnZGWZmZvX7QGKi7/0ilYG30jEdq89WqZKSEpozZw7Z29vTrl27KDQ0lFxdXSkjI0OoU1RURI6OjsLDcaOjo8nDw4NcXFyENK1xcXEklUrJ2tpaZWubn58fGRkZUUBAAC1atIgmTpxI7u7uKrmq69u+Oqlia6Lp9+/x48fUunVrunv3bo11AgMDSSKRUGxsbJVjXbp0IQAUGBhY5Zi6qXHLyeVyatWqFZ08eVLt8ROJdysdB2fW5Gnz5SsoKKDz58/T/fv3a6yTk5Mj/Ls8f3jlNio/IMDPz4+MjY2JiCgjI4MKCwt12n5t7dWmPt+/bdu20Zw5c2qtUzmQlpPJZBQZGUmHDh3SqM/qREVF0dixYzV+n1iDMy9rMFYLKysrDBkyBO3bt6+xTsVsgtX9OW1lZVXrtjY7O7taU7vWp/2GThVbkY+PD/Lz83H58uUa65RfZK1MLpcjISEBo0eP1moMt2/fRkREhMZPrhczDs6M6cHz58+hVCpRXFys76ForVmzZti1axe2bt2KpKQkjd6bmJiINWvWVHs7trrS09Oxdu1a7Ny5U61tfYaCgzNjjSwiIgInTpwAEeHzzz/HlStX9D0krZmamiIkJETjXB4jR47UOqCamJhg165dNZ6dGypOfMRYI3Nzc4Orq6vw2tTUVI+j0S19PJpNnTsUDREHZ8YamTY3Y7BXBy9rMMaYCHFwZowxEeLgzBhjIsTBmTHGREhCRKTvQVSkrwxbjLFXl6enJ/bu3avvYVS0V3S7NSIjI/U9BGaAEhISsGnTJv75YfUixhSjojtzZqw+oqKi4OXlBf5xZk3EXl5zZowxEeLgzBhjIsTBmTHGRIiDM2OMiRAHZ8YYEyEOzowxJkIcnBljTIQ4ODPGmAhxcGaMMRHi4MwYYyLEwZkxxkSIgzNjjIkQB2fGGBMhDs6MMSZCHJwZY0yEODgzxpgIcXBmjDER4uDMGGMixMGZMcZEiIMzY4yJEAdnxhgTIQ7OjDEmQhycGWNMhDg4M8aYCHFwZowxEeLgzBhjIsTBmTHGRIiDM2OMiRAHZ8YYEyEOzowxJkIcnBljTIQ4ODPGmAhJ9T0AxjSVm5uLAwcOqJRdvHgRABASEqJSbmlpCW9v70YbG2O6IiEi0vcgGNOEXC5H69atUVxcDCMjIwBA+Y+xRCIR6ikUCkybNg27du3SxzAZ08ZeXtZgBsfU1BSenp6QSqVQKBRQKBRQKpVQKpXCa4VCAQCYNGmSnkfLWP1wcGYGadKkSSgtLa21jrW1NT744INGGhFjusXBmRmkESNGwMbGpsbjxsbG+Nvf/gaplC+rMMPEwZkZpGbNmmHy5MkwNjau9rhCoeALgcygcXBmBsvb21tYW66sXbt2GDx4cCOPiDHd4eDMDNbAgQPRsWPHKuUmJiaYNm2ays4NxgwNB2dm0KZMmVJlaaO0tJSXNJjB4+DMDNrkyZOrLG107doVvXr10tOIGNMNDs7MoL3zzjvo2bOnsIRhbGyMTz75RM+jYkx7HJyZwZs6dapwp6BSqeQlDdYkcHBmBs/b2xsvXrwAAPTv3x9vvfWWnkfEmPY4ODOD16FDBwwaNAgAMG3aND2PhjHd0OvtU//+97+RkJCgzyGwJkIul0MikeDEiROIj4/X93BYEzB//ny97pXX65lzQkICLly4oM8hsCaiffv2aNOmDfLy8rBv3z59D8cgXLhwgb9/Ndi3bx/u37+v1zHoPfGAo6Mj9u7dq+9hsCbg7t27SE5OhpeXF/9MqWHChAkAwHNVDTHcwMRrzqzJ6Nq1q76HwJjOcHBmjDER4uDMGGMixMGZMcZEiIMzY4yJEAdnxqqRlpaGGTNmIDMzU99DMRhKpRK//fabStnDhw8RGBiIxYsX49dffxXu5NREUVERtm/fjiVLliA0NBTPnz9XOZ6cnIz09HStxi5GHJwZq0ZycjLCw8Nx/fp1fQ/FIBQWFmLjxo0q2QBv3ryJVatWYfLkyfDw8MCKFSvQoUMHZGRkqN3uH3/8gW7duuFf//oXvvnmG/j4+KB3797Izs4W6vTu3Rvr1q1rcjcfcXBmrBqenp7Izc3FRx99pNdx7N69W6/9q+PBgweYMmUK/P39YWlpKZSvXr0a3bp1g62tLRwdHbF69Wo8fPgQGzduVLvtefPm4fjx47hz5w4yMzMxa9YspKam4ssvvxTqSKVSBAUFYd26dU3qlykHZ8Zq8MYbb+i1/9jYWHzxxRd6HYM65s+fj/Hjx8PKykql3MzMDKGhocJrR0dHAEBWVpZa7V66dAmTJ09G7969AQA2NjZYuXIlmjVrVmX5xMjICPPnz4evr682H0VUODgzVo2ysjLExcUhKSlJKLt//z42b96MsrIy3LhxA6tXr8YPP/yAsrIyoU5mZiaCg4NBRDh9+jS++OILBAUFoaSkRKgTExODTZs2CYGrqKgIW7ZswaZNmxAZGQkAiIuLw7hx41BcXIzt27cjJiYGAJCXl4e1a9fi0aNHjTENdUpMTMSRI0fg6elZ5VhwcDCOHDkivC5fFx4xYoRabXfq1AmTJk1SKbO1tcWAAQPQsmXLKvVHjhyJoqIiREdHa/IRREvvt28zJjYpKSn46quvsG/fPmzduhUODg6IiYnBzJkzkZubCyLCtWvXkJubi2XLliEzMxNffPEFIiIiMHfuXMhkMly/fh2lpaXIzs7GunXrsHv3bpw/fx7GxsZwd3fHu+++i8LCQsyaNQuWlpaYOnUq2rdvD3t7e3h5eaFly5bo3bs37ty5g+7du8Pa2hoAcPDgQSxduhQWFhaYO3eunmcK2LBhAwYPHqyynFHOzMxM5RmPBw8eRM+ePeHj46NW261ataq2/P79+/D396/22NChQ7Fq1Sp4eHio1YeY8ZkzY5X07NkTK1asUClzd3fHzJkzAQC9evXCzp07ERMTg/79+2P//v0AXj4yy9XVFTKZDAEBAQgLC8ORI0ewfPlyJCUlYefOnUJ7PXr0UGnf0tJS5fbzvn37wsbGBmZmZnByckLfvn0BvMxdvWfPHkyfPr0hPrrGrl27hnbt2tVZj4gQHh6O0NBQmJiY1Lu/+Ph4SKVSzJs3r9rj9vb2wi9GQ8fBmbFqmJqaVilr3rw5gJePxirXs2dPld0H5ubmkEqlsLe3F8qWLFkCqVRar90ElRPwmJubw9vbu9oz1cZWWlqKtLQ02Nra1ln31KlTcHFx0SoF54sXL7BixQocPnwYFhYW1daxsrKCUqnE3bt3692PWHBwZkwLRkZGIKJa67Ro0QLt27dHbm6uxu2LITtaTR4/fowXL14Iv7RqExsbi5UrV2rV38KFCzF//nz069evxjrlQbsp7E/n4MxYA5PL5cjOzkbnzp01fq+Yg3Pbtm1hbW2NoqKiOut26tSpym4OTYSEhKBfv34YM2ZMrfWePHkCALCzs6t3X2LBwZmxBnbhwgXIZDK4ubkJZVKpFDKZrNb3SSSSet1R15js7e2Rk5NTZz0/P79693HgwAEQEaZOnapSfubMmSp1s7KyIJFImsRzJDk4M1YNuVwO4OXWtXJPnz4FAJWLTXl5eZDL5SpLG0qlErdu3RJe79u3D8OHD1cJzs7OzsjLy0N4eDiePXuG8PBw5OfnIy0tTTj7s7W1RXZ2NtLS0pCamopnz57h0qVLGDhwIE6fPt0gn1tTw4YNq/PGj7Nnz8LNza3aOwN9fX0xevToGrcGnjp1CuvXr4dCoUBQUBCCgoKwefNm+Pn54dq1a1Xq37t3D87OzjAzM6vfBxIT0iNPT0/y9PTU5xBYExMZGUna/lhfuHCBPD09CQC9++679PPPP9Pp06epc+fOBIBmzZpFWVlZ9NNPP9Frr71GAOjrr78mhUJBfn5+ZGRkRAEBAbRo0SKaOHEiubu709OnT1X6KCoqIkdHRwJAPXr0oOjoaPLw8CAXFxfasWMHERHFxcWRVCola2tr+vbbb4mIaP/+/SSRSIQ62tDF9+/x48fUunVrunv3bo11AgMDSSKRUGxsbJVjXbp0IQAUGBhY5dilS5fI3NycAFT5z8zMjPLz81Xqy+VyatWqFZ08eVKrz0REBIAiIyO1bkcLURycWZOii+CsDT8/PzI2NiYiooyMDCosLKy1fk5OjvDvkpKSKscLCgqqBPa62lSXrr5/27Ztozlz5tRap3IgLSeTySgyMpIOHTqk9TiioqJo7NixWrdDJI7gzMsajDUQOzs7vPbaa7XWsbGxEf5d3Z/iVlZWVbbN1dVmY/Px8UF+fj4uX75cY53XX3+92nK5XI6EhASMHj1aqzHcvn0bERER+Omnn7RqR0w4ODOmQ8+fP4dSqURxcbG+h9JomjVrhl27dmHr1q0qt7urIzExEWvWrIFUWv+bldPT07F27Vrs3LlTrW19hsLgb98uLi5GXFwczp07h/Xr1+t7OFrLz89HSEhIlYQ3BQUFCAsLQ0ZGBlxdXfHhhx/CyMhIo7bj4+Px4MEDlTJjY2PY2NigXbt2ePvtt7Ue/6ssIiICJ06cABHh888/h4+Pj3BnX1NnamqKkJAQjdKBAi/zYWjLxMQEu3btEvW2w/ow+DPnY8eO4dNPP8V//vMffQ9FJ2bNmoXNmzerlD1+/Bjvvfcerl69ihs3buCjjz7CkCFDNG67d+/eSE1NxaRJkzB9+nQ8ffoUubm5iImJgZeXF9566y0sW7YMCoVCVx/nleLm5obbt2/jyZMnWL16Nbp3767vITW6Dh06NHqftra2TS4wA03gzNnT0xN79+7FxYsX9T0Ure3YsQM3b96sUh4VFYXExERh3e6f//wnVqxYgfPnz2Po0KFqt29tbY3p06dj+fLl6NKli8reUyLC/v37MXPmTCQmJmL//v2iuEXYkGhzkwVjlRn8mTPwcs2rWTPD/ih37tzB5cuXVfbCAi/31Lq4uKhcUCnfjF+fC0M1vUcikcDT0xMhISE4efIkhg0b1iSSxzBmqAzyzPnx48fYt28f7t27h/feew9EVOXPmocPH+LYsWPIzMzE0KFD8eGHHwrH7t+/j+joaMydOxcpKSk4dOgQOnTogMmTJ6sEeSLCmTNncOXKFRgZGeGdd97BqFGj1OpDEwqFAsuWLUNYWBi++uorlWMmJiZV7na6du0a3NzcVB4JlJeXhx07dmDGjBlo06ZNvcYBAF5eXti9ezeOHj2KxMREvP/++8Ixbee0seaTsSZBnxv56rPP8vbt2+Tg4EC//fYbKRQK2r59O5mamlK3bt2EOrGxseTj40PJyckUFRVFFhYW5O/vT0REhw8fJhsbGwJA33zzDX3yySfk5uZGAGjNmjUqfS1dulTY7J+UlEQDBw5Uqw9NLVu2jM6fP09ERPPmzaM2bdpUW6+srIwiIyOpZ8+edP/+fZVjO3bsIADCzQo1KSwsFG58qMnKlSurzIcu5rQx5lPf+5wNCd9nUDOIYJ+zwQXnQYMG0aJFi4TXZWVl1LlzZyE4FxUVUefOnam4uFioM3PmTAJACQkJRES0ZMkSAkCnTp0S6vTv358GDBig0u4bb7xBcXFxQtmqVavU7kNdp0+fpq+//lp4XVNwLi4uJh8fH2rRogUBIGtra0pMTFQ5vmfPnio3LFSmTnCOjo4mAPTRRx8RkW7mtLHmk4Oz+jg410wMwdmgljViY2Px+++/q/zpL5FI4ODggCtXrgAAfvrpJ5SUlGDx4sVCnaysLHTp0gV3796Fo6NjjXl5jx8/rtJu9+7d4eXlhZCQEIwdOxaDpO6lAAAMgklEQVQLFy5Uuw91FBQUICgoSK2N8+bm5ggJCcG2bdvw7bffYuHChZg9e7ZwIbQ8z68ulO/RNTc3B6CbOW2M+ayoKV69byg8V+JkUMH56tWrAIB3331XpbziD9fNmzdha2uLLVu2aNR2dXl5g4KCMGHCBIwbNw4ffvghIiIi0KZNm3r3Udm8efPg4OCAw4cPC2X//e9/IZPJEB0dDWtra3zwwQcq72nWrBk+++wz/Pbbb9i/fz/kcnm1ieG1kZycDAAYNGgQAN3NaUPPZ0Xlz+JjNfvmm28AoManirzKvLy89D0EwwrO5VnBfv/99yr5WssDtJGREf744w8oFAoYGxtr1V/fvn2RnJyMJUuWYPv27ejfvz+uX7+usz5yc3Nx8uRJlbLCwkI8f/4cn376Kezt7asE53KjRo1CXFyczgMzEeHs2bMwMjISLtbp6vM29HxW9Ne//lUn7TRle/fuBcBzVR0xBGeD2n9WvjshNja2xjp9+vTBs2fPsG3bNpXygoICBAcHq92XXC7HDz/8AEtLS2zZsgVHjhxBVlYWoqOjddbHzz//jMzMTJX/Zs+eDRsbG2RmZqoss1R248YNuLu7q92XuubNm4dLly5h48aN6NOnDwDdzGljzCdjTYo+V7w1vSChUCjonXfeIQsLCzpz5gwRET148IBsbW3JwsKCrl69SsXFxWRnZ0cmJia0YcMGSklJocjISJowYYJwsWzBggUEgNLS0oS2XV1dydLSksrKyojoZYawIUOGCK/LysrIxsaGDhw4QDKZrM4+6mvRokUqFwSfP39Oq1atouvXrwtleXl5NGzYMCooKBDKLl68SA4ODioX3Kpz9epVAkCdOnVSKf/zzz/J39+fJBIJzZ07V+WYOp+3rjltrPnkC4Lq4wuCNYMILggaVHAmehlEHBwcCAB17tyZJk2aRO7u7vT+++/T1q1bqaSkhFJSUqhbt25C7ld7e3tKTk4mIlI7L29JSQnZ2trSxIkTae/evRQYGEgrVqwQxlFbH9qoHJyLi4upX79+JJFIyMHBgZYvX06bN2+moqIilfepk+f38OHD5OTkJIx58ODBNGrUKHJ1daWxY8fSggULKCkpqdr3ajunRUVFjTKfHJzVx8G5ZmIIzpL/DUQvJkyYAOD/r31pIjc3Fy1atIC5uTmKi4urfRpveno6JBJJve/3VyqVKCsrQ3Z2do1taNuHugoKCmBiYoIWLVrUWOfp06cNnk5Sm8/bGPMZFRUFLy+vOh+6yrT7/jV1EokEkZGR+lyP32tQFwQrqpgHt6bHpHfs2FGrPsrTGNYWKKrrw9/fv862fX19NcpYZm1tXWedxsjzq82c1nc+GXsVGWxwFrMRI0bUWafiLxfGDJFSqURiYqKQIfHhw4fYs2cPcnJy4OLiAicnJ43T2laUnZ2N27dvw8nJqcoxuVwupAJ4//33MWjQIKGv5ORktGrVyuB/0XNwbgDlfy4y1lQVFhYiODgYAQEBAF7uhd+yZQuWL1+O9PR0LFiwAPfu3UNCQoLGS1S5ublYv349goOD4ePjUyU45+TkwNHREUuXLsWMGTOwYcMGrFmzBocOHYKRkRF69+6NuXPnwtvbG3/5y1909ZEbnUFtpWPMEOzevdug26/LgwcPMGXKFPj7+wtpZVevXo1u3brB1tYWjo6OWL16NR4+fIiNGzdq3P69e/cwdepUlJSUVDlWVlaGjz/+GL169cKsWbPwxhtvYO3atbhx4wa+/PJLAC+Xz4KCgrBu3bo6nwwuZhycGdOh2NjYKk+xMaT21TF//nyMHz9eJX+1mZkZQkNDhdflt9xnZWVp3L6Dg4NKGoCK4uPjce7cOfj4+AhlRkZGmDZtGoKCgvDs2TOhbP78+fD19dW4f7HgZQ3GABQVFeHo0aO4desW7Ozs4OzsLNyFGhMTg9TUVFhYWGDWrFkoKirC7t27oVAoYGtrK9xNFhcXh3HjxkEikWD79u1o164d3N3dkZmZicOHD2P27Nk4c+YMjh8/jjfffBMzZ85E8+bNtW5fV+li1ZGYmIgjR46oBGIACA4OxqNHj4TX6enpANS7/qKJ6OhoAFBJlwu8TOnw7NkzHD16VFhWHDlyJD777DNER0fDw8NDp+NoDHzmzF55V69exdChQ2FsbIw5c+agoKAAPXv2FJYP3N3dERoain/84x8AAEtLS0ydOhVfffWVyiPFWrZsid69e8PU1BTdu3eHnZ0dIiIi0Lt3byxcuBD+/v744YcfcO3aNcydOxfDhw+HQqHQqn0AOHjwIJYuXYqoqKgGn6sNGzZg8ODBVZ6SY2ZmpnIB7uDBg+jZs6fKGa4u3L17F8DLR1NV1Lp1awAvH1pR0dChQ7Fq1SqdjqGxcHBmr7TS0lJMnDgR48ePh4eHB2xsbLBgwQKMGTMGPj4+SElJAQD06NFD5X2Wlpbo2rWrSlnfvn1hY2MDMzMzODk5oW/fvpg8eTJcXV0hk8kQEBCAsLAwHDlyBMuXL0dSUhJ27typVfsA4O3tjT179mD69Om6nJpqXbt2De3atau1DhEhPDwcoaGhMDEx0Wn/jx49gpGRUZV2y/f/V15Gsbe3x/Xr1w3yqT4cnNkr7dixY7h9+3aVtKQuLi4oLS1FWFiYxm1WTsFpbm4OqVQKe3t7oWzJkiWQSqWIj4/XSfve3t4N/szH0tJSpKWlVTlrrezUqVNwcXHB4MGDdT6Gmu5pePHiBQCgbdu2KuVWVlZQKpXCGbch4eDMXmnlZ8aVv/TDhg0DANy6dUvjNtXJj9yiRQu0b98eubm5DdJ+Q3j8+DFevHgh5O6uSWxsLFauXNkgY7Czs8OLFy8gl8tVyouKigC8zCFeUfn/18zMzAYZT0Pi4MxeaeUPzk1ISFAp79ixI4yNjdGyZUuN21QneMrlcmRnZ6Nz584N0n5DaNu2LaytrYVAWJNOnTo12JPIy5d/7t+/r1Kel5cHoGpwfvLkCQBUSTFsCDg4s1da+QMFKi8v3LhxAwqFQvjTXCqVQiaT1dmeRCIR/sSuzYULFyCTyYSnreu6/YZib2+PnJycWuv4+fk1WP8zZ86Eqakpzp8/r1J+6dIl9O3bF926dVMpz8rKgkQiqfKQZEPAwZm90vr06YNp06YhPj4eGRkZQvm5c+fw9ttvC/tknZ2dkZeXh/DwcDx79gzh4eHIz89HWlqacHYGvNxFkJ2djbS0NKSmpgr7bpVKpcoSyb59+zB8+HAhOGvT/qVLlzBw4ECcPn26IacKwMvlntpu7Dh79izc3NxU5rKcr68vRo8erbLlribln7nyL6y2bdsiICAAGzduFJJbyWQyxMTEICwsTHjSe7l79+7B2dkZZmZmdfYpNhyc2Stv27ZtmDp1KkaPHo3vv/8eYWFhOHr0KH799VdhV8CECRPg6OiIGTNmwMHBAdbW1hgwYAD69u2L/fv3C21NmDABRIQBAwbg6NGjwnMYmzVrhuDgYCxevBje3t5IT09HTEyMyvvq2356ejouXrzYKBe9Fi9ejIcPHyI1NbXa44mJiTh69Gi1x2NjY/HLL7/gxx9/rLWPX375Bf/3f/8H4OWWvNDQUGRnZwvHN27cCDc3N4wZMwbfffcdVq5ciWXLlqF///4q7ZSWluLQoUPCsyoNjh7zlXI+WaZz2uRzLigooPPnz9P9+/drrJOTkyP8u6SkpMZ2Kj4kwM/Pj4yNjYmIKCMjgwoLC3XaPhHV2mZN6vv927ZtG82ZM6fG4/n5+dWWy2QyioyMpEOHDmncZ3WUSiVlZ2fXeDwqKorGjh1br7YhgnzOfObM2P9YWVlhyJAhaN++fY11KmYTrOlPZSsrqxq3tdnZ2dWa2rW+7TdGuthyPj4+yM/Px+XLl6s9Xn6RtTK5XI6EhASMHj1aJ+MwMjKq8Y7I27dvIyIiQq0n24sVB2fGGtjz58+hVCpRXFys76HoRLNmzbBr1y5s3boVSUlJar8vMTERa9asEfJ6N5T09HSsXbsWO3furHPbn5hxcGasAUVERODEiRMgInz++ee4cuWKvoekE6ampggJCdEol8fIkSMbJViamJhg165dNZ7BGwpOfMRYA3Jzc4Orq6vw2tTUVI+j0b2GfjxbfdR1B6Oh4ODMWANqqJsxWNPHyxqMMSZCHJwZY0yEODgzxpgI6X3NOTMzs1GShLNXQ3kCI/6Zqlt5pjaeK3HSe3C+cOGC8BgexnSFf6bUx3MlTpL/3arIGGNMPPbymjNjjIkQB2fGGBMhDs6MMSZCHJwZY0yE/h+Ysoz2nJw0BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display best model\n",
    "best_model = grid_cv2.best_estimator_.model\n",
    "keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it with EvolutionaryAlgorithmSearchCV. Should take much less than 5 minutes--if only it didn't hang! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf2 = KerasClassifier(build_model2) # get a fresh model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/Users/EdwardArroyo/anaconda3/envs/laptop_env/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_cv2 = EvolutionaryAlgorithmSearchCV(estimator=keras_clf2,\n",
    "                                   params=param_grid2,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=1,\n",
    "                                   population_size=50,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting stuck for some reason\n",
    "# grid_cv2.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change of plan...Try it with our original build function...\n",
    "\n",
    "```python\n",
    "keras_clf3 = KerasClassifier(build_model)\n",
    "param_grid3 = {'n_hidden': range(1,5),'n_neurons': range(1,5)}\n",
    "```\n",
    "\n",
    "Also get stuck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': range(1, 10), 'n_neurons': range(1, 10)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid3 = {'n_hidden': range(1,10),'n_neurons': range(1,10)}\n",
    "param_grid3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf3 = KerasClassifier(build_model) # get a fresh model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv3 = EvolutionaryAlgorithmSearchCV(estimator=keras_clf3,\n",
    "                                   params=param_grid3,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   population_size=50,\n",
    "                                   gene_mutation_prob=0.10,\n",
    "                                   gene_crossover_prob=0.5,\n",
    "                                   tournament_size=3,\n",
    "                                   generations_number=5,\n",
    "                                   n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting stuck for some reason\n",
    "# grid_cv3.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing with GridSearchCV..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf3 = KerasClassifier(build_model) # get a fresh model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 2.0080 - accuracy: 0.2130 - val_loss: 1.8678 - val_accuracy: 0.2396\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.8102 - accuracy: 0.2573 - val_loss: 1.7450 - val_accuracy: 0.2816\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.7255 - accuracy: 0.2903 - val_loss: 1.6918 - val_accuracy: 0.3126\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.6802 - accuracy: 0.3109 - val_loss: 1.6549 - val_accuracy: 0.3362\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.6544 - accuracy: 0.3246 - val_loss: 1.6339 - val_accuracy: 0.3364\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.6379 - accuracy: 0.3333 - val_loss: 1.6206 - val_accuracy: 0.3476\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.6267 - accuracy: 0.3390 - val_loss: 1.6143 - val_accuracy: 0.3656\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.6185 - accuracy: 0.3541 - val_loss: 1.6076 - val_accuracy: 0.3730\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.6124 - accuracy: 0.3590 - val_loss: 1.5978 - val_accuracy: 0.3812\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.6074 - accuracy: 0.3642 - val_loss: 1.5930 - val_accuracy: 0.3916\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.6033 - accuracy: 0.3680 - val_loss: 1.5928 - val_accuracy: 0.4014\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.5998 - accuracy: 0.3754 - val_loss: 1.5891 - val_accuracy: 0.3968\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.5961 - accuracy: 0.3826 - val_loss: 1.5860 - val_accuracy: 0.4078\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.5929 - accuracy: 0.3898 - val_loss: 1.5840 - val_accuracy: 0.4164\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.5884 - accuracy: 0.4052 - val_loss: 1.5763 - val_accuracy: 0.4364\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.5803 - accuracy: 0.4194 - val_loss: 1.5720 - val_accuracy: 0.4422\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.5719 - accuracy: 0.4251 - val_loss: 1.5631 - val_accuracy: 0.4460\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5648 - accuracy: 0.4227 - val_loss: 1.5710 - val_accuracy: 0.4386\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.5580 - accuracy: 0.4231 - val_loss: 1.5541 - val_accuracy: 0.4418\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.5534 - accuracy: 0.4236 - val_loss: 1.5527 - val_accuracy: 0.4242\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.5483 - accuracy: 0.4222 - val_loss: 1.5555 - val_accuracy: 0.4470\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5453 - accuracy: 0.4196 - val_loss: 1.5456 - val_accuracy: 0.4376\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5421 - accuracy: 0.4228 - val_loss: 1.5443 - val_accuracy: 0.4270\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.5390 - accuracy: 0.4191 - val_loss: 1.5429 - val_accuracy: 0.4384\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.5365 - accuracy: 0.4175 - val_loss: 1.5417 - val_accuracy: 0.4320\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5349 - accuracy: 0.4177 - val_loss: 1.5412 - val_accuracy: 0.4284\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.5338 - accuracy: 0.4144 - val_loss: 1.5376 - val_accuracy: 0.4318\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.5331 - accuracy: 0.4181 - val_loss: 1.5490 - val_accuracy: 0.4172\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.5322 - accuracy: 0.4171 - val_loss: 1.5397 - val_accuracy: 0.4284\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 1.5722 - accuracy: 0.4114\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 2.0255 - accuracy: 0.2074 - val_loss: 1.8850 - val_accuracy: 0.2436\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.8381 - accuracy: 0.2612 - val_loss: 1.7693 - val_accuracy: 0.2956\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7537 - accuracy: 0.3060 - val_loss: 1.7083 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.7025 - accuracy: 0.3333 - val_loss: 1.6658 - val_accuracy: 0.3506\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.6651 - accuracy: 0.3495 - val_loss: 1.6387 - val_accuracy: 0.3718\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.6365 - accuracy: 0.3612 - val_loss: 1.6130 - val_accuracy: 0.3760\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.6162 - accuracy: 0.3690 - val_loss: 1.5974 - val_accuracy: 0.3792\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6012 - accuracy: 0.3745 - val_loss: 1.5845 - val_accuracy: 0.3886\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5911 - accuracy: 0.3764 - val_loss: 1.5733 - val_accuracy: 0.3918\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5822 - accuracy: 0.3743 - val_loss: 1.5716 - val_accuracy: 0.3952\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5753 - accuracy: 0.3788 - val_loss: 1.5624 - val_accuracy: 0.3832\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5703 - accuracy: 0.3802 - val_loss: 1.5603 - val_accuracy: 0.3978\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5657 - accuracy: 0.3851 - val_loss: 1.5533 - val_accuracy: 0.4054\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5609 - accuracy: 0.3840 - val_loss: 1.5514 - val_accuracy: 0.3942\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5576 - accuracy: 0.3801 - val_loss: 1.5504 - val_accuracy: 0.4002\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5551 - accuracy: 0.3841 - val_loss: 1.5640 - val_accuracy: 0.3862\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5522 - accuracy: 0.3833 - val_loss: 1.5456 - val_accuracy: 0.3944\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5499 - accuracy: 0.3807 - val_loss: 1.5420 - val_accuracy: 0.3942\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5477 - accuracy: 0.3796 - val_loss: 1.5419 - val_accuracy: 0.3976\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5463 - accuracy: 0.3830 - val_loss: 1.5421 - val_accuracy: 0.3958\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5446 - accuracy: 0.3813 - val_loss: 1.5418 - val_accuracy: 0.3940\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5427 - accuracy: 0.3845 - val_loss: 1.5384 - val_accuracy: 0.3966\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5408 - accuracy: 0.3833 - val_loss: 1.5379 - val_accuracy: 0.3958\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5391 - accuracy: 0.3850 - val_loss: 1.5396 - val_accuracy: 0.3952\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5382 - accuracy: 0.3871 - val_loss: 1.5384 - val_accuracy: 0.3950\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 1.5488 - accuracy: 0.3849\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 2.0565 - accuracy: 0.1876 - val_loss: 1.8902 - val_accuracy: 0.2084\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.8568 - accuracy: 0.2292 - val_loss: 1.7950 - val_accuracy: 0.2600\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.7895 - accuracy: 0.2709 - val_loss: 1.7502 - val_accuracy: 0.2898\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.7532 - accuracy: 0.2920 - val_loss: 1.7206 - val_accuracy: 0.3034\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.7273 - accuracy: 0.3072 - val_loss: 1.7031 - val_accuracy: 0.3216\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.7039 - accuracy: 0.3273 - val_loss: 1.6748 - val_accuracy: 0.3436\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.6750 - accuracy: 0.3475 - val_loss: 1.6458 - val_accuracy: 0.3498\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.6427 - accuracy: 0.3597 - val_loss: 1.6191 - val_accuracy: 0.3784\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6170 - accuracy: 0.3671 - val_loss: 1.5891 - val_accuracy: 0.3804\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.6017 - accuracy: 0.3709 - val_loss: 1.5796 - val_accuracy: 0.3832\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5918 - accuracy: 0.3741 - val_loss: 1.5702 - val_accuracy: 0.3824\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5853 - accuracy: 0.3751 - val_loss: 1.5626 - val_accuracy: 0.3890\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5805 - accuracy: 0.3771 - val_loss: 1.5577 - val_accuracy: 0.3944\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5771 - accuracy: 0.3784 - val_loss: 1.5574 - val_accuracy: 0.3794\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5742 - accuracy: 0.3776 - val_loss: 1.5569 - val_accuracy: 0.3954\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5721 - accuracy: 0.3799 - val_loss: 1.5510 - val_accuracy: 0.3884\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5697 - accuracy: 0.3800 - val_loss: 1.5551 - val_accuracy: 0.3934\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.5687 - accuracy: 0.3810 - val_loss: 1.5478 - val_accuracy: 0.3928\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5669 - accuracy: 0.3816 - val_loss: 1.5581 - val_accuracy: 0.3890\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 31us/sample - loss: 1.5663 - accuracy: 0.3815 - val_loss: 1.5446 - val_accuracy: 0.3920\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5647 - accuracy: 0.3831 - val_loss: 1.5477 - val_accuracy: 0.3840\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5641 - accuracy: 0.3834 - val_loss: 1.5440 - val_accuracy: 0.3968\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5636 - accuracy: 0.3824 - val_loss: 1.5518 - val_accuracy: 0.3934\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5625 - accuracy: 0.3845 - val_loss: 1.5421 - val_accuracy: 0.3940\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.5615 - accuracy: 0.3830 - val_loss: 1.5430 - val_accuracy: 0.3926\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.5610 - accuracy: 0.3834 - val_loss: 1.5437 - val_accuracy: 0.3952\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 1.5592 - accuracy: 0.3791\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.7705 - accuracy: 0.3038 - val_loss: 1.5086 - val_accuracy: 0.4236\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.3968 - accuracy: 0.4767 - val_loss: 1.2948 - val_accuracy: 0.5182\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.2543 - accuracy: 0.5270 - val_loss: 1.2006 - val_accuracy: 0.5586\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.1787 - accuracy: 0.5695 - val_loss: 1.1328 - val_accuracy: 0.5958\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 1.1231 - accuracy: 0.5968 - val_loss: 1.0783 - val_accuracy: 0.6138\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.0730 - accuracy: 0.6279 - val_loss: 1.0281 - val_accuracy: 0.6916\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.0264 - accuracy: 0.6792 - val_loss: 1.0025 - val_accuracy: 0.6984\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.0016 - accuracy: 0.6828 - val_loss: 0.9821 - val_accuracy: 0.7014\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.9863 - accuracy: 0.6847 - val_loss: 0.9721 - val_accuracy: 0.6992\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.9755 - accuracy: 0.6848 - val_loss: 0.9663 - val_accuracy: 0.6982\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.9675 - accuracy: 0.6877 - val_loss: 0.9601 - val_accuracy: 0.7030\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9609 - accuracy: 0.6885 - val_loss: 0.9558 - val_accuracy: 0.7032\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.9556 - accuracy: 0.6904 - val_loss: 0.9477 - val_accuracy: 0.7108\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.9506 - accuracy: 0.6901 - val_loss: 0.9437 - val_accuracy: 0.7042\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.9472 - accuracy: 0.6904 - val_loss: 0.9436 - val_accuracy: 0.7076\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9444 - accuracy: 0.6915 - val_loss: 0.9434 - val_accuracy: 0.7006\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.9408 - accuracy: 0.6909 - val_loss: 0.9454 - val_accuracy: 0.7060\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 32us/sample - loss: 0.9392 - accuracy: 0.6921 - val_loss: 0.9436 - val_accuracy: 0.7002\n",
      "18334/18334 [==============================] - 1s 37us/sample - loss: 0.9869 - accuracy: 0.6794\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.7770 - accuracy: 0.3206 - val_loss: 1.5127 - val_accuracy: 0.4820\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.4461 - accuracy: 0.4960 - val_loss: 1.3589 - val_accuracy: 0.5408\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.3393 - accuracy: 0.5397 - val_loss: 1.2787 - val_accuracy: 0.5582\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.2745 - accuracy: 0.5654 - val_loss: 1.2332 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.2197 - accuracy: 0.6032 - val_loss: 1.1766 - val_accuracy: 0.6250\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1656 - accuracy: 0.6253 - val_loss: 1.1288 - val_accuracy: 0.6442\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.1313 - accuracy: 0.6360 - val_loss: 1.1049 - val_accuracy: 0.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1091 - accuracy: 0.6405 - val_loss: 1.0888 - val_accuracy: 0.6532\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0935 - accuracy: 0.6454 - val_loss: 1.0849 - val_accuracy: 0.6584\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0814 - accuracy: 0.6503 - val_loss: 1.0658 - val_accuracy: 0.6608\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0723 - accuracy: 0.6542 - val_loss: 1.0572 - val_accuracy: 0.6646\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0644 - accuracy: 0.6551 - val_loss: 1.0556 - val_accuracy: 0.6580\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0582 - accuracy: 0.6584 - val_loss: 1.0476 - val_accuracy: 0.6660\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0524 - accuracy: 0.6599 - val_loss: 1.0408 - val_accuracy: 0.6696\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0474 - accuracy: 0.6598 - val_loss: 1.0395 - val_accuracy: 0.6670\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0434 - accuracy: 0.6613 - val_loss: 1.0345 - val_accuracy: 0.6642\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0391 - accuracy: 0.6592 - val_loss: 1.0313 - val_accuracy: 0.6586\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0361 - accuracy: 0.6534 - val_loss: 1.0324 - val_accuracy: 0.6556\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0332 - accuracy: 0.6548 - val_loss: 1.0270 - val_accuracy: 0.6598\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0308 - accuracy: 0.6579 - val_loss: 1.0314 - val_accuracy: 0.6606\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0279 - accuracy: 0.6582 - val_loss: 1.0244 - val_accuracy: 0.6576\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0247 - accuracy: 0.6593 - val_loss: 1.0193 - val_accuracy: 0.6652\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0224 - accuracy: 0.6618 - val_loss: 1.0237 - val_accuracy: 0.6662\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0196 - accuracy: 0.6614 - val_loss: 1.0153 - val_accuracy: 0.6724\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0170 - accuracy: 0.6629 - val_loss: 1.0138 - val_accuracy: 0.6708\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0154 - accuracy: 0.6650 - val_loss: 1.0112 - val_accuracy: 0.6694\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0128 - accuracy: 0.6673 - val_loss: 1.0105 - val_accuracy: 0.6748\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0097 - accuracy: 0.6675 - val_loss: 1.0098 - val_accuracy: 0.6804\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0070 - accuracy: 0.6672 - val_loss: 1.0093 - val_accuracy: 0.6742\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0052 - accuracy: 0.6672 - val_loss: 1.0064 - val_accuracy: 0.6762\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 1.0260 - accuracy: 0.6667\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7161 - accuracy: 0.3765 - val_loss: 1.4529 - val_accuracy: 0.4924\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.3322 - accuracy: 0.5520 - val_loss: 1.2368 - val_accuracy: 0.5842\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.1810 - accuracy: 0.6122 - val_loss: 1.1288 - val_accuracy: 0.6232\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.1046 - accuracy: 0.6388 - val_loss: 1.0707 - val_accuracy: 0.6430\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0626 - accuracy: 0.6484 - val_loss: 1.0415 - val_accuracy: 0.6494\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 1.0388 - accuracy: 0.6575 - val_loss: 1.0199 - val_accuracy: 0.6792\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0210 - accuracy: 0.6737 - val_loss: 1.0086 - val_accuracy: 0.6884\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 1.0087 - accuracy: 0.6819 - val_loss: 0.9970 - val_accuracy: 0.6972\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9974 - accuracy: 0.6852 - val_loss: 0.9861 - val_accuracy: 0.7004\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9898 - accuracy: 0.6904 - val_loss: 0.9792 - val_accuracy: 0.7014\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.9829 - accuracy: 0.6919 - val_loss: 0.9715 - val_accuracy: 0.7080\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 32us/sample - loss: 0.9768 - accuracy: 0.6951 - val_loss: 0.9699 - val_accuracy: 0.7046\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9722 - accuracy: 0.6996 - val_loss: 0.9647 - val_accuracy: 0.7080\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9682 - accuracy: 0.6997 - val_loss: 0.9595 - val_accuracy: 0.7108\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9649 - accuracy: 0.7013 - val_loss: 0.9594 - val_accuracy: 0.7110\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.9626 - accuracy: 0.7024 - val_loss: 0.9541 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9604 - accuracy: 0.7033 - val_loss: 0.9533 - val_accuracy: 0.7210\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9585 - accuracy: 0.7043 - val_loss: 0.9484 - val_accuracy: 0.7186\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9557 - accuracy: 0.7058 - val_loss: 0.9675 - val_accuracy: 0.7046\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.9551 - accuracy: 0.7053 - val_loss: 0.9502 - val_accuracy: 0.7240\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.9367 - accuracy: 0.7036\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.3780 - accuracy: 0.5135 - val_loss: 1.0430 - val_accuracy: 0.6624\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9786 - accuracy: 0.6786 - val_loss: 0.9117 - val_accuracy: 0.7028\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.8968 - accuracy: 0.7131 - val_loss: 0.8507 - val_accuracy: 0.7388\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.8552 - accuracy: 0.7312 - val_loss: 0.8175 - val_accuracy: 0.7512\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.8302 - accuracy: 0.7413 - val_loss: 0.7976 - val_accuracy: 0.7580\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.8130 - accuracy: 0.7453 - val_loss: 0.7842 - val_accuracy: 0.7668\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7996 - accuracy: 0.7527 - val_loss: 0.7766 - val_accuracy: 0.7668\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7873 - accuracy: 0.7592 - val_loss: 0.7613 - val_accuracy: 0.7770\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7772 - accuracy: 0.7641 - val_loss: 0.7478 - val_accuracy: 0.7874\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7665 - accuracy: 0.7704 - val_loss: 0.7424 - val_accuracy: 0.7876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7570 - accuracy: 0.7761 - val_loss: 0.7286 - val_accuracy: 0.7996\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7471 - accuracy: 0.7807 - val_loss: 0.7217 - val_accuracy: 0.7996\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7395 - accuracy: 0.7839 - val_loss: 0.7105 - val_accuracy: 0.7998\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7317 - accuracy: 0.7848 - val_loss: 0.7054 - val_accuracy: 0.8014\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7259 - accuracy: 0.7883 - val_loss: 0.7014 - val_accuracy: 0.8044\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.7191 - accuracy: 0.7889 - val_loss: 0.6961 - val_accuracy: 0.8078\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.7147 - accuracy: 0.7911 - val_loss: 0.6938 - val_accuracy: 0.8048\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7094 - accuracy: 0.7911 - val_loss: 0.6923 - val_accuracy: 0.8066\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.7055 - accuracy: 0.7925 - val_loss: 0.6820 - val_accuracy: 0.8056\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7018 - accuracy: 0.7942 - val_loss: 0.6805 - val_accuracy: 0.8070\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6979 - accuracy: 0.7951 - val_loss: 0.6784 - val_accuracy: 0.8030\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6942 - accuracy: 0.7956 - val_loss: 0.6757 - val_accuracy: 0.8106\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.6919 - accuracy: 0.7961 - val_loss: 0.6719 - val_accuracy: 0.8064\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6892 - accuracy: 0.7974 - val_loss: 0.6688 - val_accuracy: 0.8114\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6855 - accuracy: 0.7989 - val_loss: 0.6722 - val_accuracy: 0.8040\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.6834 - accuracy: 0.7990 - val_loss: 0.6793 - val_accuracy: 0.8060\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.7179 - accuracy: 0.7916\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.4667 - accuracy: 0.4512 - val_loss: 1.0704 - val_accuracy: 0.6610\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9882 - accuracy: 0.6759 - val_loss: 0.8909 - val_accuracy: 0.7088\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8772 - accuracy: 0.7110 - val_loss: 0.8298 - val_accuracy: 0.7294\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8306 - accuracy: 0.7335 - val_loss: 0.8012 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8053 - accuracy: 0.7442 - val_loss: 0.7866 - val_accuracy: 0.7548\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7864 - accuracy: 0.7503 - val_loss: 0.7693 - val_accuracy: 0.7650\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7710 - accuracy: 0.7553 - val_loss: 0.7556 - val_accuracy: 0.7700\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7586 - accuracy: 0.7598 - val_loss: 0.7526 - val_accuracy: 0.7700\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7491 - accuracy: 0.7628 - val_loss: 0.7578 - val_accuracy: 0.7666\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7420 - accuracy: 0.7636 - val_loss: 0.7460 - val_accuracy: 0.7668\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7355 - accuracy: 0.7654 - val_loss: 0.7366 - val_accuracy: 0.7754\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7294 - accuracy: 0.7648 - val_loss: 0.7345 - val_accuracy: 0.7702\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7235 - accuracy: 0.7686 - val_loss: 0.7250 - val_accuracy: 0.7730\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7179 - accuracy: 0.7691 - val_loss: 0.7256 - val_accuracy: 0.7702\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7123 - accuracy: 0.7708 - val_loss: 0.7225 - val_accuracy: 0.7786\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7076 - accuracy: 0.7726 - val_loss: 0.7194 - val_accuracy: 0.7764\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7020 - accuracy: 0.7736 - val_loss: 0.7130 - val_accuracy: 0.7808\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6974 - accuracy: 0.7749 - val_loss: 0.7157 - val_accuracy: 0.7788\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6927 - accuracy: 0.7764 - val_loss: 0.7060 - val_accuracy: 0.7790\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6880 - accuracy: 0.7793 - val_loss: 0.6967 - val_accuracy: 0.7818\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6835 - accuracy: 0.7803 - val_loss: 0.6930 - val_accuracy: 0.7820\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6793 - accuracy: 0.7826 - val_loss: 0.6892 - val_accuracy: 0.7810\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6746 - accuracy: 0.7836 - val_loss: 0.6843 - val_accuracy: 0.7854\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6708 - accuracy: 0.7868 - val_loss: 0.6854 - val_accuracy: 0.7840\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6670 - accuracy: 0.7880 - val_loss: 0.6831 - val_accuracy: 0.7890\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6635 - accuracy: 0.7882 - val_loss: 0.6713 - val_accuracy: 0.7898\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6604 - accuracy: 0.7927 - val_loss: 0.6674 - val_accuracy: 0.7904\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6578 - accuracy: 0.7946 - val_loss: 0.6696 - val_accuracy: 0.7952\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.6546 - accuracy: 0.7971 - val_loss: 0.6631 - val_accuracy: 0.7988\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6527 - accuracy: 0.7974 - val_loss: 0.6664 - val_accuracy: 0.8002\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.6975 - accuracy: 0.7819\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.3979 - accuracy: 0.5036 - val_loss: 1.0239 - val_accuracy: 0.6504\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9470 - accuracy: 0.6737 - val_loss: 0.8400 - val_accuracy: 0.7264\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.8311 - accuracy: 0.7214 - val_loss: 0.7717 - val_accuracy: 0.7510\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.7781 - accuracy: 0.7416 - val_loss: 0.7291 - val_accuracy: 0.7670\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 0.7487 - accuracy: 0.7523 - val_loss: 0.7114 - val_accuracy: 0.7792\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7302 - accuracy: 0.7617 - val_loss: 0.7007 - val_accuracy: 0.7788\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7168 - accuracy: 0.7667 - val_loss: 0.6850 - val_accuracy: 0.7920\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7072 - accuracy: 0.7729 - val_loss: 0.6769 - val_accuracy: 0.7916\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6992 - accuracy: 0.7757 - val_loss: 0.6714 - val_accuracy: 0.7942\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6929 - accuracy: 0.7791 - val_loss: 0.6624 - val_accuracy: 0.8002\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.6873 - accuracy: 0.7826 - val_loss: 0.6562 - val_accuracy: 0.8032\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.6830 - accuracy: 0.7839 - val_loss: 0.6549 - val_accuracy: 0.8036\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6787 - accuracy: 0.7871 - val_loss: 0.6509 - val_accuracy: 0.8034\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 0.6755 - accuracy: 0.7875 - val_loss: 0.6462 - val_accuracy: 0.8038\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6727 - accuracy: 0.7889 - val_loss: 0.6474 - val_accuracy: 0.8056\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6707 - accuracy: 0.7915 - val_loss: 0.6449 - val_accuracy: 0.8080\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6688 - accuracy: 0.7913 - val_loss: 0.6417 - val_accuracy: 0.8042\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6662 - accuracy: 0.7934 - val_loss: 0.6414 - val_accuracy: 0.8062\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6643 - accuracy: 0.7929 - val_loss: 0.6467 - val_accuracy: 0.8034\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6636 - accuracy: 0.7943 - val_loss: 0.6431 - val_accuracy: 0.8100\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.6570 - accuracy: 0.7956\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 1.3216 - accuracy: 0.5323 - val_loss: 0.8905 - val_accuracy: 0.7134\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8153 - accuracy: 0.7424 - val_loss: 0.6948 - val_accuracy: 0.7874\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7059 - accuracy: 0.7809 - val_loss: 0.6398 - val_accuracy: 0.8042\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.6632 - accuracy: 0.7950 - val_loss: 0.6116 - val_accuracy: 0.8124\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.6372 - accuracy: 0.8042 - val_loss: 0.5970 - val_accuracy: 0.8174\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6204 - accuracy: 0.8107 - val_loss: 0.5856 - val_accuracy: 0.8208\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6061 - accuracy: 0.8159 - val_loss: 0.5814 - val_accuracy: 0.8250\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5929 - accuracy: 0.8191 - val_loss: 0.5701 - val_accuracy: 0.8282\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5799 - accuracy: 0.8226 - val_loss: 0.5539 - val_accuracy: 0.8346\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5658 - accuracy: 0.8295 - val_loss: 0.5413 - val_accuracy: 0.8400\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5517 - accuracy: 0.8344 - val_loss: 0.5401 - val_accuracy: 0.8412\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5387 - accuracy: 0.8403 - val_loss: 0.5250 - val_accuracy: 0.8500\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5253 - accuracy: 0.8470 - val_loss: 0.5150 - val_accuracy: 0.8552\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5065 - accuracy: 0.8526 - val_loss: 0.4920 - val_accuracy: 0.8626\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4866 - accuracy: 0.8620 - val_loss: 0.4728 - val_accuracy: 0.8716\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4719 - accuracy: 0.8665 - val_loss: 0.4623 - val_accuracy: 0.8754\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4617 - accuracy: 0.8701 - val_loss: 0.4584 - val_accuracy: 0.8780\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.4560 - accuracy: 0.8718 - val_loss: 0.4600 - val_accuracy: 0.8782\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.4507 - accuracy: 0.8738 - val_loss: 0.4499 - val_accuracy: 0.8788\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 61us/sample - loss: 0.4470 - accuracy: 0.8747 - val_loss: 0.4556 - val_accuracy: 0.8774\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.4439 - accuracy: 0.8749 - val_loss: 0.4565 - val_accuracy: 0.8788\n",
      "18334/18334 [==============================] - 1s 30us/sample - loss: 0.4901 - accuracy: 0.8665\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1430 - accuracy: 0.5993 - val_loss: 0.7316 - val_accuracy: 0.7786\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6620 - accuracy: 0.7992 - val_loss: 0.5900 - val_accuracy: 0.8322\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5892 - accuracy: 0.8248 - val_loss: 0.5622 - val_accuracy: 0.8386\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5607 - accuracy: 0.8352 - val_loss: 0.5358 - val_accuracy: 0.8486\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5427 - accuracy: 0.8420 - val_loss: 0.5269 - val_accuracy: 0.8526\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5309 - accuracy: 0.8460 - val_loss: 0.5202 - val_accuracy: 0.8574\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5212 - accuracy: 0.8486 - val_loss: 0.5132 - val_accuracy: 0.8570\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5149 - accuracy: 0.8510 - val_loss: 0.5124 - val_accuracy: 0.8612\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5090 - accuracy: 0.8527 - val_loss: 0.5117 - val_accuracy: 0.8590\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5042 - accuracy: 0.8547 - val_loss: 0.5099 - val_accuracy: 0.8600\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5009 - accuracy: 0.8570 - val_loss: 0.5082 - val_accuracy: 0.8614\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4960 - accuracy: 0.8579 - val_loss: 0.5089 - val_accuracy: 0.8622\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4939 - accuracy: 0.8594 - val_loss: 0.5029 - val_accuracy: 0.8632\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4915 - accuracy: 0.8611 - val_loss: 0.5041 - val_accuracy: 0.8640\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4887 - accuracy: 0.8606 - val_loss: 0.5025 - val_accuracy: 0.8644\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4868 - accuracy: 0.8616 - val_loss: 0.5029 - val_accuracy: 0.8602\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4845 - accuracy: 0.8626 - val_loss: 0.5024 - val_accuracy: 0.8644\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4831 - accuracy: 0.8625 - val_loss: 0.4999 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.86 - 1s 39us/sample - loss: 0.4818 - accuracy: 0.8632 - val_loss: 0.5030 - val_accuracy: 0.8622\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4798 - accuracy: 0.8643 - val_loss: 0.5027 - val_accuracy: 0.8656\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.5349 - accuracy: 0.8507\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.3368 - accuracy: 0.5710 - val_loss: 0.8586 - val_accuracy: 0.7426\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.7560 - accuracy: 0.7779 - val_loss: 0.6668 - val_accuracy: 0.8072\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6643 - accuracy: 0.8063 - val_loss: 0.6230 - val_accuracy: 0.8162\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6315 - accuracy: 0.8173 - val_loss: 0.6062 - val_accuracy: 0.8196\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6105 - accuracy: 0.8251 - val_loss: 0.5834 - val_accuracy: 0.8316\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5964 - accuracy: 0.8299 - val_loss: 0.5778 - val_accuracy: 0.8324\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5858 - accuracy: 0.8323 - val_loss: 0.5685 - val_accuracy: 0.8356\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5774 - accuracy: 0.8345 - val_loss: 0.5572 - val_accuracy: 0.8388\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5710 - accuracy: 0.8364 - val_loss: 0.5583 - val_accuracy: 0.8366\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5650 - accuracy: 0.8381 - val_loss: 0.5527 - val_accuracy: 0.8406\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5598 - accuracy: 0.8416 - val_loss: 0.5466 - val_accuracy: 0.8446\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5556 - accuracy: 0.8422 - val_loss: 0.5488 - val_accuracy: 0.8448\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5523 - accuracy: 0.8435 - val_loss: 0.5411 - val_accuracy: 0.8476\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5479 - accuracy: 0.8456 - val_loss: 0.5410 - val_accuracy: 0.8498\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5457 - accuracy: 0.8447 - val_loss: 0.5390 - val_accuracy: 0.8510\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5425 - accuracy: 0.8477 - val_loss: 0.5370 - val_accuracy: 0.8524\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5392 - accuracy: 0.8488 - val_loss: 0.5334 - val_accuracy: 0.8566\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5367 - accuracy: 0.8484 - val_loss: 0.5318 - val_accuracy: 0.8530\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5334 - accuracy: 0.8496 - val_loss: 0.5396 - val_accuracy: 0.8552\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5325 - accuracy: 0.8511 - val_loss: 0.5310 - val_accuracy: 0.8576\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5299 - accuracy: 0.8513 - val_loss: 0.5292 - val_accuracy: 0.8604\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5284 - accuracy: 0.8514 - val_loss: 0.5343 - val_accuracy: 0.8582\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5265 - accuracy: 0.8522 - val_loss: 0.5280 - val_accuracy: 0.8562\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5247 - accuracy: 0.8538 - val_loss: 0.5248 - val_accuracy: 0.8562\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5225 - accuracy: 0.8540 - val_loss: 0.5287 - val_accuracy: 0.8588\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5217 - accuracy: 0.8537 - val_loss: 0.5260 - val_accuracy: 0.8602\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.5247 - accuracy: 0.8500\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.0025 - accuracy: 0.6893 - val_loss: 0.6480 - val_accuracy: 0.8126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5981 - accuracy: 0.8227 - val_loss: 0.5466 - val_accuracy: 0.8450\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5209 - accuracy: 0.8462 - val_loss: 0.4915 - val_accuracy: 0.8624\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4783 - accuracy: 0.8589 - val_loss: 0.4634 - val_accuracy: 0.8674\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4495 - accuracy: 0.8695 - val_loss: 0.4478 - val_accuracy: 0.8738\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4297 - accuracy: 0.8744 - val_loss: 0.4314 - val_accuracy: 0.8782\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4162 - accuracy: 0.8811 - val_loss: 0.4256 - val_accuracy: 0.8826\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4053 - accuracy: 0.8834 - val_loss: 0.4149 - val_accuracy: 0.8816\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3972 - accuracy: 0.8870 - val_loss: 0.4068 - val_accuracy: 0.8846\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3915 - accuracy: 0.8891 - val_loss: 0.4049 - val_accuracy: 0.8888\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3855 - accuracy: 0.8898 - val_loss: 0.4024 - val_accuracy: 0.8876\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3803 - accuracy: 0.8908 - val_loss: 0.4012 - val_accuracy: 0.8886\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3767 - accuracy: 0.8924 - val_loss: 0.3995 - val_accuracy: 0.8870\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3734 - accuracy: 0.8939 - val_loss: 0.3933 - val_accuracy: 0.8916\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3707 - accuracy: 0.8944 - val_loss: 0.3823 - val_accuracy: 0.8956\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3673 - accuracy: 0.8947 - val_loss: 0.3793 - val_accuracy: 0.8952\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3644 - accuracy: 0.8976 - val_loss: 0.3802 - val_accuracy: 0.8980\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3626 - accuracy: 0.8984 - val_loss: 0.3857 - val_accuracy: 0.8968\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.4111 - accuracy: 0.8857\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.0330 - accuracy: 0.6668 - val_loss: 0.6333 - val_accuracy: 0.8090\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5754 - accuracy: 0.8318 - val_loss: 0.5032 - val_accuracy: 0.8554\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.4932 - accuracy: 0.8597 - val_loss: 0.4493 - val_accuracy: 0.8722\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4569 - accuracy: 0.8708 - val_loss: 0.4254 - val_accuracy: 0.8818\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4348 - accuracy: 0.8784 - val_loss: 0.4089 - val_accuracy: 0.8908\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4211 - accuracy: 0.8820 - val_loss: 0.4022 - val_accuracy: 0.8882\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4114 - accuracy: 0.8854 - val_loss: 0.3921 - val_accuracy: 0.8962\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4039 - accuracy: 0.8874 - val_loss: 0.3945 - val_accuracy: 0.8958\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3984 - accuracy: 0.8894 - val_loss: 0.3979 - val_accuracy: 0.8942\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.4437 - accuracy: 0.8780\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.1211 - accuracy: 0.6566 - val_loss: 0.7613 - val_accuracy: 0.7840\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.7184 - accuracy: 0.7896 - val_loss: 0.6365 - val_accuracy: 0.8242\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6221 - accuracy: 0.8224 - val_loss: 0.5698 - val_accuracy: 0.8466\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.5663 - accuracy: 0.8393 - val_loss: 0.5319 - val_accuracy: 0.8550\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5297 - accuracy: 0.8501 - val_loss: 0.5003 - val_accuracy: 0.8644\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5050 - accuracy: 0.8576 - val_loss: 0.4803 - val_accuracy: 0.8686\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4852 - accuracy: 0.8624 - val_loss: 0.4623 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4701 - accuracy: 0.8669 - val_loss: 0.4524 - val_accuracy: 0.8792\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4583 - accuracy: 0.8712 - val_loss: 0.4433 - val_accuracy: 0.8828\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4478 - accuracy: 0.8747 - val_loss: 0.4312 - val_accuracy: 0.8850\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4378 - accuracy: 0.8774 - val_loss: 0.4203 - val_accuracy: 0.8900\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4291 - accuracy: 0.8809 - val_loss: 0.4114 - val_accuracy: 0.8892\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4214 - accuracy: 0.8845 - val_loss: 0.4093 - val_accuracy: 0.8922\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4148 - accuracy: 0.8870 - val_loss: 0.4067 - val_accuracy: 0.8932\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4085 - accuracy: 0.8897 - val_loss: 0.3982 - val_accuracy: 0.8944\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4041 - accuracy: 0.8915 - val_loss: 0.3964 - val_accuracy: 0.8958\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3995 - accuracy: 0.8925 - val_loss: 0.3965 - val_accuracy: 0.8966\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3963 - accuracy: 0.8937 - val_loss: 0.3934 - val_accuracy: 0.8940\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3925 - accuracy: 0.8944 - val_loss: 0.3990 - val_accuracy: 0.8948\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3899 - accuracy: 0.8955 - val_loss: 0.3930 - val_accuracy: 0.8974\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3880 - accuracy: 0.8959 - val_loss: 0.3926 - val_accuracy: 0.8972\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3853 - accuracy: 0.8962 - val_loss: 0.3930 - val_accuracy: 0.8986\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3835 - accuracy: 0.8969 - val_loss: 0.3959 - val_accuracy: 0.8954\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3933 - accuracy: 0.8916\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.9713 - accuracy: 0.7002 - val_loss: 0.5704 - val_accuracy: 0.8408\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.5297 - accuracy: 0.8475 - val_loss: 0.4807 - val_accuracy: 0.8648\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4753 - accuracy: 0.8629 - val_loss: 0.4441 - val_accuracy: 0.8754\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4502 - accuracy: 0.8715 - val_loss: 0.4321 - val_accuracy: 0.8832\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4335 - accuracy: 0.8765 - val_loss: 0.4245 - val_accuracy: 0.8832\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4226 - accuracy: 0.8791 - val_loss: 0.4184 - val_accuracy: 0.8846\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4142 - accuracy: 0.8840 - val_loss: 0.4202 - val_accuracy: 0.8846\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4073 - accuracy: 0.8852 - val_loss: 0.4077 - val_accuracy: 0.8868\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4020 - accuracy: 0.8866 - val_loss: 0.4070 - val_accuracy: 0.8868\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3972 - accuracy: 0.8888 - val_loss: 0.4071 - val_accuracy: 0.8896\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3934 - accuracy: 0.8895 - val_loss: 0.4048 - val_accuracy: 0.8916\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3898 - accuracy: 0.8914 - val_loss: 0.4039 - val_accuracy: 0.8896\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3872 - accuracy: 0.8926 - val_loss: 0.4027 - val_accuracy: 0.8866\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3847 - accuracy: 0.8932 - val_loss: 0.3973 - val_accuracy: 0.8900\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3824 - accuracy: 0.8941 - val_loss: 0.3945 - val_accuracy: 0.8946\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3798 - accuracy: 0.8943 - val_loss: 0.3945 - val_accuracy: 0.8926\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3783 - accuracy: 0.8952 - val_loss: 0.3949 - val_accuracy: 0.8916\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3773 - accuracy: 0.8959 - val_loss: 0.3960 - val_accuracy: 0.8932\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.4357 - accuracy: 0.8817\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.8451 - accuracy: 0.7419 - val_loss: 0.4728 - val_accuracy: 0.8712\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4653 - accuracy: 0.8638 - val_loss: 0.4091 - val_accuracy: 0.8848\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4166 - accuracy: 0.8804 - val_loss: 0.3835 - val_accuracy: 0.8950\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3899 - accuracy: 0.8887 - val_loss: 0.3628 - val_accuracy: 0.9002\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3702 - accuracy: 0.8944 - val_loss: 0.3555 - val_accuracy: 0.9006\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3560 - accuracy: 0.8988 - val_loss: 0.3452 - val_accuracy: 0.9044\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3445 - accuracy: 0.9033 - val_loss: 0.3394 - val_accuracy: 0.9058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3365 - accuracy: 0.9056 - val_loss: 0.3446 - val_accuracy: 0.9044\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3302 - accuracy: 0.9071 - val_loss: 0.3384 - val_accuracy: 0.9076\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3247 - accuracy: 0.9100 - val_loss: 0.3345 - val_accuracy: 0.9070\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3213 - accuracy: 0.9110 - val_loss: 0.3302 - val_accuracy: 0.9086\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3164 - accuracy: 0.9127 - val_loss: 0.3376 - val_accuracy: 0.9074\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3142 - accuracy: 0.9128 - val_loss: 0.3312 - val_accuracy: 0.9064\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.3715 - accuracy: 0.8984\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.8756 - accuracy: 0.7322 - val_loss: 0.5393 - val_accuracy: 0.8516\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4968 - accuracy: 0.8574 - val_loss: 0.4559 - val_accuracy: 0.8720\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4397 - accuracy: 0.8752 - val_loss: 0.4154 - val_accuracy: 0.8850\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4091 - accuracy: 0.8847 - val_loss: 0.3902 - val_accuracy: 0.8900\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3870 - accuracy: 0.8918 - val_loss: 0.3743 - val_accuracy: 0.8990\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3711 - accuracy: 0.8988 - val_loss: 0.3633 - val_accuracy: 0.9008\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3588 - accuracy: 0.9030 - val_loss: 0.3474 - val_accuracy: 0.9052\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3503 - accuracy: 0.9033 - val_loss: 0.3513 - val_accuracy: 0.9042\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3442 - accuracy: 0.9054 - val_loss: 0.3449 - val_accuracy: 0.9046\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3394 - accuracy: 0.9069 - val_loss: 0.3402 - val_accuracy: 0.9064\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3352 - accuracy: 0.9077 - val_loss: 0.3400 - val_accuracy: 0.9064\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3327 - accuracy: 0.9080 - val_loss: 0.3331 - val_accuracy: 0.9054\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3300 - accuracy: 0.9100 - val_loss: 0.3372 - val_accuracy: 0.9064\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3277 - accuracy: 0.9106 - val_loss: 0.3324 - val_accuracy: 0.9102\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3256 - accuracy: 0.9117 - val_loss: 0.3323 - val_accuracy: 0.9086\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3241 - accuracy: 0.9113 - val_loss: 0.3365 - val_accuracy: 0.9080\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3218 - accuracy: 0.9128 - val_loss: 0.3328 - val_accuracy: 0.9064\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3401 - accuracy: 0.9057\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.9112 - accuracy: 0.7166 - val_loss: 0.5314 - val_accuracy: 0.8476\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5046 - accuracy: 0.8542 - val_loss: 0.4526 - val_accuracy: 0.8754\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.4464 - accuracy: 0.8738 - val_loss: 0.4130 - val_accuracy: 0.8870\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4109 - accuracy: 0.8841 - val_loss: 0.3894 - val_accuracy: 0.8922\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3839 - accuracy: 0.8927 - val_loss: 0.3707 - val_accuracy: 0.8990\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3654 - accuracy: 0.8988 - val_loss: 0.3573 - val_accuracy: 0.8992\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3530 - accuracy: 0.9032 - val_loss: 0.3485 - val_accuracy: 0.9044\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3441 - accuracy: 0.9065 - val_loss: 0.3396 - val_accuracy: 0.9076\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3364 - accuracy: 0.9073 - val_loss: 0.3381 - val_accuracy: 0.9048\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3310 - accuracy: 0.9099 - val_loss: 0.3362 - val_accuracy: 0.9072\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3265 - accuracy: 0.9108 - val_loss: 0.3294 - val_accuracy: 0.9110\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.3229 - accuracy: 0.9120 - val_loss: 0.3377 - val_accuracy: 0.9076\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.3205 - accuracy: 0.9122 - val_loss: 0.3344 - val_accuracy: 0.9090\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3699 - accuracy: 0.9021\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.8749 - accuracy: 0.7339 - val_loss: 0.4218 - val_accuracy: 0.8784\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3829 - accuracy: 0.8899 - val_loss: 0.3335 - val_accuracy: 0.9082\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.3348 - accuracy: 0.9056 - val_loss: 0.3163 - val_accuracy: 0.9132\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3162 - accuracy: 0.9117 - val_loss: 0.2999 - val_accuracy: 0.9150\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3047 - accuracy: 0.9144 - val_loss: 0.2956 - val_accuracy: 0.9176\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2964 - accuracy: 0.9178 - val_loss: 0.2903 - val_accuracy: 0.9218\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.2901 - accuracy: 0.9190 - val_loss: 0.2887 - val_accuracy: 0.9200\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2844 - accuracy: 0.9208 - val_loss: 0.2923 - val_accuracy: 0.9210\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 33us/sample - loss: 0.2807 - accuracy: 0.9225 - val_loss: 0.2966 - val_accuracy: 0.9178\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.3275 - accuracy: 0.9076\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.8288 - accuracy: 0.7573 - val_loss: 0.4484 - val_accuracy: 0.8744\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4406 - accuracy: 0.8738 - val_loss: 0.3815 - val_accuracy: 0.8910\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3993 - accuracy: 0.8867 - val_loss: 0.3559 - val_accuracy: 0.8986\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 0.3806 - accuracy: 0.8920 - val_loss: 0.3435 - val_accuracy: 0.9000\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3672 - accuracy: 0.8962 - val_loss: 0.3348 - val_accuracy: 0.9046\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3583 - accuracy: 0.9000 - val_loss: 0.3361 - val_accuracy: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3509 - accuracy: 0.9013 - val_loss: 0.3229 - val_accuracy: 0.9046\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3459 - accuracy: 0.9021 - val_loss: 0.3265 - val_accuracy: 0.9078\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3416 - accuracy: 0.9048 - val_loss: 0.3268 - val_accuracy: 0.9036\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.3426 - accuracy: 0.9020\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6868 - accuracy: 0.7974 - val_loss: 0.3598 - val_accuracy: 0.9034\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3489 - accuracy: 0.9002 - val_loss: 0.3111 - val_accuracy: 0.9116\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3149 - accuracy: 0.9091 - val_loss: 0.2899 - val_accuracy: 0.9166\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2987 - accuracy: 0.9144 - val_loss: 0.2849 - val_accuracy: 0.9172\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2882 - accuracy: 0.9169 - val_loss: 0.2773 - val_accuracy: 0.9228\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2807 - accuracy: 0.9198 - val_loss: 0.2721 - val_accuracy: 0.9216\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2757 - accuracy: 0.9209 - val_loss: 0.2753 - val_accuracy: 0.9222\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.2704 - accuracy: 0.9239 - val_loss: 0.2675 - val_accuracy: 0.9234\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 33us/sample - loss: 0.2662 - accuracy: 0.9239 - val_loss: 0.2653 - val_accuracy: 0.9220\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2632 - accuracy: 0.9255 - val_loss: 0.2677 - val_accuracy: 0.9232\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.2595 - accuracy: 0.9246 - val_loss: 0.2659 - val_accuracy: 0.9252\n",
      "18334/18334 [==============================] - 1s 37us/sample - loss: 0.3031 - accuracy: 0.9140\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7347 - accuracy: 0.7844 - val_loss: 0.3892 - val_accuracy: 0.8886\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3654 - accuracy: 0.8958 - val_loss: 0.3223 - val_accuracy: 0.9072\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3245 - accuracy: 0.9087 - val_loss: 0.3055 - val_accuracy: 0.9160\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3068 - accuracy: 0.9121 - val_loss: 0.2971 - val_accuracy: 0.9166\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2951 - accuracy: 0.9173 - val_loss: 0.2955 - val_accuracy: 0.9182\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2870 - accuracy: 0.9187 - val_loss: 0.2895 - val_accuracy: 0.9188\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2800 - accuracy: 0.9206 - val_loss: 0.2861 - val_accuracy: 0.9200\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2742 - accuracy: 0.9234 - val_loss: 0.2904 - val_accuracy: 0.9240\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2696 - accuracy: 0.9244 - val_loss: 0.2882 - val_accuracy: 0.9208\n",
      "18333/18333 [==============================] - 0s 21us/sample - loss: 0.3152 - accuracy: 0.9116\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6429 - accuracy: 0.8247 - val_loss: 0.3597 - val_accuracy: 0.8986\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.3544 - accuracy: 0.8996 - val_loss: 0.3158 - val_accuracy: 0.9142\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3229 - accuracy: 0.9093 - val_loss: 0.2985 - val_accuracy: 0.9214\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3048 - accuracy: 0.9146 - val_loss: 0.2910 - val_accuracy: 0.9222\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2938 - accuracy: 0.9181 - val_loss: 0.2832 - val_accuracy: 0.9258\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2856 - accuracy: 0.9209 - val_loss: 0.2930 - val_accuracy: 0.9190\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2800 - accuracy: 0.9222 - val_loss: 0.2764 - val_accuracy: 0.9274\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2749 - accuracy: 0.9233 - val_loss: 0.2798 - val_accuracy: 0.9260\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2723 - accuracy: 0.9253 - val_loss: 0.2763 - val_accuracy: 0.9230\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2689 - accuracy: 0.9260 - val_loss: 0.2815 - val_accuracy: 0.9242\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2654 - accuracy: 0.9266 - val_loss: 0.2802 - val_accuracy: 0.9242\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.2917 - accuracy: 0.9198\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6551 - accuracy: 0.8184 - val_loss: 0.3937 - val_accuracy: 0.8886\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.3643 - accuracy: 0.8993 - val_loss: 0.3335 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3172 - accuracy: 0.9107 - val_loss: 0.2988 - val_accuracy: 0.9158\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2952 - accuracy: 0.9168 - val_loss: 0.2886 - val_accuracy: 0.9190\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.2821 - accuracy: 0.9210 - val_loss: 0.2816 - val_accuracy: 0.9202\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2736 - accuracy: 0.9236 - val_loss: 0.2815 - val_accuracy: 0.9216\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2684 - accuracy: 0.9261 - val_loss: 0.2757 - val_accuracy: 0.9248\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2636 - accuracy: 0.9285 - val_loss: 0.2740 - val_accuracy: 0.9258\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2594 - accuracy: 0.9292 - val_loss: 0.2711 - val_accuracy: 0.9260\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2566 - accuracy: 0.9298 - val_loss: 0.2733 - val_accuracy: 0.9280\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2532 - accuracy: 0.9306 - val_loss: 0.2789 - val_accuracy: 0.9260\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.3036 - accuracy: 0.9193\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7041 - accuracy: 0.7930 - val_loss: 0.3752 - val_accuracy: 0.8944\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3559 - accuracy: 0.8981 - val_loss: 0.3163 - val_accuracy: 0.9114\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3140 - accuracy: 0.9118 - val_loss: 0.3048 - val_accuracy: 0.9158\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2958 - accuracy: 0.9176 - val_loss: 0.2905 - val_accuracy: 0.9180\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2844 - accuracy: 0.9223 - val_loss: 0.2916 - val_accuracy: 0.9180\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.2766 - accuracy: 0.9239 - val_loss: 0.2827 - val_accuracy: 0.9224\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2704 - accuracy: 0.9271 - val_loss: 0.2804 - val_accuracy: 0.9220\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2655 - accuracy: 0.9285 - val_loss: 0.2878 - val_accuracy: 0.9214\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2611 - accuracy: 0.9296 - val_loss: 0.2857 - val_accuracy: 0.9232\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3075 - accuracy: 0.9168\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7080 - accuracy: 0.7977 - val_loss: 0.3761 - val_accuracy: 0.8962\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3611 - accuracy: 0.8975 - val_loss: 0.3087 - val_accuracy: 0.9140\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3181 - accuracy: 0.9099 - val_loss: 0.2889 - val_accuracy: 0.9208\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2983 - accuracy: 0.9146 - val_loss: 0.2826 - val_accuracy: 0.9202\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2862 - accuracy: 0.9194 - val_loss: 0.2711 - val_accuracy: 0.9282\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2770 - accuracy: 0.9222 - val_loss: 0.2812 - val_accuracy: 0.9248\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2697 - accuracy: 0.9237 - val_loss: 0.2627 - val_accuracy: 0.9280\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2646 - accuracy: 0.9245 - val_loss: 0.2690 - val_accuracy: 0.9264262\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2600 - accuracy: 0.9256 - val_loss: 0.2642 - val_accuracy: 0.9276\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.2822 - accuracy: 0.9215\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.8313 - accuracy: 0.3274 - val_loss: 1.5364 - val_accuracy: 0.4320\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.4310 - accuracy: 0.4652 - val_loss: 1.3380 - val_accuracy: 0.5094\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.2765 - accuracy: 0.5498 - val_loss: 1.1970 - val_accuracy: 0.6020\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.1632 - accuracy: 0.6019 - val_loss: 1.1249 - val_accuracy: 0.6178\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.1082 - accuracy: 0.6256 - val_loss: 1.0784 - val_accuracy: 0.6480\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.0743 - accuracy: 0.6382 - val_loss: 1.0584 - val_accuracy: 0.6586\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.0540 - accuracy: 0.6467 - val_loss: 1.0583 - val_accuracy: 0.6516\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 1.0373 - accuracy: 0.6546 - val_loss: 1.0418 - val_accuracy: 0.6620\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.0253 - accuracy: 0.6597 - val_loss: 1.0252 - val_accuracy: 0.6772\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0161 - accuracy: 0.6610 - val_loss: 1.0214 - val_accuracy: 0.6818\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0077 - accuracy: 0.6658 - val_loss: 1.0197 - val_accuracy: 0.6838\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0013 - accuracy: 0.6699 - val_loss: 1.0153 - val_accuracy: 0.6768\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9955 - accuracy: 0.6736 - val_loss: 1.0049 - val_accuracy: 0.6744\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.9903 - accuracy: 0.6751 - val_loss: 1.0283 - val_accuracy: 0.6724\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9869 - accuracy: 0.6765 - val_loss: 1.0038 - val_accuracy: 0.6798\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9824 - accuracy: 0.6786 - val_loss: 0.9959 - val_accuracy: 0.6880\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.9790 - accuracy: 0.6798 - val_loss: 1.0162 - val_accuracy: 0.6758\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9762 - accuracy: 0.6803 - val_loss: 0.9932 - val_accuracy: 0.6812\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.9737 - accuracy: 0.6818 - val_loss: 0.9850 - val_accuracy: 0.6886\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9712 - accuracy: 0.6833 - val_loss: 0.9860 - val_accuracy: 0.6890\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9684 - accuracy: 0.6852 - val_loss: 0.9915 - val_accuracy: 0.6836\n",
      "18334/18334 [==============================] - 1s 31us/sample - loss: 1.0121 - accuracy: 0.6687\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.6685 - accuracy: 0.3950 - val_loss: 1.3928 - val_accuracy: 0.5320\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.3043 - accuracy: 0.5563 - val_loss: 1.2157 - val_accuracy: 0.6054\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.2004 - accuracy: 0.5891 - val_loss: 1.1550 - val_accuracy: 0.6118\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.1595 - accuracy: 0.5985 - val_loss: 1.1229 - val_accuracy: 0.6230\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.1359 - accuracy: 0.6097 - val_loss: 1.1020 - val_accuracy: 0.6260\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1172 - accuracy: 0.6207 - val_loss: 1.0841 - val_accuracy: 0.6396\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1024 - accuracy: 0.6273 - val_loss: 1.0729 - val_accuracy: 0.6472\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0908 - accuracy: 0.6346 - val_loss: 1.0651 - val_accuracy: 0.6438\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0815 - accuracy: 0.6415 - val_loss: 1.0533 - val_accuracy: 0.6506\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0729 - accuracy: 0.6444 - val_loss: 1.0397 - val_accuracy: 0.6682\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0660 - accuracy: 0.6465 - val_loss: 1.0354 - val_accuracy: 0.6722\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0603 - accuracy: 0.6530 - val_loss: 1.0328 - val_accuracy: 0.6704\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0544 - accuracy: 0.6549 - val_loss: 1.0269 - val_accuracy: 0.6782\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0493 - accuracy: 0.6570 - val_loss: 1.0215 - val_accuracy: 0.6758\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0449 - accuracy: 0.6606 - val_loss: 1.0141 - val_accuracy: 0.6788\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0414 - accuracy: 0.6621 - val_loss: 1.0132 - val_accuracy: 0.6790\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0376 - accuracy: 0.6617 - val_loss: 1.0100 - val_accuracy: 0.6882\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0349 - accuracy: 0.6654 - val_loss: 1.0086 - val_accuracy: 0.6820\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0313 - accuracy: 0.6662 - val_loss: 1.0088 - val_accuracy: 0.6802\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0297 - accuracy: 0.6668 - val_loss: 1.0083 - val_accuracy: 0.6902\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 1.0269 - accuracy: 0.6692 - val_loss: 1.0012 - val_accuracy: 0.6850\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0250 - accuracy: 0.6680 - val_loss: 1.0007 - val_accuracy: 0.6876\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0237 - accuracy: 0.6697 - val_loss: 1.0033 - val_accuracy: 0.6842\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0215 - accuracy: 0.6715 - val_loss: 1.0110 - val_accuracy: 0.6830\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 1.0345 - accuracy: 0.6640\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 1.6964 - accuracy: 0.3904 - val_loss: 1.3182 - val_accuracy: 0.5748\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.1815 - accuracy: 0.6320 - val_loss: 1.0804 - val_accuracy: 0.6896\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.0488 - accuracy: 0.6855 - val_loss: 0.9952 - val_accuracy: 0.7186\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9827 - accuracy: 0.7084 - val_loss: 0.9361 - val_accuracy: 0.7400\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.9083 - accuracy: 0.7373 - val_loss: 0.8637 - val_accuracy: 0.7614\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.8500 - accuracy: 0.7541 - val_loss: 0.8280 - val_accuracy: 0.7696\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8222 - accuracy: 0.7632 - val_loss: 0.8096 - val_accuracy: 0.7784\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8061 - accuracy: 0.7691 - val_loss: 0.7980 - val_accuracy: 0.7834\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7946 - accuracy: 0.7709 - val_loss: 0.7956 - val_accuracy: 0.7826\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7847 - accuracy: 0.7716 - val_loss: 0.7784 - val_accuracy: 0.7860\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7750 - accuracy: 0.7743 - val_loss: 0.7776 - val_accuracy: 0.7896\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7664 - accuracy: 0.7786 - val_loss: 0.7608 - val_accuracy: 0.7954\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7572 - accuracy: 0.7818 - val_loss: 0.7508 - val_accuracy: 0.7974\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7452 - accuracy: 0.7835 - val_loss: 0.7368 - val_accuracy: 0.7976\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.7319 - accuracy: 0.7894 - val_loss: 0.7163 - val_accuracy: 0.8056\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 34us/sample - loss: 0.7198 - accuracy: 0.7944 - val_loss: 0.7159 - val_accuracy: 0.8028\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7111 - accuracy: 0.7958 - val_loss: 0.6999 - val_accuracy: 0.8118\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.7053 - accuracy: 0.7996 - val_loss: 0.7021 - val_accuracy: 0.8084\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.6996 - accuracy: 0.7988 - val_loss: 0.7027 - val_accuracy: 0.8070\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.7554 - accuracy: 0.7901\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.7100 - accuracy: 0.4139 - val_loss: 1.3414 - val_accuracy: 0.6230\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.1710 - accuracy: 0.6455 - val_loss: 1.0781 - val_accuracy: 0.6782\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0174 - accuracy: 0.6812 - val_loss: 0.9851 - val_accuracy: 0.6960\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9464 - accuracy: 0.7030 - val_loss: 0.9317 - val_accuracy: 0.7014\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9049 - accuracy: 0.7165 - val_loss: 0.8969 - val_accuracy: 0.7250\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8789 - accuracy: 0.7246 - val_loss: 0.8772 - val_accuracy: 0.7316\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8599 - accuracy: 0.7312 - val_loss: 0.8645 - val_accuracy: 0.7372\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.8433 - accuracy: 0.7405 - val_loss: 0.8492 - val_accuracy: 0.7494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.8271 - accuracy: 0.7482 - val_loss: 0.8332 - val_accuracy: 0.7552\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8138 - accuracy: 0.7511 - val_loss: 0.8192 - val_accuracy: 0.7638\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.8027 - accuracy: 0.7567 - val_loss: 0.8114 - val_accuracy: 0.7602\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7918 - accuracy: 0.7593 - val_loss: 0.8063 - val_accuracy: 0.7656\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7835 - accuracy: 0.7605 - val_loss: 0.7884 - val_accuracy: 0.7656\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7717 - accuracy: 0.7635 - val_loss: 0.7791 - val_accuracy: 0.7684\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7598 - accuracy: 0.7714 - val_loss: 0.7686 - val_accuracy: 0.7782\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7464 - accuracy: 0.7805 - val_loss: 0.7625 - val_accuracy: 0.7828\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7338 - accuracy: 0.7840 - val_loss: 0.7476 - val_accuracy: 0.7910\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7250 - accuracy: 0.7862 - val_loss: 0.7422 - val_accuracy: 0.7910\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7199 - accuracy: 0.7901 - val_loss: 0.7372 - val_accuracy: 0.7916\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7153 - accuracy: 0.7905 - val_loss: 0.7389 - val_accuracy: 0.7972\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7120 - accuracy: 0.7920 - val_loss: 0.7326 - val_accuracy: 0.7950\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7082 - accuracy: 0.7920 - val_loss: 0.7426 - val_accuracy: 0.7894\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7067 - accuracy: 0.7918 - val_loss: 0.7330 - val_accuracy: 0.7922\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.7703 - accuracy: 0.7784\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.6574 - accuracy: 0.4156 - val_loss: 1.0991 - val_accuracy: 0.6332\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9601 - accuracy: 0.6829 - val_loss: 0.8351 - val_accuracy: 0.7316\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.8305 - accuracy: 0.7266 - val_loss: 0.7760 - val_accuracy: 0.7504\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.7855 - accuracy: 0.7425 - val_loss: 0.7331 - val_accuracy: 0.7640\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.7605 - accuracy: 0.7534 - val_loss: 0.7145 - val_accuracy: 0.7676\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7439 - accuracy: 0.7587 - val_loss: 0.7103 - val_accuracy: 0.7728\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7312 - accuracy: 0.7639 - val_loss: 0.6943 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7211 - accuracy: 0.7686 - val_loss: 0.6853 - val_accuracy: 0.7826\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.7134 - accuracy: 0.7730 - val_loss: 0.6822 - val_accuracy: 0.7850\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7072 - accuracy: 0.7752 - val_loss: 0.6782 - val_accuracy: 0.7870\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7016 - accuracy: 0.7775 - val_loss: 0.6680 - val_accuracy: 0.7932\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6968 - accuracy: 0.7782 - val_loss: 0.6661 - val_accuracy: 0.7928\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.6925 - accuracy: 0.7810 - val_loss: 0.6657 - val_accuracy: 0.7916\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.6885 - accuracy: 0.7821 - val_loss: 0.6565 - val_accuracy: 0.7952\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6848 - accuracy: 0.7845 - val_loss: 0.6695 - val_accuracy: 0.7856\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6831 - accuracy: 0.7872 - val_loss: 0.6584 - val_accuracy: 0.7940\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.6729 - accuracy: 0.7892\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 70us/sample - loss: 1.4238 - accuracy: 0.5086 - val_loss: 1.0092 - val_accuracy: 0.6786\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.8664 - accuracy: 0.7478 - val_loss: 0.7336 - val_accuracy: 0.8024\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6848 - accuracy: 0.8098 - val_loss: 0.6182 - val_accuracy: 0.8334\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6111 - accuracy: 0.8279 - val_loss: 0.5770 - val_accuracy: 0.8378\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5780 - accuracy: 0.8354 - val_loss: 0.5572 - val_accuracy: 0.8440\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5603 - accuracy: 0.8390 - val_loss: 0.5461 - val_accuracy: 0.8484\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5473 - accuracy: 0.8422 - val_loss: 0.5357 - val_accuracy: 0.8566\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5367 - accuracy: 0.8452 - val_loss: 0.5266 - val_accuracy: 0.8562\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5266 - accuracy: 0.8472 - val_loss: 0.5237 - val_accuracy: 0.8610\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5186 - accuracy: 0.8519 - val_loss: 0.5195 - val_accuracy: 0.8592\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5115 - accuracy: 0.8531 - val_loss: 0.5092 - val_accuracy: 0.8620\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5043 - accuracy: 0.8554 - val_loss: 0.5073 - val_accuracy: 0.8618\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4979 - accuracy: 0.8568 - val_loss: 0.5088 - val_accuracy: 0.8656\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4923 - accuracy: 0.8590 - val_loss: 0.5029 - val_accuracy: 0.8640\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.4871 - accuracy: 0.8606 - val_loss: 0.4990 - val_accuracy: 0.8650\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4820 - accuracy: 0.8636 - val_loss: 0.4951 - val_accuracy: 0.8670\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4791 - accuracy: 0.8637 - val_loss: 0.4958 - val_accuracy: 0.8624\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.4758 - accuracy: 0.8650 - val_loss: 0.4957 - val_accuracy: 0.8656\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.5191 - accuracy: 0.8551\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.4927 - accuracy: 0.5448 - val_loss: 1.0882 - val_accuracy: 0.7244ss: 1.6113 - \n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9545 - accuracy: 0.7540 - val_loss: 0.8325 - val_accuracy: 0.7786\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.8028 - accuracy: 0.7822 - val_loss: 0.7021 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6872 - accuracy: 0.8094 - val_loss: 0.6287 - val_accuracy: 0.8208\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6269 - accuracy: 0.8243 - val_loss: 0.5720 - val_accuracy: 0.8434\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5942 - accuracy: 0.8327 - val_loss: 0.5601 - val_accuracy: 0.8476\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5734 - accuracy: 0.8387 - val_loss: 0.5394 - val_accuracy: 0.8532\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5593 - accuracy: 0.8420 - val_loss: 0.5375 - val_accuracy: 0.8558\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5472 - accuracy: 0.8461 - val_loss: 0.5345 - val_accuracy: 0.8562\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5381 - accuracy: 0.8502 - val_loss: 0.5169 - val_accuracy: 0.8632\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5300 - accuracy: 0.8517 - val_loss: 0.5155 - val_accuracy: 0.8614\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5222 - accuracy: 0.8548 - val_loss: 0.5087 - val_accuracy: 0.8632\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5147 - accuracy: 0.8576 - val_loss: 0.5007 - val_accuracy: 0.8678\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5073 - accuracy: 0.8591 - val_loss: 0.4937 - val_accuracy: 0.8664\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.5006 - accuracy: 0.8608 - val_loss: 0.4887 - val_accuracy: 0.8696\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.4945 - accuracy: 0.8615 - val_loss: 0.4905 - val_accuracy: 0.8658\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4877 - accuracy: 0.8645 - val_loss: 0.4797 - val_accuracy: 0.8704\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4817 - accuracy: 0.8648 - val_loss: 0.4779 - val_accuracy: 0.8730\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4752 - accuracy: 0.8674 - val_loss: 0.4811 - val_accuracy: 0.8676\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4691 - accuracy: 0.8694 - val_loss: 0.4671 - val_accuracy: 0.8762\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4622 - accuracy: 0.8710 - val_loss: 0.4644 - val_accuracy: 0.8736\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4560 - accuracy: 0.8728 - val_loss: 0.4590 - val_accuracy: 0.8762\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4518 - accuracy: 0.8744 - val_loss: 0.4546 - val_accuracy: 0.8762\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4467 - accuracy: 0.8740 - val_loss: 0.4546 - val_accuracy: 0.8776\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4430 - accuracy: 0.8763 - val_loss: 0.4444 - val_accuracy: 0.8796\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4392 - accuracy: 0.8769 - val_loss: 0.4392 - val_accuracy: 0.8830\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4373 - accuracy: 0.8780 - val_loss: 0.4400 - val_accuracy: 0.8844\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4345 - accuracy: 0.8805 - val_loss: 0.4380 - val_accuracy: 0.8824\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4318 - accuracy: 0.8798 - val_loss: 0.4426 - val_accuracy: 0.8788\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4305 - accuracy: 0.8797 - val_loss: 0.4386 - val_accuracy: 0.8842\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.4791 - accuracy: 0.8664\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.3392 - accuracy: 0.5337 - val_loss: 0.8815 - val_accuracy: 0.7204\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8136 - accuracy: 0.7353 - val_loss: 0.7233 - val_accuracy: 0.7782\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6986 - accuracy: 0.7834 - val_loss: 0.6501 - val_accuracy: 0.8128\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6303 - accuracy: 0.8123 - val_loss: 0.6072 - val_accuracy: 0.8228\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5948 - accuracy: 0.8258 - val_loss: 0.5774 - val_accuracy: 0.8350\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5744 - accuracy: 0.8326 - val_loss: 0.5722 - val_accuracy: 0.8364\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5591 - accuracy: 0.8373 - val_loss: 0.5489 - val_accuracy: 0.8440\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5474 - accuracy: 0.8395 - val_loss: 0.5463 - val_accuracy: 0.8482\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5376 - accuracy: 0.8445 - val_loss: 0.5332 - val_accuracy: 0.8484\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5278 - accuracy: 0.8487 - val_loss: 0.5278 - val_accuracy: 0.8498\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5198 - accuracy: 0.8525 - val_loss: 0.5116 - val_accuracy: 0.8572\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5122 - accuracy: 0.8551 - val_loss: 0.5083 - val_accuracy: 0.8588\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5054 - accuracy: 0.8583 - val_loss: 0.5057 - val_accuracy: 0.8576\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4996 - accuracy: 0.8592 - val_loss: 0.4974 - val_accuracy: 0.8606\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4951 - accuracy: 0.8604 - val_loss: 0.4982 - val_accuracy: 0.8580\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4906 - accuracy: 0.8629 - val_loss: 0.4944 - val_accuracy: 0.8612\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4878 - accuracy: 0.8640 - val_loss: 0.4913 - val_accuracy: 0.8636\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4845 - accuracy: 0.8624 - val_loss: 0.4856 - val_accuracy: 0.8662\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4810 - accuracy: 0.8641 - val_loss: 0.4959 - val_accuracy: 0.8598\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4792 - accuracy: 0.8662 - val_loss: 0.4831 - val_accuracy: 0.8666\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4761 - accuracy: 0.8676 - val_loss: 0.4834 - val_accuracy: 0.8654\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4742 - accuracy: 0.8654 - val_loss: 0.4825 - val_accuracy: 0.8684\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4724 - accuracy: 0.8657 - val_loss: 0.4743 - val_accuracy: 0.8700\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4703 - accuracy: 0.8680 - val_loss: 0.4823 - val_accuracy: 0.8656\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4684 - accuracy: 0.8684 - val_loss: 0.4806 - val_accuracy: 0.8656\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.4672 - accuracy: 0.8635\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.5351 - accuracy: 0.4815 - val_loss: 1.2040 - val_accuracy: 0.5950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0874 - accuracy: 0.6173 - val_loss: 0.9603 - val_accuracy: 0.6754\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.8852 - accuracy: 0.7171 - val_loss: 0.8055 - val_accuracy: 0.7586\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7643 - accuracy: 0.7640 - val_loss: 0.7244 - val_accuracy: 0.7806\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6996 - accuracy: 0.7795 - val_loss: 0.6738 - val_accuracy: 0.7960\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6590 - accuracy: 0.7964 - val_loss: 0.6375 - val_accuracy: 0.8126\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6280 - accuracy: 0.8091 - val_loss: 0.6068 - val_accuracy: 0.8270\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5999 - accuracy: 0.8210 - val_loss: 0.5783 - val_accuracy: 0.8354\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5769 - accuracy: 0.8296 - val_loss: 0.5561 - val_accuracy: 0.8412\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5584 - accuracy: 0.8348 - val_loss: 0.5521 - val_accuracy: 0.8400\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5438 - accuracy: 0.8404 - val_loss: 0.5443 - val_accuracy: 0.8402\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5311 - accuracy: 0.8433 - val_loss: 0.5292 - val_accuracy: 0.8504\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5216 - accuracy: 0.8455 - val_loss: 0.5223 - val_accuracy: 0.8478\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5135 - accuracy: 0.8466 - val_loss: 0.5122 - val_accuracy: 0.8522\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5075 - accuracy: 0.8498 - val_loss: 0.5048 - val_accuracy: 0.8544\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5009 - accuracy: 0.8490 - val_loss: 0.5014 - val_accuracy: 0.8528\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4972 - accuracy: 0.8523 - val_loss: 0.4999 - val_accuracy: 0.8564\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4919 - accuracy: 0.8539 - val_loss: 0.5108 - val_accuracy: 0.8502\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4874 - accuracy: 0.8554 - val_loss: 0.4953 - val_accuracy: 0.8584\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4838 - accuracy: 0.8561 - val_loss: 0.5002 - val_accuracy: 0.8546\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4796 - accuracy: 0.8564 - val_loss: 0.4926 - val_accuracy: 0.8590\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4770 - accuracy: 0.8581 - val_loss: 0.4973 - val_accuracy: 0.8576\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4743 - accuracy: 0.8590 - val_loss: 0.4876 - val_accuracy: 0.8610\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4728 - accuracy: 0.8610 - val_loss: 0.4895 - val_accuracy: 0.8588\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4694 - accuracy: 0.8621 - val_loss: 0.4863 - val_accuracy: 0.8660\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4669 - accuracy: 0.8619 - val_loss: 0.4888 - val_accuracy: 0.8590\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4653 - accuracy: 0.8638 - val_loss: 0.4849 - val_accuracy: 0.8632\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4634 - accuracy: 0.8638 - val_loss: 0.4763 - val_accuracy: 0.8664\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.4616 - accuracy: 0.8646 - val_loss: 0.4787 - val_accuracy: 0.8650\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4600 - accuracy: 0.8656 - val_loss: 0.4767 - val_accuracy: 0.8670\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.5108 - accuracy: 0.8556\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.1617 - accuracy: 0.6236 - val_loss: 0.7518 - val_accuracy: 0.7636\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6750 - accuracy: 0.8048 - val_loss: 0.5769 - val_accuracy: 0.8394\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5675 - accuracy: 0.8408 - val_loss: 0.5074 - val_accuracy: 0.8596\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5142 - accuracy: 0.8577 - val_loss: 0.4687 - val_accuracy: 0.8718\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4853 - accuracy: 0.8662 - val_loss: 0.4472 - val_accuracy: 0.8804\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4658 - accuracy: 0.8722 - val_loss: 0.4373 - val_accuracy: 0.8788\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4537 - accuracy: 0.8757 - val_loss: 0.4261 - val_accuracy: 0.8870\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4435 - accuracy: 0.8776 - val_loss: 0.4237 - val_accuracy: 0.8852\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4346 - accuracy: 0.8811 - val_loss: 0.4306 - val_accuracy: 0.8846\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4273 - accuracy: 0.8852 - val_loss: 0.4145 - val_accuracy: 0.8914\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4213 - accuracy: 0.8863 - val_loss: 0.4106 - val_accuracy: 0.8906\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4144 - accuracy: 0.8868 - val_loss: 0.4130 - val_accuracy: 0.8888\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4097 - accuracy: 0.8902 - val_loss: 0.3942 - val_accuracy: 0.8944\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4042 - accuracy: 0.8898 - val_loss: 0.3936 - val_accuracy: 0.8930\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3995 - accuracy: 0.8907 - val_loss: 0.3887 - val_accuracy: 0.8942\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3952 - accuracy: 0.8930 - val_loss: 0.3929 - val_accuracy: 0.8952\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3904 - accuracy: 0.8962 - val_loss: 0.3902 - val_accuracy: 0.8974\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.4385 - accuracy: 0.8789\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.3298 - accuracy: 0.5439 - val_loss: 0.9407 - val_accuracy: 0.7040\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.8585 - accuracy: 0.7380 - val_loss: 0.7721 - val_accuracy: 0.7806\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7405 - accuracy: 0.7843 - val_loss: 0.6868 - val_accuracy: 0.8118\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6793 - accuracy: 0.8073 - val_loss: 0.6468 - val_accuracy: 0.8224\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6429 - accuracy: 0.8209 - val_loss: 0.6209 - val_accuracy: 0.8300\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6185 - accuracy: 0.8269 - val_loss: 0.6056 - val_accuracy: 0.8370\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5998 - accuracy: 0.8333 - val_loss: 0.5956 - val_accuracy: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5867 - accuracy: 0.8358 - val_loss: 0.5775 - val_accuracy: 0.8392\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5744 - accuracy: 0.8385 - val_loss: 0.5679 - val_accuracy: 0.8390\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5633 - accuracy: 0.8427 - val_loss: 0.5546 - val_accuracy: 0.8450\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5549 - accuracy: 0.8451 - val_loss: 0.5479 - val_accuracy: 0.8466\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5470 - accuracy: 0.8473 - val_loss: 0.5444 - val_accuracy: 0.8532\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5400 - accuracy: 0.8493 - val_loss: 0.5361 - val_accuracy: 0.8530\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5330 - accuracy: 0.8511 - val_loss: 0.5256 - val_accuracy: 0.8532\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5277 - accuracy: 0.8525 - val_loss: 0.5282 - val_accuracy: 0.8504\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5216 - accuracy: 0.8545 - val_loss: 0.5192 - val_accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5168 - accuracy: 0.8563 - val_loss: 0.5129 - val_accuracy: 0.8570\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5108 - accuracy: 0.8574 - val_loss: 0.5061 - val_accuracy: 0.8568\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5057 - accuracy: 0.8588 - val_loss: 0.5079 - val_accuracy: 0.8562\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4996 - accuracy: 0.8608 - val_loss: 0.4972 - val_accuracy: 0.8624\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4951 - accuracy: 0.8619 - val_loss: 0.5009 - val_accuracy: 0.8586\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4897 - accuracy: 0.8651 - val_loss: 0.4945 - val_accuracy: 0.8642\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4847 - accuracy: 0.8658 - val_loss: 0.4914 - val_accuracy: 0.8626\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4805 - accuracy: 0.8669 - val_loss: 0.4810 - val_accuracy: 0.8626\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4761 - accuracy: 0.8690 - val_loss: 0.4818 - val_accuracy: 0.8614\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4732 - accuracy: 0.8689 - val_loss: 0.4843 - val_accuracy: 0.8636\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.4834 - accuracy: 0.8604\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.2337 - accuracy: 0.5851 - val_loss: 0.7433 - val_accuracy: 0.7774\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.6615 - accuracy: 0.8027 - val_loss: 0.5787 - val_accuracy: 0.8398\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5603 - accuracy: 0.8353 - val_loss: 0.5352 - val_accuracy: 0.8544\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5206 - accuracy: 0.8483 - val_loss: 0.5093 - val_accuracy: 0.8628\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4989 - accuracy: 0.8561 - val_loss: 0.4966 - val_accuracy: 0.8630\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4848 - accuracy: 0.8604 - val_loss: 0.4862 - val_accuracy: 0.8742\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4732 - accuracy: 0.8643 - val_loss: 0.4859 - val_accuracy: 0.8766\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4632 - accuracy: 0.8687 - val_loss: 0.4757 - val_accuracy: 0.8738\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4551 - accuracy: 0.8707 - val_loss: 0.4723 - val_accuracy: 0.8790\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4480 - accuracy: 0.8744 - val_loss: 0.4696 - val_accuracy: 0.8766\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4414 - accuracy: 0.8759 - val_loss: 0.4746 - val_accuracy: 0.8756\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4359 - accuracy: 0.8781 - val_loss: 0.4611 - val_accuracy: 0.8824\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4317 - accuracy: 0.8781 - val_loss: 0.4557 - val_accuracy: 0.8812\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4271 - accuracy: 0.8794 - val_loss: 0.4525 - val_accuracy: 0.8838\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4234 - accuracy: 0.8811 - val_loss: 0.4440 - val_accuracy: 0.8840\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4197 - accuracy: 0.8823 - val_loss: 0.4492 - val_accuracy: 0.8858\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4160 - accuracy: 0.8828 - val_loss: 0.4408 - val_accuracy: 0.8862\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4127 - accuracy: 0.8846 - val_loss: 0.4447 - val_accuracy: 0.8880\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4096 - accuracy: 0.8851 - val_loss: 0.4331 - val_accuracy: 0.8864\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4064 - accuracy: 0.8858 - val_loss: 0.4506 - val_accuracy: 0.8836\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4020 - accuracy: 0.8881 - val_loss: 0.4372 - val_accuracy: 0.8876\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.4673 - accuracy: 0.8745\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.2422 - accuracy: 0.5874 - val_loss: 0.8141 - val_accuracy: 0.7552\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6239 - accuracy: 0.8211 - val_loss: 0.5030 - val_accuracy: 0.8594\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4871 - accuracy: 0.8605 - val_loss: 0.4567 - val_accuracy: 0.8746\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4494 - accuracy: 0.8707 - val_loss: 0.4321 - val_accuracy: 0.8842\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4269 - accuracy: 0.8791 - val_loss: 0.4151 - val_accuracy: 0.8852\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4118 - accuracy: 0.8827 - val_loss: 0.4016 - val_accuracy: 0.8932\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3984 - accuracy: 0.8873 - val_loss: 0.3993 - val_accuracy: 0.8920\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3898 - accuracy: 0.8871 - val_loss: 0.3879 - val_accuracy: 0.8934\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3813 - accuracy: 0.8904 - val_loss: 0.4046 - val_accuracy: 0.8908\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3728 - accuracy: 0.8938 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3617 - accuracy: 0.8970 - val_loss: 0.3662 - val_accuracy: 0.9006\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3516 - accuracy: 0.8991 - val_loss: 0.3685 - val_accuracy: 0.8984\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3441 - accuracy: 0.9018 - val_loss: 0.3563 - val_accuracy: 0.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3375 - accuracy: 0.9030 - val_loss: 0.3495 - val_accuracy: 0.9050\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3324 - accuracy: 0.9054 - val_loss: 0.3483 - val_accuracy: 0.9034\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3303 - accuracy: 0.9065 - val_loss: 0.3456 - val_accuracy: 0.9028\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3247 - accuracy: 0.9081 - val_loss: 0.3458 - val_accuracy: 0.9074\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3211 - accuracy: 0.9088 - val_loss: 0.3403 - val_accuracy: 0.9062ccuracy: 0.90\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3188 - accuracy: 0.9108 - val_loss: 0.3392 - val_accuracy: 0.9060\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3162 - accuracy: 0.9118 - val_loss: 0.3329 - val_accuracy: 0.9086\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3135 - accuracy: 0.9116 - val_loss: 0.3348 - val_accuracy: 0.9056\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3112 - accuracy: 0.9135 - val_loss: 0.3355 - val_accuracy: 0.9050ss: 0\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3706 - accuracy: 0.8947\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.1003 - accuracy: 0.6479 - val_loss: 0.6206 - val_accuracy: 0.8190\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5739 - accuracy: 0.8283 - val_loss: 0.4830 - val_accuracy: 0.8580\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4892 - accuracy: 0.8574 - val_loss: 0.4237 - val_accuracy: 0.8796\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4483 - accuracy: 0.8696 - val_loss: 0.4094 - val_accuracy: 0.8814\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4231 - accuracy: 0.8791 - val_loss: 0.3864 - val_accuracy: 0.8936\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4045 - accuracy: 0.8840 - val_loss: 0.3820 - val_accuracy: 0.8926\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3889 - accuracy: 0.8882 - val_loss: 0.3576 - val_accuracy: 0.8996\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3758 - accuracy: 0.8922 - val_loss: 0.3584 - val_accuracy: 0.9002\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3643 - accuracy: 0.8962 - val_loss: 0.3527 - val_accuracy: 0.9032\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3559 - accuracy: 0.8989 - val_loss: 0.3467 - val_accuracy: 0.9050\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3482 - accuracy: 0.9012 - val_loss: 0.3446 - val_accuracy: 0.9066\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3427 - accuracy: 0.9025 - val_loss: 0.3354 - val_accuracy: 0.9092\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3378 - accuracy: 0.9042 - val_loss: 0.3462 - val_accuracy: 0.9024\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3341 - accuracy: 0.9048 - val_loss: 0.3393 - val_accuracy: 0.9062\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3546 - accuracy: 0.8998\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.8973 - accuracy: 0.7158 - val_loss: 0.5350 - val_accuracy: 0.8526\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4501 - accuracy: 0.8727 - val_loss: 0.3945 - val_accuracy: 0.8892\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3791 - accuracy: 0.8927 - val_loss: 0.3573 - val_accuracy: 0.9002\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3487 - accuracy: 0.9014 - val_loss: 0.3305 - val_accuracy: 0.9082\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3304 - accuracy: 0.9074 - val_loss: 0.3236 - val_accuracy: 0.9066\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3197 - accuracy: 0.9098 - val_loss: 0.3094 - val_accuracy: 0.9148\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3119 - accuracy: 0.9120 - val_loss: 0.3090 - val_accuracy: 0.9112\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3049 - accuracy: 0.9151 - val_loss: 0.3050 - val_accuracy: 0.9142\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2992 - accuracy: 0.9161 - val_loss: 0.3034 - val_accuracy: 0.9144\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2945 - accuracy: 0.9176 - val_loss: 0.3026 - val_accuracy: 0.9182\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2902 - accuracy: 0.9175 - val_loss: 0.3129 - val_accuracy: 0.9152\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2866 - accuracy: 0.9203 - val_loss: 0.3106 - val_accuracy: 0.9162\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.3365 - accuracy: 0.9093\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.8286 - accuracy: 0.7479 - val_loss: 0.4869 - val_accuracy: 0.8596\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4584 - accuracy: 0.8638 - val_loss: 0.4161 - val_accuracy: 0.8790\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4044 - accuracy: 0.8828 - val_loss: 0.3799 - val_accuracy: 0.8964\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3746 - accuracy: 0.8917 - val_loss: 0.3588 - val_accuracy: 0.8974\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3544 - accuracy: 0.8983 - val_loss: 0.3507 - val_accuracy: 0.9026\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 0.3398 - accuracy: 0.9030 - val_loss: 0.3468 - val_accuracy: 0.9048\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3282 - accuracy: 0.9065 - val_loss: 0.3351 - val_accuracy: 0.9032\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.3191 - accuracy: 0.9091 - val_loss: 0.3336 - val_accuracy: 0.9076\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3124 - accuracy: 0.9122 - val_loss: 0.3495 - val_accuracy: 0.9046\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3066 - accuracy: 0.9144 - val_loss: 0.3291 - val_accuracy: 0.9098\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3022 - accuracy: 0.9154 - val_loss: 0.3185 - val_accuracy: 0.9124\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2978 - accuracy: 0.9167 - val_loss: 0.3235 - val_accuracy: 0.9134\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.2954 - accuracy: 0.9189 - val_loss: 0.3198 - val_accuracy: 0.9162\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3514 - accuracy: 0.9019\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.9499 - accuracy: 0.7249 - val_loss: 0.5005 - val_accuracy: 0.8594\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4801 - accuracy: 0.8633 - val_loss: 0.4026 - val_accuracy: 0.8842\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4118 - accuracy: 0.8832 - val_loss: 0.3650 - val_accuracy: 0.9010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3809 - accuracy: 0.8916 - val_loss: 0.3461 - val_accuracy: 0.9066\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3596 - accuracy: 0.8970 - val_loss: 0.3293 - val_accuracy: 0.9108\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3435 - accuracy: 0.9014 - val_loss: 0.3506 - val_accuracy: 0.8960: 0.3400 - accura\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3303 - accuracy: 0.9056 - val_loss: 0.3029 - val_accuracy: 0.9132\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3184 - accuracy: 0.9086 - val_loss: 0.2990 - val_accuracy: 0.9178\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3098 - accuracy: 0.9111 - val_loss: 0.2977 - val_accuracy: 0.9142\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3040 - accuracy: 0.9146 - val_loss: 0.2973 - val_accuracy: 0.9164\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2980 - accuracy: 0.9144 - val_loss: 0.2931 - val_accuracy: 0.9156\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2921 - accuracy: 0.9165 - val_loss: 0.2876 - val_accuracy: 0.9192\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2893 - accuracy: 0.9179 - val_loss: 0.2858 - val_accuracy: 0.9184\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2842 - accuracy: 0.9187 - val_loss: 0.2852 - val_accuracy: 0.9182\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2812 - accuracy: 0.9210 - val_loss: 0.2863 - val_accuracy: 0.9160\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2794 - accuracy: 0.9204 - val_loss: 0.3078 - val_accuracy: 0.9158\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3010 - accuracy: 0.9118\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.8590 - accuracy: 0.7422 - val_loss: 0.4479 - val_accuracy: 0.8794\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4038 - accuracy: 0.8826 - val_loss: 0.3525 - val_accuracy: 0.9028\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3467 - accuracy: 0.8987 - val_loss: 0.3272 - val_accuracy: 0.9112\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3232 - accuracy: 0.9061 - val_loss: 0.3103 - val_accuracy: 0.9166\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3060 - accuracy: 0.9122 - val_loss: 0.3022 - val_accuracy: 0.9192\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2937 - accuracy: 0.9152 - val_loss: 0.2964 - val_accuracy: 0.9178\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2848 - accuracy: 0.9188 - val_loss: 0.2951 - val_accuracy: 0.9202\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2759 - accuracy: 0.9221 - val_loss: 0.2905 - val_accuracy: 0.9210\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.2691 - accuracy: 0.9237 - val_loss: 0.2838 - val_accuracy: 0.92420.2649 - accuracy - ETA: 0s - loss: 0.262\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.2644 - accuracy: 0.9251 - val_loss: 0.2778 - val_accuracy: 0.9228\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.2586 - accuracy: 0.9265 - val_loss: 0.2897 - val_accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2537 - accuracy: 0.9284 - val_loss: 0.2920 - val_accuracy: 0.9206\n",
      "18334/18334 [==============================] - 1s 36us/sample - loss: 0.3047 - accuracy: 0.9167\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.9312 - accuracy: 0.7112 - val_loss: 0.4810 - val_accuracy: 0.8624\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4400 - accuracy: 0.8747 - val_loss: 0.3872 - val_accuracy: 0.8894\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3847 - accuracy: 0.8895 - val_loss: 0.3602 - val_accuracy: 0.9030\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3581 - accuracy: 0.8973 - val_loss: 0.3460 - val_accuracy: 0.9052\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3405 - accuracy: 0.9025 - val_loss: 0.3429 - val_accuracy: 0.9080\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3271 - accuracy: 0.9062 - val_loss: 0.3269 - val_accuracy: 0.9084\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3149 - accuracy: 0.9107 - val_loss: 0.3136 - val_accuracy: 0.9136\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3041 - accuracy: 0.9119 - val_loss: 0.3112 - val_accuracy: 0.9134\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2948 - accuracy: 0.9151 - val_loss: 0.3128 - val_accuracy: 0.9136\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2871 - accuracy: 0.9186 - val_loss: 0.2970 - val_accuracy: 0.9186\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2814 - accuracy: 0.9209 - val_loss: 0.2972 - val_accuracy: 0.9150\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2751 - accuracy: 0.9221 - val_loss: 0.2974 - val_accuracy: 0.9174\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3311 - accuracy: 0.9092\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8514 - accuracy: 0.7343 - val_loss: 0.4584 - val_accuracy: 0.8654\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4071 - accuracy: 0.8829 - val_loss: 0.3443 - val_accuracy: 0.9016\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3361 - accuracy: 0.9040 - val_loss: 0.3018 - val_accuracy: 0.9128\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3079 - accuracy: 0.9139 - val_loss: 0.2930 - val_accuracy: 0.9160\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2897 - accuracy: 0.9189 - val_loss: 0.2853 - val_accuracy: 0.9234\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2792 - accuracy: 0.9213 - val_loss: 0.2765 - val_accuracy: 0.9194\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2697 - accuracy: 0.9234 - val_loss: 0.2621 - val_accuracy: 0.9258\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2636 - accuracy: 0.9258 - val_loss: 0.2606 - val_accuracy: 0.9258\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2592 - accuracy: 0.9275 - val_loss: 0.2597 - val_accuracy: 0.9266\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2548 - accuracy: 0.9281 - val_loss: 0.2656 - val_accuracy: 0.9266\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2506 - accuracy: 0.9309 - val_loss: 0.2648 - val_accuracy: 0.9256\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.2772 - accuracy: 0.9222\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.7821 - accuracy: 0.7617 - val_loss: 0.3867 - val_accuracy: 0.8970\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3601 - accuracy: 0.8996 - val_loss: 0.3193 - val_accuracy: 0.9138\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3191 - accuracy: 0.9100 - val_loss: 0.2951 - val_accuracy: 0.9196\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2972 - accuracy: 0.9153 - val_loss: 0.2849 - val_accuracy: 0.9204\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2818 - accuracy: 0.9204 - val_loss: 0.2831 - val_accuracy: 0.9206\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.2705 - accuracy: 0.9231 - val_loss: 0.2633 - val_accuracy: 0.9268\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.2618 - accuracy: 0.9259 - val_loss: 0.2683 - val_accuracy: 0.9260\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2531 - accuracy: 0.9281 - val_loss: 0.2563 - val_accuracy: 0.9308\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2457 - accuracy: 0.9297 - val_loss: 0.2593 - val_accuracy: 0.9260\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2408 - accuracy: 0.9314 - val_loss: 0.2567 - val_accuracy: 0.9272\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.2928 - accuracy: 0.9167\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.9058 - accuracy: 0.7093 - val_loss: 0.4715 - val_accuracy: 0.8692\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4187 - accuracy: 0.8808 - val_loss: 0.3661 - val_accuracy: 0.8946\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3512 - accuracy: 0.9005 - val_loss: 0.3310 - val_accuracy: 0.9086\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3190 - accuracy: 0.9116 - val_loss: 0.3073 - val_accuracy: 0.9164\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2965 - accuracy: 0.9168 - val_loss: 0.2955 - val_accuracy: 0.9210\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2800 - accuracy: 0.9219 - val_loss: 0.2816 - val_accuracy: 0.9254\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2664 - accuracy: 0.9263 - val_loss: 0.2719 - val_accuracy: 0.9284\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2570 - accuracy: 0.9284 - val_loss: 0.2711 - val_accuracy: 0.9278\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2478 - accuracy: 0.9308 - val_loss: 0.2672 - val_accuracy: 0.9292\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2404 - accuracy: 0.9325 - val_loss: 0.2606 - val_accuracy: 0.9310\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.2355 - accuracy: 0.9350 - val_loss: 0.2570 - val_accuracy: 0.9300\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2289 - accuracy: 0.9370 - val_loss: 0.2660 - val_accuracy: 0.9300\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2258 - accuracy: 0.9386 - val_loss: 0.2531 - val_accuracy: 0.9332\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2210 - accuracy: 0.9391 - val_loss: 0.2492 - val_accuracy: 0.9334\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2177 - accuracy: 0.9392 - val_loss: 0.2475 - val_accuracy: 0.9346\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2161 - accuracy: 0.9406 - val_loss: 0.2519 - val_accuracy: 0.9328\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2121 - accuracy: 0.9411 - val_loss: 0.2481 - val_accuracy: 0.9334\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.2730 - accuracy: 0.9263\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7784 - accuracy: 0.7716 - val_loss: 0.3991 - val_accuracy: 0.8826\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3957 - accuracy: 0.8847 - val_loss: 0.3497 - val_accuracy: 0.9000\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3497 - accuracy: 0.8993 - val_loss: 0.3173 - val_accuracy: 0.9052\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3197 - accuracy: 0.9076 - val_loss: 0.2993 - val_accuracy: 0.9116\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2986 - accuracy: 0.9139 - val_loss: 0.2899 - val_accuracy: 0.9186\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2797 - accuracy: 0.9190 - val_loss: 0.2859 - val_accuracy: 0.9150\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2679 - accuracy: 0.9234 - val_loss: 0.2599 - val_accuracy: 0.9250\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.2577 - accuracy: 0.9246 - val_loss: 0.2599 - val_accuracy: 0.9264\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.2524 - accuracy: 0.9271 - val_loss: 0.2557 - val_accuracy: 0.9274\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2470 - accuracy: 0.9292 - val_loss: 0.2673 - val_accuracy: 0.9248\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2419 - accuracy: 0.9297 - val_loss: 0.2561 - val_accuracy: 0.9294\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.2597 - accuracy: 0.9271\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 2.0079 - accuracy: 0.2005 - val_loss: 1.9070 - val_accuracy: 0.2230\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.8614 - accuracy: 0.2348 - val_loss: 1.8320 - val_accuracy: 0.2412\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.7769 - accuracy: 0.2710 - val_loss: 1.7460 - val_accuracy: 0.2768\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.7091 - accuracy: 0.2763 - val_loss: 1.6987 - val_accuracy: 0.2788\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.6773 - accuracy: 0.2775 - val_loss: 1.6712 - val_accuracy: 0.2746\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.6565 - accuracy: 0.2777 - val_loss: 1.6568 - val_accuracy: 0.2734\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.6434 - accuracy: 0.2811 - val_loss: 1.6468 - val_accuracy: 0.2930\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.6323 - accuracy: 0.3017 - val_loss: 1.6432 - val_accuracy: 0.3094\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.6230 - accuracy: 0.3148 - val_loss: 1.6221 - val_accuracy: 0.3286\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.6094 - accuracy: 0.3436 - val_loss: 1.6069 - val_accuracy: 0.3658\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5831 - accuracy: 0.3721 - val_loss: 1.5745 - val_accuracy: 0.3746\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 1.5605 - accuracy: 0.3750 - val_loss: 1.5571 - val_accuracy: 0.3776\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.5468 - accuracy: 0.3760 - val_loss: 1.5456 - val_accuracy: 0.3754\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5386 - accuracy: 0.3781 - val_loss: 1.5362 - val_accuracy: 0.3808\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5325 - accuracy: 0.3774 - val_loss: 1.5373 - val_accuracy: 0.3814\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5278 - accuracy: 0.3766 - val_loss: 1.5329 - val_accuracy: 0.3846\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5241 - accuracy: 0.3796 - val_loss: 1.5439 - val_accuracy: 0.3734\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.5216 - accuracy: 0.3807 - val_loss: 1.5278 - val_accuracy: 0.4114\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5189 - accuracy: 0.3853 - val_loss: 1.5241 - val_accuracy: 0.3888\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.5172 - accuracy: 0.3836 - val_loss: 1.5209 - val_accuracy: 0.3950\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5150 - accuracy: 0.3865 - val_loss: 1.5196 - val_accuracy: 0.4008\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.5133 - accuracy: 0.3874 - val_loss: 1.5179 - val_accuracy: 0.4030\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 3s 94us/sample - loss: 1.5126 - accuracy: 0.3893 - val_loss: 1.5271 - val_accuracy: 0.4006\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 63us/sample - loss: 1.5113 - accuracy: 0.3901 - val_loss: 1.5204 - val_accuracy: 0.3934\n",
      "18334/18334 [==============================] - 1s 37us/sample - loss: 1.5448 - accuracy: 0.3922\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 2.3015 - accuracy: 0.1137 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.0694 - accuracy: 0.2169 - val_loss: 1.9416 - val_accuracy: 0.2396\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.8676 - accuracy: 0.2774 - val_loss: 1.8034 - val_accuracy: 0.3114\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.7806 - accuracy: 0.3177 - val_loss: 1.7432 - val_accuracy: 0.3336\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7367 - accuracy: 0.3353 - val_loss: 1.7093 - val_accuracy: 0.3448\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.7084 - accuracy: 0.3493 - val_loss: 1.6845 - val_accuracy: 0.3602\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.6872 - accuracy: 0.3588 - val_loss: 1.6723 - val_accuracy: 0.3654\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6710 - accuracy: 0.3627 - val_loss: 1.6544 - val_accuracy: 0.3690\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6574 - accuracy: 0.3674 - val_loss: 1.6442 - val_accuracy: 0.3814\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6445 - accuracy: 0.3739 - val_loss: 1.6348 - val_accuracy: 0.3758\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6356 - accuracy: 0.3784 - val_loss: 1.6182 - val_accuracy: 0.3794\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.6250 - accuracy: 0.3804 - val_loss: 1.6126 - val_accuracy: 0.3816\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6165 - accuracy: 0.3803 - val_loss: 1.6035 - val_accuracy: 0.3798\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6084 - accuracy: 0.3824 - val_loss: 1.6085 - val_accuracy: 0.3826\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.6009 - accuracy: 0.3840 - val_loss: 1.5938 - val_accuracy: 0.3700\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5943 - accuracy: 0.3835 - val_loss: 1.5841 - val_accuracy: 0.3846\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.5872 - accuracy: 0.3823 - val_loss: 1.5729 - val_accuracy: 0.3860\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.5810 - accuracy: 0.3866 - val_loss: 1.5710 - val_accuracy: 0.3890\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5733 - accuracy: 0.3895 - val_loss: 1.5622 - val_accuracy: 0.3944\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5676 - accuracy: 0.3918 - val_loss: 1.5521 - val_accuracy: 0.3938\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5600 - accuracy: 0.3929 - val_loss: 1.5432 - val_accuracy: 0.3960\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5525 - accuracy: 0.3943 - val_loss: 1.5354 - val_accuracy: 0.3972\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5417 - accuracy: 0.3955 - val_loss: 1.5250 - val_accuracy: 0.4002\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5316 - accuracy: 0.3969 - val_loss: 1.5224 - val_accuracy: 0.3846\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5204 - accuracy: 0.3945 - val_loss: 1.5099 - val_accuracy: 0.3892\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5109 - accuracy: 0.3958 - val_loss: 1.4988 - val_accuracy: 0.3848\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5030 - accuracy: 0.3915 - val_loss: 1.4929 - val_accuracy: 0.3834\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4943 - accuracy: 0.3930 - val_loss: 1.4882 - val_accuracy: 0.3794\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.4886 - accuracy: 0.3910 - val_loss: 1.4873 - val_accuracy: 0.3812\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.4829 - accuracy: 0.3905 - val_loss: 1.4780 - val_accuracy: 0.3730\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4776 - accuracy: 0.3862 - val_loss: 1.4768 - val_accuracy: 0.3784\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 1.5162 - accuracy: 0.3806\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.0684 - accuracy: 0.2006 - val_loss: 1.9311 - val_accuracy: 0.2454\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.8783 - accuracy: 0.2380 - val_loss: 1.7938 - val_accuracy: 0.2438\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.7613 - accuracy: 0.2851 - val_loss: 1.6811 - val_accuracy: 0.3192\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6617 - accuracy: 0.3266 - val_loss: 1.6051 - val_accuracy: 0.3526\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6038 - accuracy: 0.3569 - val_loss: 1.5661 - val_accuracy: 0.3730\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5701 - accuracy: 0.3607 - val_loss: 1.5354 - val_accuracy: 0.3796\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.5487 - accuracy: 0.3634 - val_loss: 1.5190 - val_accuracy: 0.3676s - loss: 1.5629 -  - ETA: 1s - loss: - ETA: 0s - loss: 1.5489 - accura\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5360 - accuracy: 0.3649 - val_loss: 1.5053 - val_accuracy: 0.3800\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5250 - accuracy: 0.3686 - val_loss: 1.5002 - val_accuracy: 0.3804\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.5167 - accuracy: 0.3709 - val_loss: 1.4928 - val_accuracy: 0.3786\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.5087 - accuracy: 0.3747 - val_loss: 1.4899 - val_accuracy: 0.3870\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5039 - accuracy: 0.3774 - val_loss: 1.4847 - val_accuracy: 0.3846\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.4996 - accuracy: 0.3816 - val_loss: 1.4822 - val_accuracy: 0.3978\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4920 - accuracy: 0.3859 - val_loss: 1.4763 - val_accuracy: 0.4088\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4890 - accuracy: 0.3945 - val_loss: 1.4729 - val_accuracy: 0.4106\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.4843 - accuracy: 0.4030 - val_loss: 1.4667 - val_accuracy: 0.4150\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4794 - accuracy: 0.4085 - val_loss: 1.4594 - val_accuracy: 0.4168\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.4761 - accuracy: 0.4199 - val_loss: 1.4549 - val_accuracy: 0.4322\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4668 - accuracy: 0.4257 - val_loss: 1.4470 - val_accuracy: 0.4328\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.4634 - accuracy: 0.4300 - val_loss: 1.4613 - val_accuracy: 0.4420\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4521 - accuracy: 0.4369 - val_loss: 1.4324 - val_accuracy: 0.4414\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4435 - accuracy: 0.4334 - val_loss: 1.4233 - val_accuracy: 0.4450\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.4362 - accuracy: 0.4388 - val_loss: 1.4194 - val_accuracy: 0.4356\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4263 - accuracy: 0.4361 - val_loss: 1.4105 - val_accuracy: 0.4582\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4201 - accuracy: 0.4400 - val_loss: 1.4205 - val_accuracy: 0.4492\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.4165 - accuracy: 0.4420 - val_loss: 1.4061 - val_accuracy: 0.4484\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.4094 - accuracy: 0.4436 - val_loss: 1.3949 - val_accuracy: 0.4578\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4066 - accuracy: 0.4463 - val_loss: 1.3977 - val_accuracy: 0.4566\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4043 - accuracy: 0.4501 - val_loss: 1.3886 - val_accuracy: 0.4572\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4003 - accuracy: 0.4492 - val_loss: 1.3912 - val_accuracy: 0.4466\n",
      "18333/18333 [==============================] - 1s 44us/sample - loss: 1.4191 - accuracy: 0.4412\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.8467 - accuracy: 0.2676 - val_loss: 1.5940 - val_accuracy: 0.3516\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.5125 - accuracy: 0.4113 - val_loss: 1.4092 - val_accuracy: 0.4912\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.3291 - accuracy: 0.5211 - val_loss: 1.2558 - val_accuracy: 0.5424\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.2162 - accuracy: 0.5511 - val_loss: 1.1823 - val_accuracy: 0.5762\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.1484 - accuracy: 0.5736 - val_loss: 1.1311 - val_accuracy: 0.5946\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.0897 - accuracy: 0.6166 - val_loss: 1.0829 - val_accuracy: 0.6458\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.0456 - accuracy: 0.6432 - val_loss: 1.0501 - val_accuracy: 0.6616\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.0139 - accuracy: 0.6581 - val_loss: 1.0244 - val_accuracy: 0.6766\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9838 - accuracy: 0.6772 - val_loss: 0.9831 - val_accuracy: 0.6966\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.9528 - accuracy: 0.6952 - val_loss: 0.9613 - val_accuracy: 0.6940: 0.953\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.9337 - accuracy: 0.6989 - val_loss: 0.9531 - val_accuracy: 0.6916\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9215 - accuracy: 0.7051 - val_loss: 0.9489 - val_accuracy: 0.6940\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.9137 - accuracy: 0.7049 - val_loss: 0.9583 - val_accuracy: 0.7060\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9081 - accuracy: 0.7098 - val_loss: 0.9867 - val_accuracy: 0.6776\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.9664 - accuracy: 0.6864\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 1.9030 - accuracy: 0.2744 - val_loss: 1.6275 - val_accuracy: 0.4432\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5326 - accuracy: 0.4371 - val_loss: 1.4123 - val_accuracy: 0.4716\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.3886 - accuracy: 0.4740 - val_loss: 1.3239 - val_accuracy: 0.5008\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.3084 - accuracy: 0.5016 - val_loss: 1.2789 - val_accuracy: 0.5214\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.2562 - accuracy: 0.5180 - val_loss: 1.2250 - val_accuracy: 0.5392\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.2144 - accuracy: 0.5295 - val_loss: 1.2034 - val_accuracy: 0.5428\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1795 - accuracy: 0.5506 - val_loss: 1.1573 - val_accuracy: 0.5776\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1489 - accuracy: 0.5644 - val_loss: 1.1563 - val_accuracy: 0.5722\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1293 - accuracy: 0.5660 - val_loss: 1.1480 - val_accuracy: 0.5686\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.1154 - accuracy: 0.5742 - val_loss: 1.1199 - val_accuracy: 0.5852\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1046 - accuracy: 0.5793 - val_loss: 1.1057 - val_accuracy: 0.5908\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0940 - accuracy: 0.5850 - val_loss: 1.1045 - val_accuracy: 0.5978\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0873 - accuracy: 0.5910 - val_loss: 1.0906 - val_accuracy: 0.6132\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0796 - accuracy: 0.5986 - val_loss: 1.0834 - val_accuracy: 0.6162\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.0737 - accuracy: 0.6089 - val_loss: 1.0750 - val_accuracy: 0.6208\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0675 - accuracy: 0.6152 - val_loss: 1.0808 - val_accuracy: 0.6432\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0597 - accuracy: 0.6236 - val_loss: 1.0743 - val_accuracy: 0.6418\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.0490 - accuracy: 0.6406 - val_loss: 1.0508 - val_accuracy: 0.6676\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0340 - accuracy: 0.6573 - val_loss: 1.0309 - val_accuracy: 0.6732\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0167 - accuracy: 0.6653 - val_loss: 1.0251 - val_accuracy: 0.6732\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.0017 - accuracy: 0.6682 - val_loss: 1.0189 - val_accuracy: 0.6644\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.9909 - accuracy: 0.6734 - val_loss: 1.0091 - val_accuracy: 0.6606\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.9845 - accuracy: 0.6727 - val_loss: 0.9838 - val_accuracy: 0.6814\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9795 - accuracy: 0.6738 - val_loss: 0.9839 - val_accuracy: 0.6788\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9755 - accuracy: 0.6748 - val_loss: 0.9793 - val_accuracy: 0.6770\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9735 - accuracy: 0.6746 - val_loss: 0.9862 - val_accuracy: 0.6780\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9704 - accuracy: 0.6778 - val_loss: 0.9835 - val_accuracy: 0.6778\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.0055 - accuracy: 0.6717\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.8944 - accuracy: 0.2414 - val_loss: 1.6727 - val_accuracy: 0.3460\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5429 - accuracy: 0.3962 - val_loss: 1.4295 - val_accuracy: 0.4692\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.2996 - accuracy: 0.5419 - val_loss: 1.1551 - val_accuracy: 0.6222\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1262 - accuracy: 0.6138 - val_loss: 1.0547 - val_accuracy: 0.6580\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0345 - accuracy: 0.6614 - val_loss: 0.9781 - val_accuracy: 0.6858\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.9662 - accuracy: 0.6904 - val_loss: 0.9250 - val_accuracy: 0.7086\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9196 - accuracy: 0.7065 - val_loss: 0.8879 - val_accuracy: 0.7268\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.8845 - accuracy: 0.7195 - val_loss: 0.8450 - val_accuracy: 0.7432\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8555 - accuracy: 0.7325 - val_loss: 0.8317 - val_accuracy: 0.7482\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.8330 - accuracy: 0.7430 - val_loss: 0.7993 - val_accuracy: 0.7594\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8142 - accuracy: 0.7526 - val_loss: 0.7841 - val_accuracy: 0.7722\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7960 - accuracy: 0.7604 - val_loss: 0.7766 - val_accuracy: 0.7720\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7816 - accuracy: 0.7640 - val_loss: 0.7589 - val_accuracy: 0.7796\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.7710 - accuracy: 0.7681 - val_loss: 0.7526 - val_accuracy: 0.7778\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7648 - accuracy: 0.7715 - val_loss: 0.7586 - val_accuracy: 0.7722\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7578 - accuracy: 0.7738 - val_loss: 0.7427 - val_accuracy: 0.7860\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7523 - accuracy: 0.7746 - val_loss: 0.7403 - val_accuracy: 0.7842\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7475 - accuracy: 0.7788 - val_loss: 0.7360 - val_accuracy: 0.7888\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7414 - accuracy: 0.7800 - val_loss: 0.7513 - val_accuracy: 0.7782\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7383 - accuracy: 0.7823 - val_loss: 0.7298 - val_accuracy: 0.7942\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7345 - accuracy: 0.7844 - val_loss: 0.7384 - val_accuracy: 0.7880\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7310 - accuracy: 0.7859 - val_loss: 0.7280 - val_accuracy: 0.7922\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7284 - accuracy: 0.7879 - val_loss: 0.7245 - val_accuracy: 0.7918\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.7249 - accuracy: 0.7897 - val_loss: 0.7385 - val_accuracy: 0.7846\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7224 - accuracy: 0.7901 - val_loss: 0.7261 - val_accuracy: 0.8014\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.7235 - accuracy: 0.7893\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.7886 - accuracy: 0.3079 - val_loss: 1.4850 - val_accuracy: 0.4484\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.3207 - accuracy: 0.5046 - val_loss: 1.1835 - val_accuracy: 0.5704\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.1420 - accuracy: 0.6051 - val_loss: 1.0772 - val_accuracy: 0.6554\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.0520 - accuracy: 0.6548 - val_loss: 1.0194 - val_accuracy: 0.6804\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9951 - accuracy: 0.6821 - val_loss: 0.9760 - val_accuracy: 0.7032\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.9592 - accuracy: 0.6976 - val_loss: 0.9478 - val_accuracy: 0.7204\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9330 - accuracy: 0.7114 - val_loss: 0.9386 - val_accuracy: 0.7274\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9150 - accuracy: 0.7197 - val_loss: 0.9135 - val_accuracy: 0.7298\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.8987 - accuracy: 0.7255 - val_loss: 0.8947 - val_accuracy: 0.7472\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.8858 - accuracy: 0.7358 - val_loss: 0.8858 - val_accuracy: 0.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8722 - accuracy: 0.7447 - val_loss: 0.8749 - val_accuracy: 0.7596\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8592 - accuracy: 0.7476 - val_loss: 0.8626 - val_accuracy: 0.7572\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.8494 - accuracy: 0.7526 - val_loss: 0.8543 - val_accuracy: 0.7676\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8272 - accuracy: 0.7660 - val_loss: 0.8154 - val_accuracy: 0.7772\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7745 - accuracy: 0.7867 - val_loss: 0.7681 - val_accuracy: 0.7968\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.7419 - accuracy: 0.7954 - val_loss: 0.7459 - val_accuracy: 0.8048\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.7177 - accuracy: 0.8023 - val_loss: 0.7462 - val_accuracy: 0.7994\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7027 - accuracy: 0.8059 - val_loss: 0.7134 - val_accuracy: 0.8110\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6902 - accuracy: 0.8087 - val_loss: 0.7062 - val_accuracy: 0.8160\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.6798 - accuracy: 0.8114 - val_loss: 0.7000 - val_accuracy: 0.8132\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6706 - accuracy: 0.8140 - val_loss: 0.6883 - val_accuracy: 0.8178\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6635 - accuracy: 0.8168 - val_loss: 0.6837 - val_accuracy: 0.8182\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6571 - accuracy: 0.8167 - val_loss: 0.6854 - val_accuracy: 0.8216\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6509 - accuracy: 0.8194 - val_loss: 0.6718 - val_accuracy: 0.8244\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6466 - accuracy: 0.8214 - val_loss: 0.6678 - val_accuracy: 0.8200\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6411 - accuracy: 0.8225 - val_loss: 0.6644 - val_accuracy: 0.8230\n",
      "Epoch 27/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6374 - accuracy: 0.8240 - val_loss: 0.6646 - val_accuracy: 0.8290\n",
      "Epoch 28/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.6323 - accuracy: 0.8235 - val_loss: 0.6488 - val_accuracy: 0.8350\n",
      "Epoch 29/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6285 - accuracy: 0.8250 - val_loss: 0.6689 - val_accuracy: 0.8256\n",
      "Epoch 30/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6243 - accuracy: 0.8272 - val_loss: 0.6390 - val_accuracy: 0.8334\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.6741 - accuracy: 0.8146\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.4959 - accuracy: 0.4726 - val_loss: 1.1023 - val_accuracy: 0.6248\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9893 - accuracy: 0.6657 - val_loss: 0.9010 - val_accuracy: 0.6962\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8489 - accuracy: 0.7195 - val_loss: 0.7852 - val_accuracy: 0.7518\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7778 - accuracy: 0.7515 - val_loss: 0.7510 - val_accuracy: 0.7774\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7313 - accuracy: 0.7770 - val_loss: 0.7102 - val_accuracy: 0.8002\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6953 - accuracy: 0.7940 - val_loss: 0.6843 - val_accuracy: 0.8074\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6650 - accuracy: 0.8066 - val_loss: 0.6577 - val_accuracy: 0.8138\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6415 - accuracy: 0.8164 - val_loss: 0.6435 - val_accuracy: 0.8222\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6246 - accuracy: 0.8221 - val_loss: 0.6370 - val_accuracy: 0.8180\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6128 - accuracy: 0.8286 - val_loss: 0.6314 - val_accuracy: 0.8228\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6047 - accuracy: 0.8329 - val_loss: 0.6180 - val_accuracy: 0.8316\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5966 - accuracy: 0.8330 - val_loss: 0.6237 - val_accuracy: 0.8280\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5902 - accuracy: 0.8361 - val_loss: 0.6144 - val_accuracy: 0.8332\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5849 - accuracy: 0.8377 - val_loss: 0.6130 - val_accuracy: 0.8358\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5784 - accuracy: 0.8410 - val_loss: 0.6146 - val_accuracy: 0.8302\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5758 - accuracy: 0.8411 - val_loss: 0.6004 - val_accuracy: 0.8364\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5691 - accuracy: 0.8406 - val_loss: 0.5992 - val_accuracy: 0.8414\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5665 - accuracy: 0.8433 - val_loss: 0.6029 - val_accuracy: 0.8384\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5622 - accuracy: 0.8446 - val_loss: 0.5899 - val_accuracy: 0.8392\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5597 - accuracy: 0.8473 - val_loss: 0.6030 - val_accuracy: 0.8358\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5561 - accuracy: 0.8467 - val_loss: 0.5879 - val_accuracy: 0.8414\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5528 - accuracy: 0.8479 - val_loss: 0.5841 - val_accuracy: 0.8418\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5495 - accuracy: 0.8477 - val_loss: 0.5744 - val_accuracy: 0.8458\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5465 - accuracy: 0.8487 - val_loss: 0.5819 - val_accuracy: 0.8458\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5438 - accuracy: 0.8522 - val_loss: 0.5798 - val_accuracy: 0.8416\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.6064 - accuracy: 0.8373\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.6787 - accuracy: 0.3715 - val_loss: 1.2878 - val_accuracy: 0.6070\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.0698 - accuracy: 0.6846 - val_loss: 0.9025 - val_accuracy: 0.7380\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.8573 - accuracy: 0.7447 - val_loss: 0.7806 - val_accuracy: 0.7604\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7760 - accuracy: 0.7664 - val_loss: 0.7313 - val_accuracy: 0.7814\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7362 - accuracy: 0.7796 - val_loss: 0.6960 - val_accuracy: 0.7996\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.7083 - accuracy: 0.7901 - val_loss: 0.6794 - val_accuracy: 0.7990\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6859 - accuracy: 0.7983 - val_loss: 0.6574 - val_accuracy: 0.8150\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6659 - accuracy: 0.8046 - val_loss: 0.6444 - val_accuracy: 0.8132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6483 - accuracy: 0.8100 - val_loss: 0.6234 - val_accuracy: 0.8210\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6344 - accuracy: 0.8164 - val_loss: 0.6103 - val_accuracy: 0.8324\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6242 - accuracy: 0.8198 - val_loss: 0.5987 - val_accuracy: 0.8346\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6158 - accuracy: 0.8230 - val_loss: 0.5952 - val_accuracy: 0.8360\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6100 - accuracy: 0.8252 - val_loss: 0.5897 - val_accuracy: 0.8338\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6047 - accuracy: 0.8271 - val_loss: 0.5808 - val_accuracy: 0.8400\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.82 - 1s 37us/sample - loss: 0.6011 - accuracy: 0.8266 - val_loss: 0.5840 - val_accuracy: 0.8372\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5973 - accuracy: 0.8289 - val_loss: 0.5832 - val_accuracy: 0.8398\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.5945 - accuracy: 0.8302\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.3932 - accuracy: 0.5227 - val_loss: 0.8111 - val_accuracy: 0.7392\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6997 - accuracy: 0.7835 - val_loss: 0.5600 - val_accuracy: 0.8404\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5460 - accuracy: 0.8385 - val_loss: 0.4834 - val_accuracy: 0.8626\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4927 - accuracy: 0.8540 - val_loss: 0.4635 - val_accuracy: 0.8706\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4619 - accuracy: 0.8669 - val_loss: 0.4339 - val_accuracy: 0.8810\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4426 - accuracy: 0.8706 - val_loss: 0.4197 - val_accuracy: 0.8896\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4292 - accuracy: 0.8766 - val_loss: 0.4133 - val_accuracy: 0.8910\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4184 - accuracy: 0.8797 - val_loss: 0.4162 - val_accuracy: 0.8882\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4092 - accuracy: 0.8820 - val_loss: 0.4137 - val_accuracy: 0.8874\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 0.4604 - accuracy: 0.8742\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.6013 - accuracy: 0.3857 - val_loss: 1.2489 - val_accuracy: 0.5180\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.1276 - accuracy: 0.5809 - val_loss: 1.0195 - val_accuracy: 0.6360\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9580 - accuracy: 0.6747 - val_loss: 0.8751 - val_accuracy: 0.7164\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8200 - accuracy: 0.7407 - val_loss: 0.7626 - val_accuracy: 0.7740\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7275 - accuracy: 0.7829 - val_loss: 0.6903 - val_accuracy: 0.8108\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6676 - accuracy: 0.8076 - val_loss: 0.6445 - val_accuracy: 0.8216\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6135 - accuracy: 0.8273 - val_loss: 0.5896 - val_accuracy: 0.8408\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5648 - accuracy: 0.8421 - val_loss: 0.5558 - val_accuracy: 0.8538\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5336 - accuracy: 0.8523 - val_loss: 0.5582 - val_accuracy: 0.8474s - loss: 0.5342 - accuracy: 0.85\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5120 - accuracy: 0.8617 - val_loss: 0.5167 - val_accuracy: 0.8624\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4948 - accuracy: 0.8650 - val_loss: 0.5087 - val_accuracy: 0.8614\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4821 - accuracy: 0.8668 - val_loss: 0.4985 - val_accuracy: 0.8664\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4710 - accuracy: 0.8723 - val_loss: 0.4851 - val_accuracy: 0.8704\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4618 - accuracy: 0.8744 - val_loss: 0.4772 - val_accuracy: 0.8692ccu\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4526 - accuracy: 0.8773 - val_loss: 0.4772 - val_accuracy: 0.8718\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4462 - accuracy: 0.8781 - val_loss: 0.4671 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4387 - accuracy: 0.8807 - val_loss: 0.4624 - val_accuracy: 0.8802\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4336 - accuracy: 0.8831 - val_loss: 0.4764 - val_accuracy: 0.8782\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4284 - accuracy: 0.8827 - val_loss: 0.4758 - val_accuracy: 0.8732\n",
      "18333/18333 [==============================] - 1s 30us/sample - loss: 0.4961 - accuracy: 0.8686\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.6686 - accuracy: 0.3745 - val_loss: 1.2272 - val_accuracy: 0.5330\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.1758 - accuracy: 0.5352 - val_loss: 1.0814 - val_accuracy: 0.5690\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0987 - accuracy: 0.5724 - val_loss: 1.0210 - val_accuracy: 0.6130\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0415 - accuracy: 0.6033 - val_loss: 0.9750 - val_accuracy: 0.6328\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9795 - accuracy: 0.6257 - val_loss: 0.9129 - val_accuracy: 0.6536\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.9182 - accuracy: 0.6653 - val_loss: 0.8507 - val_accuracy: 0.7410\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8474 - accuracy: 0.7387 - val_loss: 0.7746 - val_accuracy: 0.7732\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.7895 - accuracy: 0.7573 - val_loss: 0.7378 - val_accuracy: 0.7852\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7504 - accuracy: 0.7706 - val_loss: 0.6990 - val_accuracy: 0.7882\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7175 - accuracy: 0.7848 - val_loss: 0.6724 - val_accuracy: 0.7970\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6908 - accuracy: 0.7968 - val_loss: 0.6511 - val_accuracy: 0.8086\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6679 - accuracy: 0.8046 - val_loss: 0.6437 - val_accuracy: 0.8142\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6486 - accuracy: 0.8141 - val_loss: 0.6232 - val_accuracy: 0.8212\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.6321 - accuracy: 0.8212 - val_loss: 0.6069 - val_accuracy: 0.8272\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6211 - accuracy: 0.8231 - val_loss: 0.6001 - val_accuracy: 0.8304\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6116 - accuracy: 0.8271 - val_loss: 0.6064 - val_accuracy: 0.8270\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6011 - accuracy: 0.8314 - val_loss: 0.5825 - val_accuracy: 0.8382\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5946 - accuracy: 0.8319 - val_loss: 0.5836 - val_accuracy: 0.8400\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5876 - accuracy: 0.8350 - val_loss: 0.5842 - val_accuracy: 0.8364\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.6097 - accuracy: 0.8289\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.3867 - accuracy: 0.5633 - val_loss: 0.9517 - val_accuracy: 0.7670\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.8340 - accuracy: 0.7861 - val_loss: 0.7282 - val_accuracy: 0.8178\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6908 - accuracy: 0.8134 - val_loss: 0.6433 - val_accuracy: 0.8312\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6251 - accuracy: 0.8250 - val_loss: 0.5876 - val_accuracy: 0.8458\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.5705 - accuracy: 0.8413 - val_loss: 0.5356 - val_accuracy: 0.8582\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5233 - accuracy: 0.8541 - val_loss: 0.5124 - val_accuracy: 0.8554\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4951 - accuracy: 0.8597 - val_loss: 0.4766 - val_accuracy: 0.8700\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4703 - accuracy: 0.8669 - val_loss: 0.4565 - val_accuracy: 0.8756\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4519 - accuracy: 0.8737 - val_loss: 0.4592 - val_accuracy: 0.8732\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4388 - accuracy: 0.8775 - val_loss: 0.4369 - val_accuracy: 0.8802\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4272 - accuracy: 0.8812 - val_loss: 0.4415 - val_accuracy: 0.8826\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4175 - accuracy: 0.8846 - val_loss: 0.4185 - val_accuracy: 0.8880\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4113 - accuracy: 0.8860 - val_loss: 0.4123 - val_accuracy: 0.8884\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.4039 - accuracy: 0.8875 - val_loss: 0.4185 - val_accuracy: 0.8876\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3995 - accuracy: 0.8906 - val_loss: 0.4120 - val_accuracy: 0.8892\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3946 - accuracy: 0.8911 - val_loss: 0.4015 - val_accuracy: 0.8922\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3902 - accuracy: 0.8922 - val_loss: 0.4092 - val_accuracy: 0.8912\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3861 - accuracy: 0.8933 - val_loss: 0.4096 - val_accuracy: 0.8880\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.4509 - accuracy: 0.8793\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.1869 - accuracy: 0.5856 - val_loss: 0.7155 - val_accuracy: 0.7982\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5925 - accuracy: 0.8382 - val_loss: 0.5048 - val_accuracy: 0.8650\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4610 - accuracy: 0.8720 - val_loss: 0.4397 - val_accuracy: 0.8848\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4113 - accuracy: 0.8859 - val_loss: 0.3909 - val_accuracy: 0.8974\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3844 - accuracy: 0.8929 - val_loss: 0.3719 - val_accuracy: 0.9010\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3678 - accuracy: 0.8985 - val_loss: 0.3697 - val_accuracy: 0.9018\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3542 - accuracy: 0.9001 - val_loss: 0.3479 - val_accuracy: 0.9084\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3454 - accuracy: 0.9015 - val_loss: 0.3638 - val_accuracy: 0.9044\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3378 - accuracy: 0.9064 - val_loss: 0.3538 - val_accuracy: 0.9012\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3776 - accuracy: 0.8928\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.2732 - accuracy: 0.5769 - val_loss: 0.7272 - val_accuracy: 0.7828\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6450 - accuracy: 0.8072 - val_loss: 0.5431 - val_accuracy: 0.8478\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5314 - accuracy: 0.8470 - val_loss: 0.4768 - val_accuracy: 0.8686\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4821 - accuracy: 0.8618 - val_loss: 0.4514 - val_accuracy: 0.8734\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4541 - accuracy: 0.8702 - val_loss: 0.4257 - val_accuracy: 0.8804\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.4347 - accuracy: 0.8747 - val_loss: 0.4296 - val_accuracy: 0.8772\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4217 - accuracy: 0.8782 - val_loss: 0.4040 - val_accuracy: 0.8852\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4113 - accuracy: 0.8814 - val_loss: 0.4053 - val_accuracy: 0.8838\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4021 - accuracy: 0.8854 - val_loss: 0.3973 - val_accuracy: 0.8852\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3957 - accuracy: 0.8868 - val_loss: 0.3918 - val_accuracy: 0.8868\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3893 - accuracy: 0.8891 - val_loss: 0.3933 - val_accuracy: 0.8840\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3836 - accuracy: 0.8905 - val_loss: 0.3823 - val_accuracy: 0.8900\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3786 - accuracy: 0.8918 - val_loss: 0.3830 - val_accuracy: 0.8876\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3761 - accuracy: 0.8918 - val_loss: 0.3743 - val_accuracy: 0.8942\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3715 - accuracy: 0.8946 - val_loss: 0.3800 - val_accuracy: 0.8910\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3686 - accuracy: 0.8950 - val_loss: 0.3805 - val_accuracy: 0.8894\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.3978 - accuracy: 0.8846\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.9609 - accuracy: 0.7043 - val_loss: 0.6161 - val_accuracy: 0.8232\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5430 - accuracy: 0.8388 - val_loss: 0.4959 - val_accuracy: 0.8614\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4687 - accuracy: 0.8638 - val_loss: 0.4495 - val_accuracy: 0.8806\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4280 - accuracy: 0.8783 - val_loss: 0.4115 - val_accuracy: 0.8906\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3994 - accuracy: 0.8856 - val_loss: 0.3961 - val_accuracy: 0.8914\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3787 - accuracy: 0.8929 - val_loss: 0.3754 - val_accuracy: 0.8992\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3627 - accuracy: 0.8987 - val_loss: 0.3602 - val_accuracy: 0.9006\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3498 - accuracy: 0.9025 - val_loss: 0.3525 - val_accuracy: 0.9014\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3399 - accuracy: 0.9051 - val_loss: 0.3610 - val_accuracy: 0.8966\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3316 - accuracy: 0.9076 - val_loss: 0.3385 - val_accuracy: 0.9044\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3258 - accuracy: 0.9092 - val_loss: 0.3448 - val_accuracy: 0.9046\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3202 - accuracy: 0.9115 - val_loss: 0.3345 - val_accuracy: 0.9078\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 63us/sample - loss: 0.3161 - accuracy: 0.9132 - val_loss: 0.3404 - val_accuracy: 0.9042\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3134 - accuracy: 0.9126 - val_loss: 0.3371 - val_accuracy: 0.9034\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3787 - accuracy: 0.8990\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.1028 - accuracy: 0.6516 - val_loss: 0.5883 - val_accuracy: 0.8370s - loss: 1.4\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5222 - accuracy: 0.8485 - val_loss: 0.4580 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4341 - accuracy: 0.8754 - val_loss: 0.3959 - val_accuracy: 0.8942\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3944 - accuracy: 0.8861 - val_loss: 0.3718 - val_accuracy: 0.8946\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3733 - accuracy: 0.8930 - val_loss: 0.3612 - val_accuracy: 0.8950\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3571 - accuracy: 0.8977 - val_loss: 0.3456 - val_accuracy: 0.9042\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3441 - accuracy: 0.9027 - val_loss: 0.3368 - val_accuracy: 0.9018\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3342 - accuracy: 0.9050 - val_loss: 0.3410 - val_accuracy: 0.9060\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3253 - accuracy: 0.9071 - val_loss: 0.3817 - val_accuracy: 0.8856\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3721 - accuracy: 0.8928\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.0558 - accuracy: 0.6431 - val_loss: 0.5675 - val_accuracy: 0.8316\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5442 - accuracy: 0.8414 - val_loss: 0.4630 - val_accuracy: 0.8690\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4729 - accuracy: 0.8650 - val_loss: 0.4179 - val_accuracy: 0.8856\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4310 - accuracy: 0.8781 - val_loss: 0.3891 - val_accuracy: 0.8938\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4017 - accuracy: 0.8871 - val_loss: 0.3645 - val_accuracy: 0.8996\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3792 - accuracy: 0.8956 - val_loss: 0.3695 - val_accuracy: 0.8994\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3629 - accuracy: 0.8991 - val_loss: 0.3410 - val_accuracy: 0.9074\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3509 - accuracy: 0.9033 - val_loss: 0.3493 - val_accuracy: 0.9060\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3406 - accuracy: 0.9067 - val_loss: 0.3426 - val_accuracy: 0.9056\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.3566 - accuracy: 0.9032\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 62us/sample - loss: 1.1230 - accuracy: 0.6224 - val_loss: 0.6482 - val_accuracy: 0.8308\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5207 - accuracy: 0.8559 - val_loss: 0.4351 - val_accuracy: 0.8856\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4163 - accuracy: 0.8829 - val_loss: 0.4002 - val_accuracy: 0.8942\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3769 - accuracy: 0.8930 - val_loss: 0.3638 - val_accuracy: 0.9020\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3511 - accuracy: 0.8996 - val_loss: 0.3579 - val_accuracy: 0.8980\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.3339 - accuracy: 0.9045 - val_loss: 0.3333 - val_accuracy: 0.9086\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3224 - accuracy: 0.9093 - val_loss: 0.3292 - val_accuracy: 0.9128\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3144 - accuracy: 0.9115 - val_loss: 0.3311 - val_accuracy: 0.9096\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3064 - accuracy: 0.9142 - val_loss: 0.3156 - val_accuracy: 0.9116\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3009 - accuracy: 0.9152 - val_loss: 0.3214 - val_accuracy: 0.9124\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2957 - accuracy: 0.9161 - val_loss: 0.3270 - val_accuracy: 0.9114\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.3464 - accuracy: 0.9067\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.0762 - accuracy: 0.6650 - val_loss: 0.6053 - val_accuracy: 0.8356\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5478 - accuracy: 0.8518 - val_loss: 0.4746 - val_accuracy: 0.8752\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4493 - accuracy: 0.8804 - val_loss: 0.3985 - val_accuracy: 0.8966\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.3984 - accuracy: 0.8938 - val_loss: 0.3741 - val_accuracy: 0.9006\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3647 - accuracy: 0.9017 - val_loss: 0.3569 - val_accuracy: 0.9072\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3424 - accuracy: 0.9074 - val_loss: 0.3430 - val_accuracy: 0.9118\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3240 - accuracy: 0.9129 - val_loss: 0.3329 - val_accuracy: 0.9124\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3106 - accuracy: 0.9155 - val_loss: 0.3231 - val_accuracy: 0.9158\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2999 - accuracy: 0.9185 - val_loss: 0.3322 - val_accuracy: 0.9126\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2906 - accuracy: 0.9217 - val_loss: 0.3138 - val_accuracy: 0.9194\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2839 - accuracy: 0.9230 - val_loss: 0.3074 - val_accuracy: 0.9204\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2766 - accuracy: 0.9245 - val_loss: 0.3066 - val_accuracy: 0.9208\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2712 - accuracy: 0.9253 - val_loss: 0.3064 - val_accuracy: 0.9218\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2664 - accuracy: 0.9266 - val_loss: 0.3064 - val_accuracy: 0.9194\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2630 - accuracy: 0.9264 - val_loss: 0.3087 - val_accuracy: 0.9198\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3278 - accuracy: 0.9114\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.9440 - accuracy: 0.7144 - val_loss: 0.5524 - val_accuracy: 0.8472\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4997 - accuracy: 0.8618 - val_loss: 0.4317 - val_accuracy: 0.8768\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4089 - accuracy: 0.8828 - val_loss: 0.3555 - val_accuracy: 0.9008\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3655 - accuracy: 0.8968 - val_loss: 0.3312 - val_accuracy: 0.9036\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3394 - accuracy: 0.9045 - val_loss: 0.3175 - val_accuracy: 0.9132\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3227 - accuracy: 0.9085 - val_loss: 0.3321 - val_accuracy: 0.9046\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3100 - accuracy: 0.9119 - val_loss: 0.2973 - val_accuracy: 0.9160\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2995 - accuracy: 0.9144 - val_loss: 0.3020 - val_accuracy: 0.9148\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2926 - accuracy: 0.9169 - val_loss: 0.2888 - val_accuracy: 0.9192\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2847 - accuracy: 0.9190 - val_loss: 0.2861 - val_accuracy: 0.9226\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2786 - accuracy: 0.9207 - val_loss: 0.2836 - val_accuracy: 0.9194\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.2728 - accuracy: 0.9224 - val_loss: 0.2778 - val_accuracy: 0.9218\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2677 - accuracy: 0.9239 - val_loss: 0.2839 - val_accuracy: 0.9202\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2645 - accuracy: 0.9232 - val_loss: 0.2824 - val_accuracy: 0.9236\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.2964 - accuracy: 0.9179\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.9587 - accuracy: 0.6963 - val_loss: 0.5168 - val_accuracy: 0.8596\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4374 - accuracy: 0.8737 - val_loss: 0.3680 - val_accuracy: 0.8984\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3536 - accuracy: 0.8968 - val_loss: 0.3203 - val_accuracy: 0.9122\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3148 - accuracy: 0.9082 - val_loss: 0.2994 - val_accuracy: 0.9160\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2859 - accuracy: 0.9177 - val_loss: 0.2744 - val_accuracy: 0.9260\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.2675 - accuracy: 0.9236 - val_loss: 0.2706 - val_accuracy: 0.9242\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2552 - accuracy: 0.9263 - val_loss: 0.2556 - val_accuracy: 0.9282\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2445 - accuracy: 0.9311 - val_loss: 0.2464 - val_accuracy: 0.9340\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.2354 - accuracy: 0.9328 - val_loss: 0.2443 - val_accuracy: 0.9324\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2289 - accuracy: 0.9354 - val_loss: 0.2386 - val_accuracy: 0.9370\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2229 - accuracy: 0.9368 - val_loss: 0.2410 - val_accuracy: 0.9356\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2182 - accuracy: 0.9381 - val_loss: 0.2350 - val_accuracy: 0.9396\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2141 - accuracy: 0.9385 - val_loss: 0.2400 - val_accuracy: 0.9366\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2108 - accuracy: 0.9402 - val_loss: 0.2469 - val_accuracy: 0.9392\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.2691 - accuracy: 0.9287\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.0418 - accuracy: 0.6648 - val_loss: 0.5897 - val_accuracy: 0.8318\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5095 - accuracy: 0.8543 - val_loss: 0.4301 - val_accuracy: 0.8734\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4053 - accuracy: 0.8855 - val_loss: 0.3633 - val_accuracy: 0.8978\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3580 - accuracy: 0.8992 - val_loss: 0.3338 - val_accuracy: 0.9030\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.3295 - accuracy: 0.9067 - val_loss: 0.3186 - val_accuracy: 0.9118\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3070 - accuracy: 0.9132 - val_loss: 0.3358 - val_accuracy: 0.9074\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2925 - accuracy: 0.9164 - val_loss: 0.2944 - val_accuracy: 0.9198\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2819 - accuracy: 0.9204 - val_loss: 0.3056 - val_accuracy: 0.9174\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2730 - accuracy: 0.9236 - val_loss: 0.3001 - val_accuracy: 0.9206\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3180 - accuracy: 0.9115\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.9898 - accuracy: 0.6743 - val_loss: 0.5035 - val_accuracy: 0.8522\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4628 - accuracy: 0.8693 - val_loss: 0.3914 - val_accuracy: 0.8892loss: 0\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3915 - accuracy: 0.8901 - val_loss: 0.3504 - val_accuracy: 0.9036\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3547 - accuracy: 0.9001 - val_loss: 0.3207 - val_accuracy: 0.9100\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3293 - accuracy: 0.9072 - val_loss: 0.3040 - val_accuracy: 0.9142\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3095 - accuracy: 0.9123 - val_loss: 0.3067 - val_accuracy: 0.9134\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2945 - accuracy: 0.9186 - val_loss: 0.2854 - val_accuracy: 0.9188s - loss: 0.2948 - accuracy\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2847 - accuracy: 0.9183 - val_loss: 0.2861 - val_accuracy: 0.9198\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2756 - accuracy: 0.9210 - val_loss: 0.2695 - val_accuracy: 0.9230\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2686 - accuracy: 0.9242 - val_loss: 0.2655 - val_accuracy: 0.9262\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2624 - accuracy: 0.9250 - val_loss: 0.2713 - val_accuracy: 0.9242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2588 - accuracy: 0.9258 - val_loss: 0.2575 - val_accuracy: 0.9284\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2542 - accuracy: 0.9286 - val_loss: 0.2737 - val_accuracy: 0.9226\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2498 - accuracy: 0.9287 - val_loss: 0.2543 - val_accuracy: 0.9260\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2465 - accuracy: 0.9294 - val_loss: 0.2609 - val_accuracy: 0.9268\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2427 - accuracy: 0.9306 - val_loss: 0.2652 - val_accuracy: 0.9254\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.2812 - accuracy: 0.9222\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.11263010 - accu\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.9420 - accuracy: 0.2240 - val_loss: 1.8189 - val_accuracy: 0.3032\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.7658 - accuracy: 0.3250 - val_loss: 1.7174 - val_accuracy: 0.3424\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 1.6944 - accuracy: 0.3542 - val_loss: 1.6653 - val_accuracy: 0.3760\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6512 - accuracy: 0.3798 - val_loss: 1.6320 - val_accuracy: 0.3802\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6234 - accuracy: 0.3839 - val_loss: 1.6094 - val_accuracy: 0.3882\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5991 - accuracy: 0.3914 - val_loss: 1.5852 - val_accuracy: 0.3944\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.5713 - accuracy: 0.3949 - val_loss: 1.5515 - val_accuracy: 0.3950\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5395 - accuracy: 0.3878 - val_loss: 1.5205 - val_accuracy: 0.3984\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5141 - accuracy: 0.4041 - val_loss: 1.5027 - val_accuracy: 0.3988\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.4970 - accuracy: 0.4011 - val_loss: 1.4939 - val_accuracy: 0.3992\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4878 - accuracy: 0.4054 - val_loss: 1.4811 - val_accuracy: 0.4046\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.4758 - accuracy: 0.4085 - val_loss: 1.4752 - val_accuracy: 0.4002\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4698 - accuracy: 0.4095 - val_loss: 1.4672 - val_accuracy: 0.4004\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.4626 - accuracy: 0.4081 - val_loss: 1.4706 - val_accuracy: 0.4042\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.4573 - accuracy: 0.4088 - val_loss: 1.4636 - val_accuracy: 0.4094\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4521 - accuracy: 0.4123 - val_loss: 1.4602 - val_accuracy: 0.4108\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.4470 - accuracy: 0.4094 - val_loss: 1.4642 - val_accuracy: 0.4026\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.4414 - accuracy: 0.4104 - val_loss: 1.4506 - val_accuracy: 0.4008\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.4394 - accuracy: 0.4084 - val_loss: 1.4516 - val_accuracy: 0.4042\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4357 - accuracy: 0.4124 - val_loss: 1.4442 - val_accuracy: 0.4024\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4320 - accuracy: 0.4107 - val_loss: 1.4489 - val_accuracy: 0.4040\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.4291 - accuracy: 0.4098 - val_loss: 1.4430 - val_accuracy: 0.4104\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.4264 - accuracy: 0.4090 - val_loss: 1.4402 - val_accuracy: 0.4064\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4225 - accuracy: 0.4135 - val_loss: 1.4433 - val_accuracy: 0.3992\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4218 - accuracy: 0.4102 - val_loss: 1.4402 - val_accuracy: 0.4116\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.4188 - accuracy: 0.4146 - val_loss: 1.4424 - val_accuracy: 0.4100\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4169 - accuracy: 0.4124 - val_loss: 1.4338 - val_accuracy: 0.4156\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4136 - accuracy: 0.4157 - val_loss: 1.4251 - val_accuracy: 0.4182\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4112 - accuracy: 0.4147 - val_loss: 1.4277 - val_accuracy: 0.4110\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4099 - accuracy: 0.4138 - val_loss: 1.4300 - val_accuracy: 0.4162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18333/18333 [==============================] - 0s 25us/sample - loss: 1.4635 - accuracy: 0.4048s - loss: 1.4682 - accuracy: 0.\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 1.7020 - accuracy: 0.3672 - val_loss: 1.3594 - val_accuracy: 0.4648\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.2308 - accuracy: 0.5500 - val_loss: 1.1276 - val_accuracy: 0.5974\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.1018 - accuracy: 0.6131 - val_loss: 1.0515 - val_accuracy: 0.64261.111\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.0552 - accuracy: 0.6291 - val_loss: 1.0231 - val_accuracy: 0.6520\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.0257 - accuracy: 0.6392 - val_loss: 0.9997 - val_accuracy: 0.6578\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.0001 - accuracy: 0.6455 - val_loss: 0.9779 - val_accuracy: 0.6622\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 65us/sample - loss: 0.9674 - accuracy: 0.6690 - val_loss: 0.9445 - val_accuracy: 0.6840\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.9336 - accuracy: 0.6906 - val_loss: 0.9243 - val_accuracy: 0.6886\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.9092 - accuracy: 0.7089 - val_loss: 0.8903 - val_accuracy: 0.7284\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.8879 - accuracy: 0.7231 - val_loss: 0.8839 - val_accuracy: 0.7370\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.8711 - accuracy: 0.7320 - val_loss: 0.8704 - val_accuracy: 0.7480\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8592 - accuracy: 0.7416 - val_loss: 0.8687 - val_accuracy: 0.7494\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.8489 - accuracy: 0.7457 - val_loss: 0.8609 - val_accuracy: 0.7566\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.8430 - accuracy: 0.7508 - val_loss: 0.8487 - val_accuracy: 0.7602\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.8358 - accuracy: 0.7548 - val_loss: 0.8485 - val_accuracy: 0.7650\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.8307 - accuracy: 0.7580 - val_loss: 0.8347 - val_accuracy: 0.7628\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.8259 - accuracy: 0.7578 - val_loss: 0.8372 - val_accuracy: 0.7602\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.8198 - accuracy: 0.7600 - val_loss: 0.8302 - val_accuracy: 0.7642\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.8129 - accuracy: 0.7615 - val_loss: 0.8204 - val_accuracy: 0.7652\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.8080 - accuracy: 0.7635 - val_loss: 0.8281 - val_accuracy: 0.7724\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.8011 - accuracy: 0.7641 - val_loss: 0.8102 - val_accuracy: 0.7684\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7960 - accuracy: 0.7652 - val_loss: 0.8062 - val_accuracy: 0.7720\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7906 - accuracy: 0.7676 - val_loss: 0.8072 - val_accuracy: 0.7716\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7887 - accuracy: 0.7694 - val_loss: 0.7971 - val_accuracy: 0.7786\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.7852 - accuracy: 0.7706 - val_loss: 0.8025 - val_accuracy: 0.7734\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7824 - accuracy: 0.7710 - val_loss: 0.8010 - val_accuracy: 0.7690s - loss: 0.783\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.8707 - accuracy: 0.7555\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7248 - accuracy: 0.3370 - val_loss: 1.4023 - val_accuracy: 0.5380\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.2879 - accuracy: 0.5479 - val_loss: 1.2442 - val_accuracy: 0.5822\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.1951 - accuracy: 0.5773 - val_loss: 1.1898 - val_accuracy: 0.5920\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.1545 - accuracy: 0.5877 - val_loss: 1.2010 - val_accuracy: 0.5810\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1167 - accuracy: 0.6044 - val_loss: 1.1198 - val_accuracy: 0.6328\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0813 - accuracy: 0.6230 - val_loss: 1.0956 - val_accuracy: 0.6296\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0561 - accuracy: 0.6312 - val_loss: 1.0729 - val_accuracy: 0.6408ccura\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0389 - accuracy: 0.6385 - val_loss: 1.0586 - val_accuracy: 0.6468\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0258 - accuracy: 0.6467 - val_loss: 1.0445 - val_accuracy: 0.6470\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0149 - accuracy: 0.6507 - val_loss: 1.0373 - val_accuracy: 0.6644\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.0067 - accuracy: 0.6581 - val_loss: 1.0451 - val_accuracy: 0.6530\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9996 - accuracy: 0.6593 - val_loss: 1.0307 - val_accuracy: 0.6670\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.9943 - accuracy: 0.6634 - val_loss: 1.0317 - val_accuracy: 0.6732\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9895 - accuracy: 0.6651 - val_loss: 1.0287 - val_accuracy: 0.6634\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9849 - accuracy: 0.6677 - val_loss: 1.0331 - val_accuracy: 0.6526\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.9808 - accuracy: 0.6701 - val_loss: 1.0153 - val_accuracy: 0.6662\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9765 - accuracy: 0.6702 - val_loss: 1.0089 - val_accuracy: 0.6840\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9732 - accuracy: 0.6718 - val_loss: 1.0050 - val_accuracy: 0.6738\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.9682 - accuracy: 0.6749 - val_loss: 1.0245 - val_accuracy: 0.6608\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9653 - accuracy: 0.6748 - val_loss: 1.0035 - val_accuracy: 0.6804\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9609 - accuracy: 0.6798 - val_loss: 0.9971 - val_accuracy: 0.6788\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9577 - accuracy: 0.6820 - val_loss: 1.0024 - val_accuracy: 0.6800\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.9547 - accuracy: 0.6833 - val_loss: 1.0049 - val_accuracy: 0.6768\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.0153 - accuracy: 0.6637\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.9559 - accuracy: 0.2470 - val_loss: 1.6159 - val_accuracy: 0.4074\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.4801 - accuracy: 0.4380 - val_loss: 1.3285 - val_accuracy: 0.5026\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.3058 - accuracy: 0.5202 - val_loss: 1.2208 - val_accuracy: 0.5666\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.2058 - accuracy: 0.5736 - val_loss: 1.1342 - val_accuracy: 0.6008\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1289 - accuracy: 0.6023 - val_loss: 1.0666 - val_accuracy: 0.6324\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0677 - accuracy: 0.6324 - val_loss: 1.0145 - val_accuracy: 0.6708\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9941 - accuracy: 0.6836 - val_loss: 0.9258 - val_accuracy: 0.7062\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9244 - accuracy: 0.7134 - val_loss: 0.8715 - val_accuracy: 0.7318\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.8822 - accuracy: 0.7266 - val_loss: 0.8426 - val_accuracy: 0.7410\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8600 - accuracy: 0.7362 - val_loss: 0.8310 - val_accuracy: 0.7476\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8422 - accuracy: 0.7419 - val_loss: 0.8105 - val_accuracy: 0.7474\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8328 - accuracy: 0.7477 - val_loss: 0.8005 - val_accuracy: 0.7604\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.8219 - accuracy: 0.7486 - val_loss: 0.7943 - val_accuracy: 0.7638\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8158 - accuracy: 0.7516 - val_loss: 0.7880 - val_accuracy: 0.7672\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8112 - accuracy: 0.7546 - val_loss: 0.7941 - val_accuracy: 0.7666\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.8056 - accuracy: 0.7575 - val_loss: 0.7887 - val_accuracy: 0.7598\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.8048 - accuracy: 0.7557\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 65us/sample - loss: 1.7171 - accuracy: 0.3243 - val_loss: 1.3187 - val_accuracy: 0.5088\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.1948 - accuracy: 0.5923 - val_loss: 1.0963 - val_accuracy: 0.6494\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.0453 - accuracy: 0.6561 - val_loss: 1.0034 - val_accuracy: 0.6928\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.9710 - accuracy: 0.6762 - val_loss: 0.9601 - val_accuracy: 0.6930\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.9220 - accuracy: 0.6816 - val_loss: 0.9192 - val_accuracy: 0.6910\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8796 - accuracy: 0.6874 - val_loss: 0.8861 - val_accuracy: 0.6960\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.8381 - accuracy: 0.6967 - val_loss: 0.8564 - val_accuracy: 0.7060\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.7954 - accuracy: 0.7314 - val_loss: 0.7948 - val_accuracy: 0.7542\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.7575 - accuracy: 0.7586 - val_loss: 0.7910 - val_accuracy: 0.7600\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.7369 - accuracy: 0.7717 - val_loss: 0.7690 - val_accuracy: 0.7826\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.7158 - accuracy: 0.7839 - val_loss: 0.7348 - val_accuracy: 0.7954\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6955 - accuracy: 0.8016 - val_loss: 0.7149 - val_accuracy: 0.8126\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6770 - accuracy: 0.8141 - val_loss: 0.7073 - val_accuracy: 0.8170\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6642 - accuracy: 0.8230 - val_loss: 0.7082 - val_accuracy: 0.8252\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.6563 - accuracy: 0.8249 - val_loss: 0.6920 - val_accuracy: 0.8268\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6480 - accuracy: 0.8272 - val_loss: 0.6827 - val_accuracy: 0.8296\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.6418 - accuracy: 0.8297 - val_loss: 0.6876 - val_accuracy: 0.8268\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6365 - accuracy: 0.8322 - val_loss: 0.6812 - val_accuracy: 0.8270\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.6293 - accuracy: 0.8345 - val_loss: 0.6974 - val_accuracy: 0.8278\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6251 - accuracy: 0.8339 - val_loss: 0.6627 - val_accuracy: 0.8330\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6183 - accuracy: 0.8344 - val_loss: 0.6714 - val_accuracy: 0.8336\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.6143 - accuracy: 0.8361 - val_loss: 0.6617 - val_accuracy: 0.8336\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.6119 - accuracy: 0.8378 - val_loss: 0.6656 - val_accuracy: 0.8364\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 0.6109 - accuracy: 0.8378 - val_loss: 0.6620 - val_accuracy: 0.8354\n",
      "18334/18334 [==============================] - 1s 49us/sample - loss: 0.7062 - accuracy: 0.8193\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 2.0480 - accuracy: 0.2012 - val_loss: 1.8714 - val_accuracy: 0.2194\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.8131 - accuracy: 0.2674 - val_loss: 1.7514 - val_accuracy: 0.3410\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.7080 - accuracy: 0.3385 - val_loss: 1.6465 - val_accuracy: 0.3906\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6244 - accuracy: 0.3767 - val_loss: 1.5734 - val_accuracy: 0.3906\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5614 - accuracy: 0.4011 - val_loss: 1.5280 - val_accuracy: 0.4226\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.5213 - accuracy: 0.4133 - val_loss: 1.5023 - val_accuracy: 0.4292\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.4914 - accuracy: 0.4297 - val_loss: 1.5033 - val_accuracy: 0.4438\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4697 - accuracy: 0.4446 - val_loss: 1.4651 - val_accuracy: 0.4486\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4493 - accuracy: 0.4553 - val_loss: 1.4537 - val_accuracy: 0.4546\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.4281 - accuracy: 0.4648 - val_loss: 1.4400 - val_accuracy: 0.4674\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4161 - accuracy: 0.4703 - val_loss: 1.4280 - val_accuracy: 0.4648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.3980 - accuracy: 0.4749 - val_loss: 1.4256 - val_accuracy: 0.4590\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 3s 88us/sample - loss: 1.3854 - accuracy: 0.4779 - val_loss: 1.3987 - val_accuracy: 0.4796\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.3738 - accuracy: 0.4831 - val_loss: 1.3801 - val_accuracy: 0.4726\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.3650 - accuracy: 0.4842 - val_loss: 1.3858 - val_accuracy: 0.4824\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.3578 - accuracy: 0.4882 - val_loss: 1.3955 - val_accuracy: 0.4914\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 1.4116 - accuracy: 0.4696\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7832 - accuracy: 0.3121 - val_loss: 1.3092 - val_accuracy: 0.4984\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.1460 - accuracy: 0.6105 - val_loss: 1.0087 - val_accuracy: 0.6792\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9664 - accuracy: 0.6862 - val_loss: 0.8902 - val_accuracy: 0.7168\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8925 - accuracy: 0.7144 - val_loss: 0.8530 - val_accuracy: 0.7338\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.8500 - accuracy: 0.7326 - val_loss: 0.8242 - val_accuracy: 0.7434\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8239 - accuracy: 0.7430 - val_loss: 0.8013 - val_accuracy: 0.7598\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.8035 - accuracy: 0.7501 - val_loss: 0.7926 - val_accuracy: 0.7566\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7891 - accuracy: 0.7543 - val_loss: 0.7699 - val_accuracy: 0.7688\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7767 - accuracy: 0.7570 - val_loss: 0.7653 - val_accuracy: 0.7692\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7640 - accuracy: 0.7641 - val_loss: 0.7557 - val_accuracy: 0.7760\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.7531 - accuracy: 0.7680 - val_loss: 0.7426 - val_accuracy: 0.7840\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.7433 - accuracy: 0.7710 - val_loss: 0.7375 - val_accuracy: 0.7808\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7315 - accuracy: 0.7738 - val_loss: 0.7301 - val_accuracy: 0.7898\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7217 - accuracy: 0.7783 - val_loss: 0.7166 - val_accuracy: 0.7906\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7154 - accuracy: 0.7788 - val_loss: 0.7087 - val_accuracy: 0.7974\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7076 - accuracy: 0.7803 - val_loss: 0.7019 - val_accuracy: 0.7980\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7006 - accuracy: 0.7815 - val_loss: 0.7026 - val_accuracy: 0.7962\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6950 - accuracy: 0.7819 - val_loss: 0.6916 - val_accuracy: 0.7956\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6853 - accuracy: 0.7866 - val_loss: 0.6772 - val_accuracy: 0.7982\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6761 - accuracy: 0.7895 - val_loss: 0.6783 - val_accuracy: 0.7998\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6655 - accuracy: 0.7977 - val_loss: 0.6627 - val_accuracy: 0.8032\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6546 - accuracy: 0.8052 - val_loss: 0.6587 - val_accuracy: 0.8038\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6434 - accuracy: 0.8105 - val_loss: 0.6371 - val_accuracy: 0.8172\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6320 - accuracy: 0.8155 - val_loss: 0.6312 - val_accuracy: 0.8200\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6232 - accuracy: 0.8204 - val_loss: 0.6229 - val_accuracy: 0.8260\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6136 - accuracy: 0.8247 - val_loss: 0.6078 - val_accuracy: 0.8276\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6060 - accuracy: 0.8293 - val_loss: 0.6096 - val_accuracy: 0.8294\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5970 - accuracy: 0.8310 - val_loss: 0.6015 - val_accuracy: 0.8316\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5929 - accuracy: 0.8326 - val_loss: 0.5951 - val_accuracy: 0.8276\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5876 - accuracy: 0.8340 - val_loss: 0.5879 - val_accuracy: 0.8350\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.6065 - accuracy: 0.8308\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 1.5894 - accuracy: 0.4198 - val_loss: 1.1720 - val_accuracy: 0.6586\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9582 - accuracy: 0.7138 - val_loss: 0.8064 - val_accuracy: 0.7560\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.7945 - accuracy: 0.7590 - val_loss: 0.7656 - val_accuracy: 0.7564\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7402 - accuracy: 0.7770 - val_loss: 0.7016 - val_accuracy: 0.7936\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.7067 - accuracy: 0.7889 - val_loss: 0.6796 - val_accuracy: 0.8074\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6830 - accuracy: 0.7988 - val_loss: 0.6639 - val_accuracy: 0.8102\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6630 - accuracy: 0.8054 - val_loss: 0.6464 - val_accuracy: 0.8130\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6464 - accuracy: 0.8125 - val_loss: 0.6417 - val_accuracy: 0.8128\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6325 - accuracy: 0.8171 - val_loss: 0.6253 - val_accuracy: 0.8214\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.6219 - accuracy: 0.8222 - val_loss: 0.6288 - val_accuracy: 0.8244\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.6120 - accuracy: 0.8249 - val_loss: 0.6193 - val_accuracy: 0.8268\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.6021 - accuracy: 0.8298 - val_loss: 0.6187 - val_accuracy: 0.8278\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5939 - accuracy: 0.8320 - val_loss: 0.6184 - val_accuracy: 0.8328\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.5868 - accuracy: 0.8334 - val_loss: 0.6123 - val_accuracy: 0.8276\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5816 - accuracy: 0.8349 - val_loss: 0.5964 - val_accuracy: 0.8362\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5757 - accuracy: 0.8358 - val_loss: 0.5878 - val_accuracy: 0.8396\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5712 - accuracy: 0.8373 - val_loss: 0.6172 - val_accuracy: 0.8210\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5689 - accuracy: 0.8387 - val_loss: 0.5947 - val_accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.6168 - accuracy: 0.8261\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.5184 - accuracy: 0.4808 - val_loss: 1.0391 - val_accuracy: 0.6944\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9059 - accuracy: 0.7323 - val_loss: 0.7707 - val_accuracy: 0.7776\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7256 - accuracy: 0.7876 - val_loss: 0.6619 - val_accuracy: 0.8174\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6505 - accuracy: 0.8131 - val_loss: 0.6397 - val_accuracy: 0.8252\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6130 - accuracy: 0.8273 - val_loss: 0.5943 - val_accuracy: 0.8440\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5911 - accuracy: 0.8344 - val_loss: 0.5848 - val_accuracy: 0.8456\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.5742 - accuracy: 0.8406 - val_loss: 0.5742 - val_accuracy: 0.8474\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5605 - accuracy: 0.8464 - val_loss: 0.5562 - val_accuracy: 0.8588\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.5461 - accuracy: 0.8498 - val_loss: 0.5499 - val_accuracy: 0.8630\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.5360 - accuracy: 0.8534 - val_loss: 0.5370 - val_accuracy: 0.8616\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.5260 - accuracy: 0.8566 - val_loss: 0.5293 - val_accuracy: 0.8620\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.5174 - accuracy: 0.8594 - val_loss: 0.5175 - val_accuracy: 0.8710\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5113 - accuracy: 0.8625 - val_loss: 0.5316 - val_accuracy: 0.8614\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5052 - accuracy: 0.8638 - val_loss: 0.5092 - val_accuracy: 0.8694\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4984 - accuracy: 0.8657 - val_loss: 0.5069 - val_accuracy: 0.8712\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4958 - accuracy: 0.8670 - val_loss: 0.5111 - val_accuracy: 0.8700\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4904 - accuracy: 0.8687 - val_loss: 0.4967 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4856 - accuracy: 0.8693 - val_loss: 0.4889 - val_accuracy: 0.8784\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4835 - accuracy: 0.8703 - val_loss: 0.4937 - val_accuracy: 0.8756\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4805 - accuracy: 0.8731 - val_loss: 0.4831 - val_accuracy: 0.8834\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4765 - accuracy: 0.8728 - val_loss: 0.4869 - val_accuracy: 0.8774\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4721 - accuracy: 0.8743 - val_loss: 0.4833 - val_accuracy: 0.8784\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.5315 - accuracy: 0.8630\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.1329 - accuracy: 0.6134 - val_loss: 0.6507 - val_accuracy: 0.8190\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6158 - accuracy: 0.8214 - val_loss: 0.5596 - val_accuracy: 0.8510\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5501 - accuracy: 0.8434 - val_loss: 0.5133 - val_accuracy: 0.8668\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5184 - accuracy: 0.8548 - val_loss: 0.4949 - val_accuracy: 0.8690\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4961 - accuracy: 0.8602 - val_loss: 0.4866 - val_accuracy: 0.8680\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4835 - accuracy: 0.8645 - val_loss: 0.4762 - val_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4734 - accuracy: 0.8678 - val_loss: 0.4677 - val_accuracy: 0.8798\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4655 - accuracy: 0.8688 - val_loss: 0.4681 - val_accuracy: 0.8784\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4602 - accuracy: 0.8713 - val_loss: 0.4695 - val_accuracy: 0.8748\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.4655 - accuracy: 0.8730\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.4917 - accuracy: 0.4730 - val_loss: 0.9911 - val_accuracy: 0.7424\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8622 - accuracy: 0.7629 - val_loss: 0.7103 - val_accuracy: 0.8086\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.6883 - accuracy: 0.8070 - val_loss: 0.6118 - val_accuracy: 0.8288\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5931 - accuracy: 0.8353 - val_loss: 0.5363 - val_accuracy: 0.8558\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5359 - accuracy: 0.8498 - val_loss: 0.5108 - val_accuracy: 0.8664\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5014 - accuracy: 0.8597 - val_loss: 0.4768 - val_accuracy: 0.8736\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4790 - accuracy: 0.8665 - val_loss: 0.4697 - val_accuracy: 0.8780\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.4633 - accuracy: 0.8732 - val_loss: 0.4518 - val_accuracy: 0.8852\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4487 - accuracy: 0.8769 - val_loss: 0.4423 - val_accuracy: 0.8852\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4363 - accuracy: 0.8804 - val_loss: 0.4305 - val_accuracy: 0.8824\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 0.4258 - accuracy: 0.8827 - val_loss: 0.4205 - val_accuracy: 0.8912\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.4158 - accuracy: 0.8873 - val_loss: 0.4174 - val_accuracy: 0.8958\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4083 - accuracy: 0.8892 - val_loss: 0.4139 - val_accuracy: 0.8944\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4003 - accuracy: 0.8922 - val_loss: 0.4006 - val_accuracy: 0.9002\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3921 - accuracy: 0.8933 - val_loss: 0.3947 - val_accuracy: 0.8990\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3865 - accuracy: 0.8950 - val_loss: 0.3988 - val_accuracy: 0.9008\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3809 - accuracy: 0.8960 - val_loss: 0.3891 - val_accuracy: 0.8998\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3755 - accuracy: 0.8981 - val_loss: 0.3872 - val_accuracy: 0.9012\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3723 - accuracy: 0.8983 - val_loss: 0.3808 - val_accuracy: 0.9034\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3681 - accuracy: 0.8990 - val_loss: 0.3839 - val_accuracy: 0.9038\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3628 - accuracy: 0.9004 - val_loss: 0.3811 - val_accuracy: 0.9052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.4235 - accuracy: 0.8886\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.1952 - accuracy: 0.5850 - val_loss: 0.8019 - val_accuracy: 0.7538\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7121 - accuracy: 0.7891 - val_loss: 0.6130 - val_accuracy: 0.8322\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5880 - accuracy: 0.8321 - val_loss: 0.5365 - val_accuracy: 0.8588\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5176 - accuracy: 0.8562 - val_loss: 0.5065 - val_accuracy: 0.8592\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4802 - accuracy: 0.8689 - val_loss: 0.4695 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4548 - accuracy: 0.8751 - val_loss: 0.4468 - val_accuracy: 0.8840\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4388 - accuracy: 0.8813 - val_loss: 0.4400 - val_accuracy: 0.8884\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4291 - accuracy: 0.8835 - val_loss: 0.4295 - val_accuracy: 0.8890\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4223 - accuracy: 0.8867 - val_loss: 0.4459 - val_accuracy: 0.8856\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4154 - accuracy: 0.8888 - val_loss: 0.4287 - val_accuracy: 0.8910s - loss: 0.4112 - accuracy: \n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4107 - accuracy: 0.8892 - val_loss: 0.4168 - val_accuracy: 0.8916\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4062 - accuracy: 0.8910 - val_loss: 0.4248 - val_accuracy: 0.8952\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4036 - accuracy: 0.8919 - val_loss: 0.4264 - val_accuracy: 0.8926\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.4426 - accuracy: 0.8792\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 1.5517 - accuracy: 0.4217 - val_loss: 1.0546 - val_accuracy: 0.6552\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8804 - accuracy: 0.7291 - val_loss: 0.7583 - val_accuracy: 0.7708\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7188 - accuracy: 0.7878 - val_loss: 0.6507 - val_accuracy: 0.8052\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6424 - accuracy: 0.8111 - val_loss: 0.6159 - val_accuracy: 0.8192\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5919 - accuracy: 0.8297 - val_loss: 0.5770 - val_accuracy: 0.8350\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5493 - accuracy: 0.8425 - val_loss: 0.5264 - val_accuracy: 0.8508\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5118 - accuracy: 0.8532 - val_loss: 0.4942 - val_accuracy: 0.8602\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4875 - accuracy: 0.8586 - val_loss: 0.4953 - val_accuracy: 0.8606\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4702 - accuracy: 0.8649 - val_loss: 0.4791 - val_accuracy: 0.8654\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4577 - accuracy: 0.8690 - val_loss: 0.4590 - val_accuracy: 0.8734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4486 - accuracy: 0.8719 - val_loss: 0.4562 - val_accuracy: 0.8728\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.4403 - accuracy: 0.8727 - val_loss: 0.4548 - val_accuracy: 0.8688\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4330 - accuracy: 0.8759 - val_loss: 0.4394 - val_accuracy: 0.8770\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4280 - accuracy: 0.8773 - val_loss: 0.4377 - val_accuracy: 0.8788\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4227 - accuracy: 0.8779 - val_loss: 0.4377 - val_accuracy: 0.8764\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4199 - accuracy: 0.8789 - val_loss: 0.4526 - val_accuracy: 0.8698\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4155 - accuracy: 0.8808 - val_loss: 0.4374 - val_accuracy: 0.8762\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4129 - accuracy: 0.8819 - val_loss: 0.4242 - val_accuracy: 0.8762\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4096 - accuracy: 0.8814 - val_loss: 0.4447 - val_accuracy: 0.8694\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4068 - accuracy: 0.8818 - val_loss: 0.4201 - val_accuracy: 0.8802\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4051 - accuracy: 0.8845 - val_loss: 0.4187 - val_accuracy: 0.8834\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4020 - accuracy: 0.8838 - val_loss: 0.4248 - val_accuracy: 0.8792\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4003 - accuracy: 0.8846 - val_loss: 0.4228 - val_accuracy: 0.8832\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4306 - accuracy: 0.8760\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 78us/sample - loss: 1.5461 - accuracy: 0.4824 - val_loss: 1.1730 - val_accuracy: 0.6410\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.0065 - accuracy: 0.7004 - val_loss: 0.8737 - val_accuracy: 0.7756\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.8039 - accuracy: 0.7906 - val_loss: 0.7075 - val_accuracy: 0.8242\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6785 - accuracy: 0.8223 - val_loss: 0.6110 - val_accuracy: 0.8514\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5997 - accuracy: 0.8433 - val_loss: 0.5630 - val_accuracy: 0.8596\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5445 - accuracy: 0.8626 - val_loss: 0.5162 - val_accuracy: 0.8738\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.5053 - accuracy: 0.8716 - val_loss: 0.4914 - val_accuracy: 0.8786\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4770 - accuracy: 0.8809 - val_loss: 0.4907 - val_accuracy: 0.8806\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4608 - accuracy: 0.8837 - val_loss: 0.4691 - val_accuracy: 0.8850\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4501 - accuracy: 0.8880 - val_loss: 0.4613 - val_accuracy: 0.8886\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4403 - accuracy: 0.8902 - val_loss: 0.4714 - val_accuracy: 0.8856\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4329 - accuracy: 0.8922 - val_loss: 0.4605 - val_accuracy: 0.8898\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4273 - accuracy: 0.8957 - val_loss: 0.4654 - val_accuracy: 0.8866\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4230 - accuracy: 0.8958 - val_loss: 0.4610 - val_accuracy: 0.8870\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.5050 - accuracy: 0.8827\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.3151 - accuracy: 0.5464 - val_loss: 0.7527 - val_accuracy: 0.7922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6168 - accuracy: 0.8087 - val_loss: 0.5297 - val_accuracy: 0.8382\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4984 - accuracy: 0.8452 - val_loss: 0.4834 - val_accuracy: 0.8632\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4505 - accuracy: 0.8643 - val_loss: 0.4415 - val_accuracy: 0.8748\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4246 - accuracy: 0.8724 - val_loss: 0.4137 - val_accuracy: 0.8856\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4037 - accuracy: 0.8818 - val_loss: 0.3948 - val_accuracy: 0.8900\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3881 - accuracy: 0.8864 - val_loss: 0.3854 - val_accuracy: 0.8936\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3741 - accuracy: 0.8922 - val_loss: 0.3814 - val_accuracy: 0.8958\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3624 - accuracy: 0.8943 - val_loss: 0.3872 - val_accuracy: 0.8948\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3515 - accuracy: 0.8987 - val_loss: 0.3598 - val_accuracy: 0.9050\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3404 - accuracy: 0.9024 - val_loss: 0.3564 - val_accuracy: 0.9004\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3308 - accuracy: 0.9050 - val_loss: 0.3465 - val_accuracy: 0.9042\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3214 - accuracy: 0.9078 - val_loss: 0.3325 - val_accuracy: 0.9052\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3142 - accuracy: 0.9092 - val_loss: 0.3203 - val_accuracy: 0.9090\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3088 - accuracy: 0.9110 - val_loss: 0.3199 - val_accuracy: 0.9098\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3038 - accuracy: 0.9129 - val_loss: 0.3208 - val_accuracy: 0.9102\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2967 - accuracy: 0.9161 - val_loss: 0.3241 - val_accuracy: 0.9106\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.3568 - accuracy: 0.9000\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.2653 - accuracy: 0.6069 - val_loss: 0.7736 - val_accuracy: 0.8036\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6579 - accuracy: 0.8154 - val_loss: 0.4951 - val_accuracy: 0.8566\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5013 - accuracy: 0.8504 - val_loss: 0.4128 - val_accuracy: 0.8796\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4395 - accuracy: 0.8695 - val_loss: 0.3829 - val_accuracy: 0.8856\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4077 - accuracy: 0.8788 - val_loss: 0.3696 - val_accuracy: 0.8924\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3891 - accuracy: 0.8845 - val_loss: 0.3936 - val_accuracy: 0.8814\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3770 - accuracy: 0.8900 - val_loss: 0.3537 - val_accuracy: 0.8980\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3652 - accuracy: 0.8928 - val_loss: 0.3693 - val_accuracy: 0.8982\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3564 - accuracy: 0.8982 - val_loss: 0.3683 - val_accuracy: 0.8888\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3758 - accuracy: 0.8912\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.2698 - accuracy: 0.5637 - val_loss: 0.7619 - val_accuracy: 0.7706\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6296 - accuracy: 0.8185 - val_loss: 0.5294 - val_accuracy: 0.8544\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5212 - accuracy: 0.8514 - val_loss: 0.4768 - val_accuracy: 0.8672\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4736 - accuracy: 0.8632 - val_loss: 0.4528 - val_accuracy: 0.8716\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4453 - accuracy: 0.8726 - val_loss: 0.4259 - val_accuracy: 0.8790\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4237 - accuracy: 0.8784 - val_loss: 0.4156 - val_accuracy: 0.8838\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4067 - accuracy: 0.8847 - val_loss: 0.3972 - val_accuracy: 0.8950\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3885 - accuracy: 0.8903 - val_loss: 0.3842 - val_accuracy: 0.9008\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3770 - accuracy: 0.8953 - val_loss: 0.3990 - val_accuracy: 0.8926\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3673 - accuracy: 0.8981 - val_loss: 0.3845 - val_accuracy: 0.8950\n",
      "18334/18334 [==============================] - 0s 22us/sample - loss: 0.4258 - accuracy: 0.8844\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.4825 - accuracy: 0.4312 - val_loss: 0.9358 - val_accuracy: 0.6580\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.7536 - accuracy: 0.7625 - val_loss: 0.6142 - val_accuracy: 0.8318\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.5340 - accuracy: 0.8514 - val_loss: 0.4832 - val_accuracy: 0.8726\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4483 - accuracy: 0.8756 - val_loss: 0.4507 - val_accuracy: 0.8742\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 34us/sample - loss: 0.4114 - accuracy: 0.8862 - val_loss: 0.4207 - val_accuracy: 0.8896\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3892 - accuracy: 0.8917 - val_loss: 0.4002 - val_accuracy: 0.8962\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.3738 - accuracy: 0.8978 - val_loss: 0.3942 - val_accuracy: 0.8966\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3628 - accuracy: 0.9005 - val_loss: 0.4025 - val_accuracy: 0.8938\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3557 - accuracy: 0.9029 - val_loss: 0.3946 - val_accuracy: 0.8940\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.4118 - accuracy: 0.8882\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.2240 - accuracy: 0.5774 - val_loss: 0.6053 - val_accuracy: 0.8350\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5041 - accuracy: 0.8582 - val_loss: 0.4234 - val_accuracy: 0.8784\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4035 - accuracy: 0.8841 - val_loss: 0.3509 - val_accuracy: 0.9010\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3626 - accuracy: 0.8950 - val_loss: 0.3500 - val_accuracy: 0.8990\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3403 - accuracy: 0.9009 - val_loss: 0.3306 - val_accuracy: 0.9052\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3256 - accuracy: 0.9051 - val_loss: 0.3458 - val_accuracy: 0.8976\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3160 - accuracy: 0.9077 - val_loss: 0.3064 - val_accuracy: 0.9128\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3063 - accuracy: 0.9095 - val_loss: 0.3123 - val_accuracy: 0.9146\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.2974 - accuracy: 0.9122 - val_loss: 0.3031 - val_accuracy: 0.9124\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.2922 - accuracy: 0.9143 - val_loss: 0.2992 - val_accuracy: 0.9146\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2846 - accuracy: 0.9165 - val_loss: 0.3012 - val_accuracy: 0.9130\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2785 - accuracy: 0.9189 - val_loss: 0.2989 - val_accuracy: 0.9150\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2734 - accuracy: 0.9196 - val_loss: 0.3013 - val_accuracy: 0.9096\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.2688 - accuracy: 0.9215 - val_loss: 0.2801 - val_accuracy: 0.9190\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.2635 - accuracy: 0.9215 - val_loss: 0.2907 - val_accuracy: 0.9166\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2604 - accuracy: 0.9233 - val_loss: 0.2797 - val_accuracy: 0.9208\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2575 - accuracy: 0.9244 - val_loss: 0.2741 - val_accuracy: 0.9214\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2523 - accuracy: 0.9255 - val_loss: 0.2859 - val_accuracy: 0.9140\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2507 - accuracy: 0.9263 - val_loss: 0.2815 - val_accuracy: 0.9202\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.2978 - accuracy: 0.9180\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.9383 - accuracy: 0.7170 - val_loss: 0.5082 - val_accuracy: 0.8672\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4587 - accuracy: 0.8751 - val_loss: 0.3848 - val_accuracy: 0.8966\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3723 - accuracy: 0.8970 - val_loss: 0.3314 - val_accuracy: 0.9098\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3276 - accuracy: 0.9069 - val_loss: 0.3136 - val_accuracy: 0.9106\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3036 - accuracy: 0.9140 - val_loss: 0.2898 - val_accuracy: 0.9208\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.2887 - accuracy: 0.9178 - val_loss: 0.2763 - val_accuracy: 0.9252\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2776 - accuracy: 0.9221 - val_loss: 0.2865 - val_accuracy: 0.9236\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.2683 - accuracy: 0.9242 - val_loss: 0.2739 - val_accuracy: 0.9302\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.2612 - accuracy: 0.9256 - val_loss: 0.2775 - val_accuracy: 0.9284\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2562 - accuracy: 0.9276 - val_loss: 0.2702 - val_accuracy: 0.9296\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.2495 - accuracy: 0.9305 - val_loss: 0.2702 - val_accuracy: 0.9282\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2459 - accuracy: 0.9306 - val_loss: 0.2665 - val_accuracy: 0.9296\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.2426 - accuracy: 0.9321 - val_loss: 0.2823 - val_accuracy: 0.9232\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2386 - accuracy: 0.9335 - val_loss: 0.2807 - val_accuracy: 0.9246\n",
      "18334/18334 [==============================] - 1s 53us/sample - loss: 0.2883 - accuracy: 0.9205\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.0805 - accuracy: 0.6260 - val_loss: 0.5859 - val_accuracy: 0.8338\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4800 - accuracy: 0.8611 - val_loss: 0.3833 - val_accuracy: 0.8992\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3576 - accuracy: 0.8982 - val_loss: 0.3268 - val_accuracy: 0.9128\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3119 - accuracy: 0.9109 - val_loss: 0.3100 - val_accuracy: 0.9180\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2875 - accuracy: 0.9183 - val_loss: 0.2951 - val_accuracy: 0.9238\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.2741 - accuracy: 0.9218 - val_loss: 0.2927 - val_accuracy: 0.9218\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.2625 - accuracy: 0.9249 - val_loss: 0.2856 - val_accuracy: 0.9246\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.2550 - accuracy: 0.9269 - val_loss: 0.3128 - val_accuracy: 0.9218\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2498 - accuracy: 0.9297 - val_loss: 0.2804 - val_accuracy: 0.9240\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2453 - accuracy: 0.9303 - val_loss: 0.2682 - val_accuracy: 0.9316\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2408 - accuracy: 0.9315 - val_loss: 0.2587 - val_accuracy: 0.9300\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2374 - accuracy: 0.9327 - val_loss: 0.2758 - val_accuracy: 0.9282\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2341 - accuracy: 0.9342 - val_loss: 0.2594 - val_accuracy: 0.9314\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.2853 - accuracy: 0.9205\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.0401 - accuracy: 0.6803 - val_loss: 0.5663 - val_accuracy: 0.8456\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5102 - accuracy: 0.8619 - val_loss: 0.4162 - val_accuracy: 0.8920\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4164 - accuracy: 0.8881 - val_loss: 0.3547 - val_accuracy: 0.9068\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3661 - accuracy: 0.9011 - val_loss: 0.3342 - val_accuracy: 0.9098\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3366 - accuracy: 0.9078 - val_loss: 0.3023 - val_accuracy: 0.9168\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3176 - accuracy: 0.9123 - val_loss: 0.3163 - val_accuracy: 0.9142\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3036 - accuracy: 0.9169 - val_loss: 0.2869 - val_accuracy: 0.9222\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2914 - accuracy: 0.9183 - val_loss: 0.2867 - val_accuracy: 0.9202\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.2831 - accuracy: 0.9208 - val_loss: 0.2863 - val_accuracy: 0.9216\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.2774 - accuracy: 0.9218 - val_loss: 0.2874 - val_accuracy: 0.9228\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2705 - accuracy: 0.9238 - val_loss: 0.2765 - val_accuracy: 0.9222\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2657 - accuracy: 0.9256 - val_loss: 0.2742 - val_accuracy: 0.9252\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2602 - accuracy: 0.9278 - val_loss: 0.2809 - val_accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.2581 - accuracy: 0.9278 - val_loss: 0.2795 - val_accuracy: 0.9244\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.2886 - accuracy: 0.9190\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126ss: 2.3012 - accuracy - ETA: 0s - loss: 2.3012 - accuracy\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 2.3014 - accuracy: 0.1144s - loss: 2.3016 - accuracy\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 1.9407 - accuracy: 0.2179 - val_loss: 1.7670 - val_accuracy: 0.2574\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.7077 - accuracy: 0.3320 - val_loss: 1.6205 - val_accuracy: 0.3986\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.6046 - accuracy: 0.4011 - val_loss: 1.5519 - val_accuracy: 0.4246\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5448 - accuracy: 0.4272 - val_loss: 1.5025 - val_accuracy: 0.4392\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5052 - accuracy: 0.4321 - val_loss: 1.5021 - val_accuracy: 0.4140\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4789 - accuracy: 0.4369 - val_loss: 1.4606 - val_accuracy: 0.4490\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.4609 - accuracy: 0.4413 - val_loss: 1.4447 - val_accuracy: 0.4598\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.4450 - accuracy: 0.4522 - val_loss: 1.4328 - val_accuracy: 0.4634\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.4313 - accuracy: 0.4545 - val_loss: 1.4300 - val_accuracy: 0.4774\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.4210 - accuracy: 0.4610 - val_loss: 1.4201 - val_accuracy: 0.4516\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.4128 - accuracy: 0.4619 - val_loss: 1.4411 - val_accuracy: 0.4374\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4079 - accuracy: 0.4642 - val_loss: 1.4197 - val_accuracy: 0.4758\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.4016 - accuracy: 0.4672 - val_loss: 1.4368 - val_accuracy: 0.4808\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 3s 80us/sample - loss: 1.4042 - accuracy: 0.4692 - val_loss: 1.4142 - val_accuracy: 0.4652\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 1.3952 - accuracy: 0.4686 - val_loss: 1.4091 - val_accuracy: 0.4850\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.3968 - accuracy: 0.4674 - val_loss: 1.4528 - val_accuracy: 0.4702\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 1.3953 - accuracy: 0.4696 - val_loss: 1.4246 - val_accuracy: 0.4900\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 1.4310 - accuracy: 0.4728\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.9996 - accuracy: 0.2110 - val_loss: 1.9017 - val_accuracy: 0.2266\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.8605 - accuracy: 0.2390 - val_loss: 1.8292 - val_accuracy: 0.2556\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.7694 - accuracy: 0.2809 - val_loss: 1.7273 - val_accuracy: 0.2824\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.6921 - accuracy: 0.3000 - val_loss: 1.6796 - val_accuracy: 0.3252\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.6537 - accuracy: 0.3104 - val_loss: 1.6470 - val_accuracy: 0.3136\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.6315 - accuracy: 0.3221 - val_loss: 1.6256 - val_accuracy: 0.3526\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6177 - accuracy: 0.3351 - val_loss: 1.6130 - val_accuracy: 0.3408\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6035 - accuracy: 0.3656 - val_loss: 1.6024 - val_accuracy: 0.3882\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.5788 - accuracy: 0.3919 - val_loss: 1.5661 - val_accuracy: 0.3780\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5565 - accuracy: 0.3847 - val_loss: 1.5571 - val_accuracy: 0.3806\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.5447 - accuracy: 0.3875 - val_loss: 1.5530 - val_accuracy: 0.3836\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5368 - accuracy: 0.3893 - val_loss: 1.5393 - val_accuracy: 0.3910\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.5320 - accuracy: 0.3910 - val_loss: 1.5292 - val_accuracy: 0.3892\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5280 - accuracy: 0.3901 - val_loss: 1.5309 - val_accuracy: 0.3948\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5243 - accuracy: 0.3911 - val_loss: 1.5276 - val_accuracy: 0.4008\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5218 - accuracy: 0.3942 - val_loss: 1.5290 - val_accuracy: 0.3846\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5191 - accuracy: 0.3926 - val_loss: 1.5277 - val_accuracy: 0.3986\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.5550 - accuracy: 0.3897\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 2.0252 - accuracy: 0.2001 - val_loss: 1.8844 - val_accuracy: 0.2594\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.8149 - accuracy: 0.2904 - val_loss: 1.7281 - val_accuracy: 0.3256\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6823 - accuracy: 0.3367 - val_loss: 1.6129 - val_accuracy: 0.3654\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.5896 - accuracy: 0.3610 - val_loss: 1.5352 - val_accuracy: 0.3776\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5294 - accuracy: 0.3751 - val_loss: 1.4884 - val_accuracy: 0.3870\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4931 - accuracy: 0.3851 - val_loss: 1.4682 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4680 - accuracy: 0.3945 - val_loss: 1.4457 - val_accuracy: 0.3998\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4521 - accuracy: 0.4017 - val_loss: 1.4353 - val_accuracy: 0.4064\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4340 - accuracy: 0.4097 - val_loss: 1.4139 - val_accuracy: 0.4204\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4220 - accuracy: 0.4160 - val_loss: 1.4052 - val_accuracy: 0.4226\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4058 - accuracy: 0.4240 - val_loss: 1.3950 - val_accuracy: 0.4270\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.3950 - accuracy: 0.4248 - val_loss: 1.3875 - val_accuracy: 0.4316\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.3893 - accuracy: 0.4260 - val_loss: 1.3868 - val_accuracy: 0.4386\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.3839 - accuracy: 0.4294 - val_loss: 1.3772 - val_accuracy: 0.4346\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.3767 - accuracy: 0.4283 - val_loss: 1.3897 - val_accuracy: 0.4334\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.3745 - accuracy: 0.4300 - val_loss: 1.3764 - val_accuracy: 0.4308\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.3704 - accuracy: 0.4334 - val_loss: 1.3606 - val_accuracy: 0.4422\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.3669 - accuracy: 0.4329 - val_loss: 1.3648 - val_accuracy: 0.4432\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.3627 - accuracy: 0.4348 - val_loss: 1.3823 - val_accuracy: 0.4364\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 1.3655 - accuracy: 0.4425\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 1.9516 - accuracy: 0.2433 - val_loss: 1.8068 - val_accuracy: 0.3248\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.7427 - accuracy: 0.3356 - val_loss: 1.6911 - val_accuracy: 0.3574\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.6663 - accuracy: 0.3585 - val_loss: 1.6394 - val_accuracy: 0.3662\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.6255 - accuracy: 0.3651 - val_loss: 1.6027 - val_accuracy: 0.3982\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.5974 - accuracy: 0.3878 - val_loss: 1.5825 - val_accuracy: 0.4034\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.5676 - accuracy: 0.4111 - val_loss: 1.5353 - val_accuracy: 0.4446\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.5233 - accuracy: 0.4326 - val_loss: 1.4972 - val_accuracy: 0.4644\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.4795 - accuracy: 0.4424 - val_loss: 1.4612 - val_accuracy: 0.4520\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.4385 - accuracy: 0.4420 - val_loss: 1.4201 - val_accuracy: 0.4550\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.4041 - accuracy: 0.4620 - val_loss: 1.4044 - val_accuracy: 0.4816\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.3816 - accuracy: 0.4858 - val_loss: 1.3756 - val_accuracy: 0.4954\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.3586 - accuracy: 0.5034 - val_loss: 1.3561 - val_accuracy: 0.5200\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.3434 - accuracy: 0.5209 - val_loss: 1.3435 - val_accuracy: 0.5412\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.3243 - accuracy: 0.5386 - val_loss: 1.3387 - val_accuracy: 0.5588\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.3046 - accuracy: 0.5517 - val_loss: 1.3074 - val_accuracy: 0.5730\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.2873 - accuracy: 0.5599 - val_loss: 1.2843 - val_accuracy: 0.5714\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.2712 - accuracy: 0.5669 - val_loss: 1.2596 - val_accuracy: 0.5854\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.2587 - accuracy: 0.5757 - val_loss: 1.2619 - val_accuracy: 0.5914\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.2492 - accuracy: 0.5815 - val_loss: 1.2379 - val_accuracy: 0.5958\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.2397 - accuracy: 0.5827 - val_loss: 1.2281 - val_accuracy: 0.6026\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.2201 - accuracy: 0.5857 - val_loss: 1.2289 - val_accuracy: 0.5946\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.2130 - accuracy: 0.5841 - val_loss: 1.2240 - val_accuracy: 0.6004\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.2111 - accuracy: 0.5879 - val_loss: 1.2135 - val_accuracy: 0.6042\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.2028 - accuracy: 0.5855 - val_loss: 1.2218 - val_accuracy: 0.6006\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.2043 - accuracy: 0.5846 - val_loss: 1.2233 - val_accuracy: 0.6096\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 1.2616 - accuracy: 0.5814\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.7592 - accuracy: 0.3445 - val_loss: 1.4934 - val_accuracy: 0.4514\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.3815 - accuracy: 0.4948 - val_loss: 1.2803 - val_accuracy: 0.5420\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.2301 - accuracy: 0.5577 - val_loss: 1.1471 - val_accuracy: 0.5956\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.1173 - accuracy: 0.6151 - val_loss: 1.0598 - val_accuracy: 0.6400\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0461 - accuracy: 0.6518 - val_loss: 1.0118 - val_accuracy: 0.6696\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.0021 - accuracy: 0.6682 - val_loss: 0.9780 - val_accuracy: 0.6880\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9802 - accuracy: 0.6780 - val_loss: 0.9654 - val_accuracy: 0.6926\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9688 - accuracy: 0.6893 - val_loss: 0.9545 - val_accuracy: 0.6920\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.9580 - accuracy: 0.6959 - val_loss: 0.9603 - val_accuracy: 0.6966\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9483 - accuracy: 0.7040 - val_loss: 0.9506 - val_accuracy: 0.7090\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9401 - accuracy: 0.7110 - val_loss: 0.9360 - val_accuracy: 0.7208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.9342 - accuracy: 0.7115 - val_loss: 0.9394 - val_accuracy: 0.7212\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9276 - accuracy: 0.7183 - val_loss: 0.9308 - val_accuracy: 0.7268\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.9201 - accuracy: 0.7215 - val_loss: 0.9350 - val_accuracy: 0.7228\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9144 - accuracy: 0.7247 - val_loss: 0.9246 - val_accuracy: 0.7222\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9095 - accuracy: 0.7281 - val_loss: 0.9451 - val_accuracy: 0.7216\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9034 - accuracy: 0.7302 - val_loss: 0.9316 - val_accuracy: 0.7340\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.9686 - accuracy: 0.7106\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.9896 - accuracy: 0.2080 - val_loss: 1.8275 - val_accuracy: 0.2404\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7936 - accuracy: 0.2590 - val_loss: 1.7365 - val_accuracy: 0.2792\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.7228 - accuracy: 0.3092 - val_loss: 1.6723 - val_accuracy: 0.3368\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6705 - accuracy: 0.3462 - val_loss: 1.6349 - val_accuracy: 0.3760\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.6318 - accuracy: 0.3730 - val_loss: 1.5828 - val_accuracy: 0.3934\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5973 - accuracy: 0.3880 - val_loss: 1.5548 - val_accuracy: 0.4090\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5710 - accuracy: 0.3992 - val_loss: 1.5432 - val_accuracy: 0.4320\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5502 - accuracy: 0.4072 - val_loss: 1.5214 - val_accuracy: 0.4318\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.5349 - accuracy: 0.4154 - val_loss: 1.4968 - val_accuracy: 0.4394\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.5202 - accuracy: 0.4206 - val_loss: 1.4866 - val_accuracy: 0.4388\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5074 - accuracy: 0.4276 - val_loss: 1.4720 - val_accuracy: 0.4454\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4863 - accuracy: 0.4354 - val_loss: 1.4407 - val_accuracy: 0.4598\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.4649 - accuracy: 0.4448 - val_loss: 1.4245 - val_accuracy: 0.4664\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4541 - accuracy: 0.4469 - val_loss: 1.4195 - val_accuracy: 0.4644\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4452 - accuracy: 0.4489 - val_loss: 1.4137 - val_accuracy: 0.4640\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4367 - accuracy: 0.4523 - val_loss: 1.4175 - val_accuracy: 0.4718\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.4302 - accuracy: 0.4559 - val_loss: 1.4209 - val_accuracy: 0.4846\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 1.4375 - accuracy: 0.4410\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.9708 - accuracy: 0.2156 - val_loss: 1.6622 - val_accuracy: 0.3202\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.5008 - accuracy: 0.4167 - val_loss: 1.3640 - val_accuracy: 0.4586\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.3070 - accuracy: 0.5005 - val_loss: 1.2305 - val_accuracy: 0.5562\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.2023 - accuracy: 0.5650 - val_loss: 1.1408 - val_accuracy: 0.6056\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.1215 - accuracy: 0.6013 - val_loss: 1.0776 - val_accuracy: 0.6302\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 1.0629 - accuracy: 0.6397 - val_loss: 1.0157 - val_accuracy: 0.6706\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.0124 - accuracy: 0.6805 - val_loss: 0.9674 - val_accuracy: 0.7176\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9717 - accuracy: 0.7080 - val_loss: 0.9357 - val_accuracy: 0.7276\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9424 - accuracy: 0.7236 - val_loss: 0.9092 - val_accuracy: 0.7514\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9212 - accuracy: 0.7317 - val_loss: 0.9067 - val_accuracy: 0.7470\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.9072 - accuracy: 0.7386 - val_loss: 0.8838 - val_accuracy: 0.7592\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8961 - accuracy: 0.7435 - val_loss: 0.8765 - val_accuracy: 0.7642\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8896 - accuracy: 0.7440 - val_loss: 0.8788 - val_accuracy: 0.7628\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8833 - accuracy: 0.7456 - val_loss: 0.8670 - val_accuracy: 0.7614\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8797 - accuracy: 0.7488 - val_loss: 0.8874 - val_accuracy: 0.7622\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.8757 - accuracy: 0.7509 - val_loss: 0.8789 - val_accuracy: 0.7576\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.9279 - accuracy: 0.7420\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.6376 - accuracy: 0.3739 - val_loss: 1.2588 - val_accuracy: 0.6140\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 1.0853 - accuracy: 0.6660 - val_loss: 0.9288 - val_accuracy: 0.7394\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.8874 - accuracy: 0.7460 - val_loss: 0.8340 - val_accuracy: 0.7810\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.8187 - accuracy: 0.7704 - val_loss: 0.7959 - val_accuracy: 0.7896\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7781 - accuracy: 0.7870 - val_loss: 0.7623 - val_accuracy: 0.8028\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7446 - accuracy: 0.7972 - val_loss: 0.7458 - val_accuracy: 0.8106\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7196 - accuracy: 0.8062 - val_loss: 0.7308 - val_accuracy: 0.8160\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6957 - accuracy: 0.8130 - val_loss: 0.7405 - val_accuracy: 0.8158\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6779 - accuracy: 0.8192 - val_loss: 0.7448 - val_accuracy: 0.8086\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.7435 - accuracy: 0.8047\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.6820 - accuracy: 0.3314 - val_loss: 1.2141 - val_accuracy: 0.5014\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.0877 - accuracy: 0.6125 - val_loss: 0.9552 - val_accuracy: 0.7176\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9101 - accuracy: 0.7121 - val_loss: 0.8384 - val_accuracy: 0.7374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8371 - accuracy: 0.7358 - val_loss: 0.7985 - val_accuracy: 0.7534\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.7945 - accuracy: 0.7550 - val_loss: 0.7600 - val_accuracy: 0.7796\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7616 - accuracy: 0.7737 - val_loss: 0.7414 - val_accuracy: 0.7890\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7344 - accuracy: 0.7920 - val_loss: 0.7094 - val_accuracy: 0.8068\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7122 - accuracy: 0.8000 - val_loss: 0.6886 - val_accuracy: 0.8100\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6952 - accuracy: 0.8057 - val_loss: 0.6720 - val_accuracy: 0.8202\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 35us/sample - loss: 0.6822 - accuracy: 0.8088 - val_loss: 0.6814 - val_accuracy: 0.8106\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6735 - accuracy: 0.8128 - val_loss: 0.6575 - val_accuracy: 0.8242\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6661 - accuracy: 0.8161 - val_loss: 0.6481 - val_accuracy: 0.8264\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6609 - accuracy: 0.8198 - val_loss: 0.6429 - val_accuracy: 0.8340\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6543 - accuracy: 0.8194 - val_loss: 0.6445 - val_accuracy: 0.8298\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6514 - accuracy: 0.8193 - val_loss: 0.6390 - val_accuracy: 0.8294\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6462 - accuracy: 0.8230 - val_loss: 0.6548 - val_accuracy: 0.8220\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6432 - accuracy: 0.8235 - val_loss: 0.6410 - val_accuracy: 0.8260\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.6670 - accuracy: 0.8164\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.6249 - accuracy: 0.4325 - val_loss: 1.1435 - val_accuracy: 0.6262\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.9844 - accuracy: 0.6717 - val_loss: 0.8517 - val_accuracy: 0.7004\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.8191 - accuracy: 0.7035 - val_loss: 0.7652 - val_accuracy: 0.7302\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.7562 - accuracy: 0.7288 - val_loss: 0.7175 - val_accuracy: 0.7548\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6853 - accuracy: 0.7896 - val_loss: 0.6498 - val_accuracy: 0.8214\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6122 - accuracy: 0.8230 - val_loss: 0.5834 - val_accuracy: 0.8382\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5720 - accuracy: 0.8353 - val_loss: 0.5684 - val_accuracy: 0.8456\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.5452 - accuracy: 0.8432 - val_loss: 0.5520 - val_accuracy: 0.8478\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.5252 - accuracy: 0.8486 - val_loss: 0.5244 - val_accuracy: 0.8586\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5117 - accuracy: 0.8514 - val_loss: 0.5163 - val_accuracy: 0.8572\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.5002 - accuracy: 0.8544 - val_loss: 0.5109 - val_accuracy: 0.8616\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4899 - accuracy: 0.8589 - val_loss: 0.5033 - val_accuracy: 0.8682\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4835 - accuracy: 0.8606 - val_loss: 0.4989 - val_accuracy: 0.8652\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 35us/sample - loss: 0.4771 - accuracy: 0.8621 - val_loss: 0.5013 - val_accuracy: 0.8676\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.4722 - accuracy: 0.8655 - val_loss: 0.4952 - val_accuracy: 0.8664\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4685 - accuracy: 0.8658 - val_loss: 0.4813 - val_accuracy: 0.8764\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4648 - accuracy: 0.8656 - val_loss: 0.4800 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4605 - accuracy: 0.8684 - val_loss: 0.4925 - val_accuracy: 0.8690\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4586 - accuracy: 0.8692 - val_loss: 0.4911 - val_accuracy: 0.8676\n",
      "18334/18334 [==============================] - 1s 32us/sample - loss: 0.5153 - accuracy: 0.8567\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 96us/sample - loss: 1.8151 - accuracy: 0.3231 - val_loss: 1.5461 - val_accuracy: 0.4476\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.3603 - accuracy: 0.5138 - val_loss: 1.2300 - val_accuracy: 0.5418\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.0843 - accuracy: 0.6076 - val_loss: 0.9984 - val_accuracy: 0.6768\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.8956 - accuracy: 0.7303 - val_loss: 0.8153 - val_accuracy: 0.7690\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7569 - accuracy: 0.7794 - val_loss: 0.7138 - val_accuracy: 0.7962\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6803 - accuracy: 0.8022 - val_loss: 0.6337 - val_accuracy: 0.8222\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6316 - accuracy: 0.8153 - val_loss: 0.6109 - val_accuracy: 0.8298\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6049 - accuracy: 0.8225 - val_loss: 0.5887 - val_accuracy: 0.8312\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5870 - accuracy: 0.8292 - val_loss: 0.5840 - val_accuracy: 0.8368ss: 0.5865 - accuracy - ETA: 0s - loss: 0.5862 - accuracy - ETA: 0s - loss: 0.5896 - accuracy: \n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5751 - accuracy: 0.8330 - val_loss: 0.5733 - val_accuracy: 0.8398\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5647 - accuracy: 0.8371 - val_loss: 0.5677 - val_accuracy: 0.8446\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5546 - accuracy: 0.8418 - val_loss: 0.5782 - val_accuracy: 0.8416\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5451 - accuracy: 0.8466 - val_loss: 0.5609 - val_accuracy: 0.8448\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5355 - accuracy: 0.8509 - val_loss: 0.5493 - val_accuracy: 0.8494\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5279 - accuracy: 0.8537 - val_loss: 0.5390 - val_accuracy: 0.8534\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5214 - accuracy: 0.8565 - val_loss: 0.5486 - val_accuracy: 0.8516\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5147 - accuracy: 0.8581 - val_loss: 0.5359 - val_accuracy: 0.8580\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5106 - accuracy: 0.8604 - val_loss: 0.5588 - val_accuracy: 0.8522\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5081 - accuracy: 0.8622 - val_loss: 0.5320 - val_accuracy: 0.8576\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5046 - accuracy: 0.8634 - val_loss: 0.5317 - val_accuracy: 0.8568\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4999 - accuracy: 0.8627 - val_loss: 0.5293 - val_accuracy: 0.8592\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4956 - accuracy: 0.8642 - val_loss: 0.5223 - val_accuracy: 0.8590\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4933 - accuracy: 0.8657 - val_loss: 0.5246 - val_accuracy: 0.8628\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4906 - accuracy: 0.8673 - val_loss: 0.5090 - val_accuracy: 0.8652\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4868 - accuracy: 0.8672 - val_loss: 0.5171 - val_accuracy: 0.8590\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4838 - accuracy: 0.8699 - val_loss: 0.5092 - val_accuracy: 0.8662\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.5348 - accuracy: 0.8522\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 1.5230 - accuracy: 0.4552 - val_loss: 1.1686 - val_accuracy: 0.6052\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.9663 - accuracy: 0.6982 - val_loss: 0.7711 - val_accuracy: 0.7482\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7300 - accuracy: 0.7558 - val_loss: 0.6731 - val_accuracy: 0.7766\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6702 - accuracy: 0.7725 - val_loss: 0.6400 - val_accuracy: 0.8000\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6416 - accuracy: 0.7900 - val_loss: 0.6214 - val_accuracy: 0.8228\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6084 - accuracy: 0.8224 - val_loss: 0.5879 - val_accuracy: 0.8460\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5770 - accuracy: 0.8401 - val_loss: 0.5547 - val_accuracy: 0.8542\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.5572 - accuracy: 0.8469 - val_loss: 0.5580 - val_accuracy: 0.8572\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 0.5443 - accuracy: 0.8514 - val_loss: 0.5230 - val_accuracy: 0.8652\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 0.5323 - accuracy: 0.8564 - val_loss: 0.5338 - val_accuracy: 0.8604\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5233 - accuracy: 0.8568 - val_loss: 0.5356 - val_accuracy: 0.8606\n",
      "18333/18333 [==============================] - 1s 33us/sample - loss: 0.5436 - accuracy: 0.8538\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 67us/sample - loss: 1.5445 - accuracy: 0.4323 - val_loss: 1.1328 - val_accuracy: 0.5792\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.9989 - accuracy: 0.6242 - val_loss: 0.8069 - val_accuracy: 0.7128\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.7695 - accuracy: 0.7112 - val_loss: 0.7167 - val_accuracy: 0.7396\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6990 - accuracy: 0.7470 - val_loss: 0.6972 - val_accuracy: 0.7674ccu\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6496 - accuracy: 0.7901 - val_loss: 0.6396 - val_accuracy: 0.8048\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6082 - accuracy: 0.8125 - val_loss: 0.5880 - val_accuracy: 0.8298\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.5861 - accuracy: 0.8169 - val_loss: 0.5705 - val_accuracy: 0.8290\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5687 - accuracy: 0.8233 - val_loss: 0.5734 - val_accuracy: 0.8290\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5560 - accuracy: 0.8296 - val_loss: 0.5597 - val_accuracy: 0.8374\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5437 - accuracy: 0.8356 - val_loss: 0.5456 - val_accuracy: 0.8446\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.5309 - accuracy: 0.8412 - val_loss: 0.5518 - val_accuracy: 0.8502\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 0.5204 - accuracy: 0.8484 - val_loss: 0.5291 - val_accuracy: 0.8574\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.5122 - accuracy: 0.8517 - val_loss: 0.5261 - val_accuracy: 0.8616\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5026 - accuracy: 0.8554 - val_loss: 0.5118 - val_accuracy: 0.8624\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4923 - accuracy: 0.8574 - val_loss: 0.5036 - val_accuracy: 0.86420.4877 - ac\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4870 - accuracy: 0.8592 - val_loss: 0.5022 - val_accuracy: 0.8686\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4810 - accuracy: 0.8613 - val_loss: 0.5139 - val_accuracy: 0.8614\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.4766 - accuracy: 0.8631 - val_loss: 0.5036 - val_accuracy: 0.8650\n",
      "18334/18334 [==============================] - 1s 29us/sample - loss: 0.5530 - accuracy: 0.8491\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 1.4969 - accuracy: 0.4714 - val_loss: 0.9044 - val_accuracy: 0.7208\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.7654 - accuracy: 0.7505 - val_loss: 0.6498 - val_accuracy: 0.7932\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.6424 - accuracy: 0.7889 - val_loss: 0.5863 - val_accuracy: 0.8090\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.6035 - accuracy: 0.8025 - val_loss: 0.5652 - val_accuracy: 0.8190\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 0.5792 - accuracy: 0.8152 - val_loss: 0.5429 - val_accuracy: 0.8332\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.5595 - accuracy: 0.8260 - val_loss: 0.5373 - val_accuracy: 0.8292\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.5436 - accuracy: 0.8341 - val_loss: 0.5153 - val_accuracy: 0.8528\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.5281 - accuracy: 0.8416 - val_loss: 0.5020 - val_accuracy: 0.8588\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5110 - accuracy: 0.8510 - val_loss: 0.5070 - val_accuracy: 0.8538\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4956 - accuracy: 0.8563 - val_loss: 0.5048 - val_accuracy: 0.8640\n",
      "18333/18333 [==============================] - 1s 28us/sample - loss: 0.5744 - accuracy: 0.8365\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 1.4560 - accuracy: 0.4549 - val_loss: 0.8966 - val_accuracy: 0.7036\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.7690 - accuracy: 0.7587 - val_loss: 0.6548 - val_accuracy: 0.8010\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6356 - accuracy: 0.8057 - val_loss: 0.5687 - val_accuracy: 0.8312\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.5808 - accuracy: 0.8225 - val_loss: 0.5413 - val_accuracy: 0.8392\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5458 - accuracy: 0.8347 - val_loss: 0.5212 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5203 - accuracy: 0.8453 - val_loss: 0.5029 - val_accuracy: 0.8606\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.5023 - accuracy: 0.8499 - val_loss: 0.4831 - val_accuracy: 0.8632\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4853 - accuracy: 0.8530 - val_loss: 0.4929 - val_accuracy: 0.8584\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4777 - accuracy: 0.8580 - val_loss: 0.4681 - val_accuracy: 0.8644\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4681 - accuracy: 0.8603 - val_loss: 0.4568 - val_accuracy: 0.8704\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4628 - accuracy: 0.8627 - val_loss: 0.4528 - val_accuracy: 0.8746\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4574 - accuracy: 0.8644 - val_loss: 0.4531 - val_accuracy: 0.8710\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4531 - accuracy: 0.8650 - val_loss: 0.4465 - val_accuracy: 0.8726\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.4488 - accuracy: 0.8676 - val_loss: 0.4508 - val_accuracy: 0.8728\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4470 - accuracy: 0.8676 - val_loss: 0.4559 - val_accuracy: 0.8740\n",
      "18333/18333 [==============================] - 1s 31us/sample - loss: 0.4646 - accuracy: 0.8639\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 62us/sample - loss: 1.3504 - accuracy: 0.5288 - val_loss: 0.8072 - val_accuracy: 0.7820\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.6711 - accuracy: 0.8181 - val_loss: 0.5652 - val_accuracy: 0.8498\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5328 - accuracy: 0.8549 - val_loss: 0.5022 - val_accuracy: 0.8646\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4782 - accuracy: 0.8706 - val_loss: 0.4760 - val_accuracy: 0.8760\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4448 - accuracy: 0.8783 - val_loss: 0.4403 - val_accuracy: 0.8816\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4220 - accuracy: 0.8837 - val_loss: 0.4234 - val_accuracy: 0.8802\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4044 - accuracy: 0.8885 - val_loss: 0.4252 - val_accuracy: 0.8854\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 0.3911 - accuracy: 0.8918 - val_loss: 0.4147 - val_accuracy: 0.8860\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.3790 - accuracy: 0.8942 - val_loss: 0.4069 - val_accuracy: 0.8888\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3707 - accuracy: 0.8975 - val_loss: 0.4052 - val_accuracy: 0.8898\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3623 - accuracy: 0.8995 - val_loss: 0.4076 - val_accuracy: 0.8906\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3554 - accuracy: 0.9006 - val_loss: 0.4025 - val_accuracy: 0.8916\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3512 - accuracy: 0.9021 - val_loss: 0.4050 - val_accuracy: 0.8944\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3448 - accuracy: 0.9035 - val_loss: 0.3959 - val_accuracy: 0.8936\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.3394 - accuracy: 0.9060 - val_loss: 0.3840 - val_accuracy: 0.8956\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3338 - accuracy: 0.9064 - val_loss: 0.3753 - val_accuracy: 0.8998\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3270 - accuracy: 0.9077 - val_loss: 0.3833 - val_accuracy: 0.8990\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.3229 - accuracy: 0.9097 - val_loss: 0.3679 - val_accuracy: 0.9004\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3174 - accuracy: 0.9105 - val_loss: 0.3599 - val_accuracy: 0.9064\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.3120 - accuracy: 0.9132 - val_loss: 0.3743 - val_accuracy: 0.8992\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3054 - accuracy: 0.9139 - val_loss: 0.3586 - val_accuracy: 0.9062\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3030 - accuracy: 0.9151 - val_loss: 0.3673 - val_accuracy: 0.9008\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.2971 - accuracy: 0.9167 - val_loss: 0.3590 - val_accuracy: 0.9050\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.3926 - accuracy: 0.8967\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.6511 - accuracy: 0.3691 - val_loss: 1.2604 - val_accuracy: 0.5776\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9679 - accuracy: 0.6974 - val_loss: 0.7862 - val_accuracy: 0.7670\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7592 - accuracy: 0.7688 - val_loss: 0.6982 - val_accuracy: 0.7888\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6879 - accuracy: 0.7912 - val_loss: 0.6868 - val_accuracy: 0.7952\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6477 - accuracy: 0.8037 - val_loss: 0.6233 - val_accuracy: 0.8232\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.6207 - accuracy: 0.8145 - val_loss: 0.6038 - val_accuracy: 0.8274\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5961 - accuracy: 0.8219 - val_loss: 0.5760 - val_accuracy: 0.8344\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5761 - accuracy: 0.8289 - val_loss: 0.5760 - val_accuracy: 0.8392\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5590 - accuracy: 0.8355 - val_loss: 0.5512 - val_accuracy: 0.8416\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5475 - accuracy: 0.8397 - val_loss: 0.5481 - val_accuracy: 0.8490\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5375 - accuracy: 0.8430 - val_loss: 0.5442 - val_accuracy: 0.8508\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5279 - accuracy: 0.8480 - val_loss: 0.5443 - val_accuracy: 0.8518\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5214 - accuracy: 0.8491 - val_loss: 0.5380 - val_accuracy: 0.8532\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5133 - accuracy: 0.8524 - val_loss: 0.5380 - val_accuracy: 0.8506\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5056 - accuracy: 0.8550 - val_loss: 0.5381 - val_accuracy: 0.8530\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5013 - accuracy: 0.8582 - val_loss: 0.5216 - val_accuracy: 0.8580\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4935 - accuracy: 0.8590 - val_loss: 0.5418 - val_accuracy: 0.8504\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4864 - accuracy: 0.8632 - val_loss: 0.5098 - val_accuracy: 0.8672\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4795 - accuracy: 0.8653 - val_loss: 0.5139 - val_accuracy: 0.8670\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4712 - accuracy: 0.8682 - val_loss: 0.5022 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4646 - accuracy: 0.8701 - val_loss: 0.4983 - val_accuracy: 0.8636\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4573 - accuracy: 0.8739 - val_loss: 0.4847 - val_accuracy: 0.8722\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4450 - accuracy: 0.8762 - val_loss: 0.4921 - val_accuracy: 0.8720\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.4340 - accuracy: 0.8780 - val_loss: 0.4711 - val_accuracy: 0.8780\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4240 - accuracy: 0.8804 - val_loss: 0.4714 - val_accuracy: 0.8756\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4142 - accuracy: 0.8829 - val_loss: 0.4583 - val_accuracy: 0.8812\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4040 - accuracy: 0.8876 - val_loss: 0.4472 - val_accuracy: 0.8824\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3955 - accuracy: 0.8878 - val_loss: 0.4425 - val_accuracy: 0.8864\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3878 - accuracy: 0.8890 - val_loss: 0.4377 - val_accuracy: 0.8874\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3839 - accuracy: 0.8904 - val_loss: 0.4336 - val_accuracy: 0.8862\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.4497 - accuracy: 0.8773\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.5201 - accuracy: 0.4008 - val_loss: 1.1862 - val_accuracy: 0.5662\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.1143 - accuracy: 0.5905 - val_loss: 0.9966 - val_accuracy: 0.6434\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9548 - accuracy: 0.6792 - val_loss: 0.8738 - val_accuracy: 0.7170\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8517 - accuracy: 0.7292 - val_loss: 0.7607 - val_accuracy: 0.7786\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7012 - accuracy: 0.8013 - val_loss: 0.6191 - val_accuracy: 0.8362\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6083 - accuracy: 0.8331 - val_loss: 0.5915 - val_accuracy: 0.8366\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5678 - accuracy: 0.8459 - val_loss: 0.5511 - val_accuracy: 0.8508\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5398 - accuracy: 0.8529 - val_loss: 0.5308 - val_accuracy: 0.8542\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5185 - accuracy: 0.8591 - val_loss: 0.5329 - val_accuracy: 0.8574\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5061 - accuracy: 0.8613 - val_loss: 0.5122 - val_accuracy: 0.8648\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4924 - accuracy: 0.8679 - val_loss: 0.4861 - val_accuracy: 0.8708\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4792 - accuracy: 0.8711 - val_loss: 0.4826 - val_accuracy: 0.8708\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4676 - accuracy: 0.8766 - val_loss: 0.4721 - val_accuracy: 0.8748\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4580 - accuracy: 0.8781 - val_loss: 0.4636 - val_accuracy: 0.8796\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4485 - accuracy: 0.8824 - val_loss: 0.4636 - val_accuracy: 0.8810\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4406 - accuracy: 0.8846 - val_loss: 0.4812 - val_accuracy: 0.8768\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4729 - accuracy: 0.8743\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 69us/sample - loss: 1.3388 - accuracy: 0.5287 - val_loss: 0.7789 - val_accuracy: 0.7984\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.6568 - accuracy: 0.8183 - val_loss: 0.5414 - val_accuracy: 0.8528\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.5109 - accuracy: 0.8580 - val_loss: 0.4886 - val_accuracy: 0.8696\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4540 - accuracy: 0.8739 - val_loss: 0.4524 - val_accuracy: 0.8780\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4193 - accuracy: 0.8842 - val_loss: 0.4293 - val_accuracy: 0.8886\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3924 - accuracy: 0.8916 - val_loss: 0.3784 - val_accuracy: 0.9024\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3681 - accuracy: 0.8982 - val_loss: 0.3686 - val_accuracy: 0.9038\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3464 - accuracy: 0.9029 - val_loss: 0.3411 - val_accuracy: 0.9102\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3281 - accuracy: 0.9078 - val_loss: 0.3324 - val_accuracy: 0.9114\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3134 - accuracy: 0.9124 - val_loss: 0.3199 - val_accuracy: 0.9102\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3030 - accuracy: 0.9135 - val_loss: 0.3177 - val_accuracy: 0.9178\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.2949 - accuracy: 0.9164 - val_loss: 0.3043 - val_accuracy: 0.9178\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.2890 - accuracy: 0.9186 - val_loss: 0.3102 - val_accuracy: 0.9158\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2830 - accuracy: 0.9212 - val_loss: 0.3213 - val_accuracy: 0.9148\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.3297 - accuracy: 0.9104\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2994 - accuracy: 0.5352 - val_loss: 0.8151 - val_accuracy: 0.7610\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.6807 - accuracy: 0.7993 - val_loss: 0.5697 - val_accuracy: 0.8486\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.4955 - accuracy: 0.8589 - val_loss: 0.4530 - val_accuracy: 0.8808\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4188 - accuracy: 0.8807 - val_loss: 0.4089 - val_accuracy: 0.8888\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3857 - accuracy: 0.8905 - val_loss: 0.4077 - val_accuracy: 0.8888\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3643 - accuracy: 0.8964 - val_loss: 0.3802 - val_accuracy: 0.8978\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3451 - accuracy: 0.9024 - val_loss: 0.3807 - val_accuracy: 0.8944\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3327 - accuracy: 0.9068 - val_loss: 0.3721 - val_accuracy: 0.9018\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3200 - accuracy: 0.9091 - val_loss: 0.3805 - val_accuracy: 0.8990\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3125 - accuracy: 0.9123 - val_loss: 0.3392 - val_accuracy: 0.9066\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3044 - accuracy: 0.9152 - val_loss: 0.3497 - val_accuracy: 0.9058\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.2962 - accuracy: 0.9162 - val_loss: 0.3383 - val_accuracy: 0.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2920 - accuracy: 0.9178 - val_loss: 0.3478 - val_accuracy: 0.9084\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2863 - accuracy: 0.9206 - val_loss: 0.3137 - val_accuracy: 0.9168\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2811 - accuracy: 0.9210 - val_loss: 0.3175 - val_accuracy: 0.9182\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2777 - accuracy: 0.9215 - val_loss: 0.3192 - val_accuracy: 0.9160\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3412 - accuracy: 0.9084\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2987 - accuracy: 0.5265 - val_loss: 0.7820 - val_accuracy: 0.7238\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.6738 - accuracy: 0.7943 - val_loss: 0.5574 - val_accuracy: 0.8468\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5404 - accuracy: 0.8424 - val_loss: 0.4876 - val_accuracy: 0.8644\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4775 - accuracy: 0.8627 - val_loss: 0.4409 - val_accuracy: 0.8768\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4382 - accuracy: 0.8777 - val_loss: 0.4210 - val_accuracy: 0.8838\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4113 - accuracy: 0.8848 - val_loss: 0.3987 - val_accuracy: 0.8878\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3931 - accuracy: 0.8898 - val_loss: 0.3923 - val_accuracy: 0.8928\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3760 - accuracy: 0.8945 - val_loss: 0.3872 - val_accuracy: 0.8968\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3661 - accuracy: 0.8981 - val_loss: 0.3739 - val_accuracy: 0.8960\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3546 - accuracy: 0.9011 - val_loss: 0.3632 - val_accuracy: 0.9038\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3455 - accuracy: 0.9040 - val_loss: 0.3590 - val_accuracy: 0.8962\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3374 - accuracy: 0.9051 - val_loss: 0.3532 - val_accuracy: 0.9030\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3284 - accuracy: 0.9075 - val_loss: 0.3349 - val_accuracy: 0.9086\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3224 - accuracy: 0.9097 - val_loss: 0.3283 - val_accuracy: 0.9098\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3158 - accuracy: 0.9114 - val_loss: 0.3173 - val_accuracy: 0.9150\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3089 - accuracy: 0.9141 - val_loss: 0.3124 - val_accuracy: 0.9106\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3017 - accuracy: 0.9171 - val_loss: 0.2980 - val_accuracy: 0.9180\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2952 - accuracy: 0.9185 - val_loss: 0.3066 - val_accuracy: 0.9164\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2907 - accuracy: 0.9198 - val_loss: 0.3246 - val_accuracy: 0.9088\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.3173 - accuracy: 0.9132\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.2496 - accuracy: 0.5657 - val_loss: 0.7093 - val_accuracy: 0.8020\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5776 - accuracy: 0.8384 - val_loss: 0.4761 - val_accuracy: 0.8694\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.4463 - accuracy: 0.8776 - val_loss: 0.4179 - val_accuracy: 0.8892\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3952 - accuracy: 0.8909 - val_loss: 0.4011 - val_accuracy: 0.8862\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3673 - accuracy: 0.8984 - val_loss: 0.3590 - val_accuracy: 0.9072\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3471 - accuracy: 0.9047 - val_loss: 0.3426 - val_accuracy: 0.9086\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3339 - accuracy: 0.9083 - val_loss: 0.3445 - val_accuracy: 0.9084\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3203 - accuracy: 0.9112 - val_loss: 0.3420 - val_accuracy: 0.9096\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.3082 - accuracy: 0.9148 - val_loss: 0.3279 - val_accuracy: 0.9102\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2996 - accuracy: 0.9168 - val_loss: 0.3205 - val_accuracy: 0.9132\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2898 - accuracy: 0.9195 - val_loss: 0.3213 - val_accuracy: 0.9136\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2826 - accuracy: 0.9223 - val_loss: 0.3167 - val_accuracy: 0.9130\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.2768 - accuracy: 0.9235 - val_loss: 0.3109 - val_accuracy: 0.9160\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.2704 - accuracy: 0.9249 - val_loss: 0.3190 - val_accuracy: 0.9138\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.2651 - accuracy: 0.9267 - val_loss: 0.3020 - val_accuracy: 0.9170\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.2617 - accuracy: 0.9281 - val_loss: 0.3012 - val_accuracy: 0.9192\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2574 - accuracy: 0.9281 - val_loss: 0.3081 - val_accuracy: 0.9150\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 0.2540 - accuracy: 0.9299 - val_loss: 0.3083 - val_accuracy: 0.9156\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 0.3318 - accuracy: 0.9104\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.0618 - accuracy: 0.6527 - val_loss: 0.5022 - val_accuracy: 0.8534\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4567 - accuracy: 0.8696 - val_loss: 0.3814 - val_accuracy: 0.8952\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3785 - accuracy: 0.8926 - val_loss: 0.3390 - val_accuracy: 0.9054\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3384 - accuracy: 0.9044 - val_loss: 0.3389 - val_accuracy: 0.9016\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3110 - accuracy: 0.9107 - val_loss: 0.2971 - val_accuracy: 0.9164\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.2898 - accuracy: 0.9171 - val_loss: 0.2866 - val_accuracy: 0.9206\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2752 - accuracy: 0.9208 - val_loss: 0.2741 - val_accuracy: 0.9204\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.2651 - accuracy: 0.9229 - val_loss: 0.2678 - val_accuracy: 0.9234\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2574 - accuracy: 0.9255 - val_loss: 0.2623 - val_accuracy: 0.9242\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2520 - accuracy: 0.9275 - val_loss: 0.2533 - val_accuracy: 0.9272\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2458 - accuracy: 0.9304 - val_loss: 0.2545 - val_accuracy: 0.9220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2396 - accuracy: 0.9312 - val_loss: 0.2524 - val_accuracy: 0.9282\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2339 - accuracy: 0.9332 - val_loss: 0.2486 - val_accuracy: 0.9270\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2309 - accuracy: 0.9344 - val_loss: 0.2605 - val_accuracy: 0.9288\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2265 - accuracy: 0.9364 - val_loss: 0.2567 - val_accuracy: 0.9290\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.2891 - accuracy: 0.9207\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.1114 - accuracy: 0.6443 - val_loss: 0.6825 - val_accuracy: 0.8108\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6098 - accuracy: 0.8229 - val_loss: 0.4675 - val_accuracy: 0.8654\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4619 - accuracy: 0.8654 - val_loss: 0.3829 - val_accuracy: 0.8980\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3948 - accuracy: 0.8883 - val_loss: 0.3497 - val_accuracy: 0.9026\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3537 - accuracy: 0.8991 - val_loss: 0.3349 - val_accuracy: 0.9100\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.3279 - accuracy: 0.9059 - val_loss: 0.3162 - val_accuracy: 0.9138\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3107 - accuracy: 0.9114 - val_loss: 0.3002 - val_accuracy: 0.9128\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2952 - accuracy: 0.9157 - val_loss: 0.2835 - val_accuracy: 0.9216\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2828 - accuracy: 0.9187 - val_loss: 0.2847 - val_accuracy: 0.9190loss: 0.2829 - accuracy: 0.\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2723 - accuracy: 0.9230 - val_loss: 0.2791 - val_accuracy: 0.9228\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2642 - accuracy: 0.9252 - val_loss: 0.2778 - val_accuracy: 0.9206\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2577 - accuracy: 0.9263 - val_loss: 0.2563 - val_accuracy: 0.9292\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2512 - accuracy: 0.9282 - val_loss: 0.2583 - val_accuracy: 0.9230\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.2464 - accuracy: 0.9299 - val_loss: 0.2478 - val_accuracy: 0.9290\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2400 - accuracy: 0.9308 - val_loss: 0.2642 - val_accuracy: 0.9284\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 0.2342 - accuracy: 0.9322 - val_loss: 0.2718 - val_accuracy: 0.9250\n",
      "18333/18333 [==============================] - 0s 22us/sample - loss: 0.2774 - accuracy: 0.9189\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 36us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.9588 - accuracy: 0.2314 - val_loss: 1.7382 - val_accuracy: 0.3052\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.5945 - accuracy: 0.3739 - val_loss: 1.4791 - val_accuracy: 0.4434\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.3830 - accuracy: 0.4920 - val_loss: 1.2894 - val_accuracy: 0.5122\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.1902 - accuracy: 0.5282 - val_loss: 1.1530 - val_accuracy: 0.5486\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.0992 - accuracy: 0.5731 - val_loss: 1.0948 - val_accuracy: 0.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.0553 - accuracy: 0.6012 - val_loss: 1.0547 - val_accuracy: 0.6054\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 1.0285 - accuracy: 0.6132 - val_loss: 1.0328 - val_accuracy: 0.6120\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.0079 - accuracy: 0.6238 - val_loss: 1.0126 - val_accuracy: 0.6212\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9872 - accuracy: 0.6304 - val_loss: 0.9888 - val_accuracy: 0.6412\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9690 - accuracy: 0.6352 - val_loss: 0.9656 - val_accuracy: 0.6446\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9501 - accuracy: 0.6420 - val_loss: 0.9514 - val_accuracy: 0.6508\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.9353 - accuracy: 0.6511 - val_loss: 0.9333 - val_accuracy: 0.6684\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9253 - accuracy: 0.6611 - val_loss: 0.9319 - val_accuracy: 0.6702\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.9151 - accuracy: 0.6667 - val_loss: 0.9234 - val_accuracy: 0.6794\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.9094 - accuracy: 0.6719 - val_loss: 0.9073 - val_accuracy: 0.6874\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.9031 - accuracy: 0.6750 - val_loss: 0.9030 - val_accuracy: 0.6942\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8977 - accuracy: 0.6806 - val_loss: 0.9107 - val_accuracy: 0.6886\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8938 - accuracy: 0.6854 - val_loss: 0.9055 - val_accuracy: 0.6830\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.9337 - accuracy: 0.6725\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 2.0030 - accuracy: 0.2252 - val_loss: 1.8543 - val_accuracy: 0.2638\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 36us/sample - loss: 1.7426 - accuracy: 0.2944 - val_loss: 1.6624 - val_accuracy: 0.3132\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.6199 - accuracy: 0.3269 - val_loss: 1.5824 - val_accuracy: 0.3544\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5646 - accuracy: 0.3451 - val_loss: 1.5427 - val_accuracy: 0.3380\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.5255 - accuracy: 0.3574 - val_loss: 1.4977 - val_accuracy: 0.3830\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4923 - accuracy: 0.3716 - val_loss: 1.4514 - val_accuracy: 0.3982\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.4541 - accuracy: 0.3918 - val_loss: 1.4221 - val_accuracy: 0.4088\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.4296 - accuracy: 0.4064 - val_loss: 1.4100 - val_accuracy: 0.4294\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.4087 - accuracy: 0.4247 - val_loss: 1.3806 - val_accuracy: 0.4448\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.3911 - accuracy: 0.4480 - val_loss: 1.3726 - val_accuracy: 0.4798\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.3714 - accuracy: 0.4759 - val_loss: 1.3589 - val_accuracy: 0.5026\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.3497 - accuracy: 0.4958 - val_loss: 1.3379 - val_accuracy: 0.5044\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.3340 - accuracy: 0.5018 - val_loss: 1.3132 - val_accuracy: 0.5270\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.3204 - accuracy: 0.5101 - val_loss: 1.3208 - val_accuracy: 0.5138\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.3111 - accuracy: 0.5155 - val_loss: 1.3186 - val_accuracy: 0.5218\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 1.3602 - accuracy: 0.5052\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 30us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.7884 - accuracy: 0.3304 - val_loss: 1.5132 - val_accuracy: 0.4120\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.3955 - accuracy: 0.4748 - val_loss: 1.2892 - val_accuracy: 0.4936\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.2284 - accuracy: 0.5536 - val_loss: 1.1244 - val_accuracy: 0.6334\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.0747 - accuracy: 0.6598 - val_loss: 0.9785 - val_accuracy: 0.7020\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9450 - accuracy: 0.7185 - val_loss: 0.8741 - val_accuracy: 0.7600\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.8755 - accuracy: 0.7438 - val_loss: 0.8290 - val_accuracy: 0.7696\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8295 - accuracy: 0.7587 - val_loss: 0.8012 - val_accuracy: 0.7798\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.8053 - accuracy: 0.7652 - val_loss: 0.7837 - val_accuracy: 0.7836\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.7912 - accuracy: 0.7699 - val_loss: 0.7651 - val_accuracy: 0.7972\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7790 - accuracy: 0.7737 - val_loss: 0.7673 - val_accuracy: 0.7966\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7681 - accuracy: 0.7777 - val_loss: 0.7505 - val_accuracy: 0.7990\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7589 - accuracy: 0.7795 - val_loss: 0.7494 - val_accuracy: 0.8012\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7526 - accuracy: 0.7819 - val_loss: 0.7637 - val_accuracy: 0.7876\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.7462 - accuracy: 0.7817 - val_loss: 0.7425 - val_accuracy: 0.8026\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7392 - accuracy: 0.7833 - val_loss: 0.7327 - val_accuracy: 0.8048\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.7308 - accuracy: 0.7871 - val_loss: 0.7341 - val_accuracy: 0.8038\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.7249 - accuracy: 0.7874 - val_loss: 0.7387 - val_accuracy: 0.7966\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.7675 - accuracy: 0.7804\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 75us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 1.8367 - accuracy: 0.3124 - val_loss: 1.5955 - val_accuracy: 0.4220\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.4481 - accuracy: 0.4645 - val_loss: 1.3310 - val_accuracy: 0.4856\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 1.2719 - accuracy: 0.5310 - val_loss: 1.1690 - val_accuracy: 0.6228\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1034 - accuracy: 0.6771 - val_loss: 0.9817 - val_accuracy: 0.7602\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9495 - accuracy: 0.7432 - val_loss: 0.8574 - val_accuracy: 0.7776\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.8672 - accuracy: 0.7627 - val_loss: 0.8022 - val_accuracy: 0.7890\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.8199 - accuracy: 0.7709 - val_loss: 0.7776 - val_accuracy: 0.7938\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7933 - accuracy: 0.7772 - val_loss: 0.7463 - val_accuracy: 0.8066\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7758 - accuracy: 0.7812 - val_loss: 0.7300 - val_accuracy: 0.8076\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7644 - accuracy: 0.7875 - val_loss: 0.7189 - val_accuracy: 0.8116\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7534 - accuracy: 0.7909 - val_loss: 0.7177 - val_accuracy: 0.8142\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.7452 - accuracy: 0.7932 - val_loss: 0.7088 - val_accuracy: 0.8166\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7372 - accuracy: 0.7949 - val_loss: 0.7164 - val_accuracy: 0.8158\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.7323 - accuracy: 0.7945 - val_loss: 0.6996 - val_accuracy: 0.8244\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7251 - accuracy: 0.7976 - val_loss: 0.6878 - val_accuracy: 0.8234\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.7199 - accuracy: 0.7988 - val_loss: 0.6918 - val_accuracy: 0.8170\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.7166 - accuracy: 0.8007 - val_loss: 0.6881 - val_accuracy: 0.8274\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.7247 - accuracy: 0.8007\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 1.6949 - accuracy: 0.3809 - val_loss: 1.3626 - val_accuracy: 0.5232\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.1342 - accuracy: 0.6053 - val_loss: 0.9928 - val_accuracy: 0.6604\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9515 - accuracy: 0.6804 - val_loss: 0.8936 - val_accuracy: 0.7178\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.8694 - accuracy: 0.7330 - val_loss: 0.8640 - val_accuracy: 0.7450\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.8131 - accuracy: 0.7577 - val_loss: 0.7895 - val_accuracy: 0.7742\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.7724 - accuracy: 0.7738 - val_loss: 0.7510 - val_accuracy: 0.7886\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.7426 - accuracy: 0.7845 - val_loss: 0.7557 - val_accuracy: 0.7944\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.7220 - accuracy: 0.7920 - val_loss: 0.7411 - val_accuracy: 0.7990\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.7061 - accuracy: 0.8012 - val_loss: 0.6984 - val_accuracy: 0.8132\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6929 - accuracy: 0.8060 - val_loss: 0.6870 - val_accuracy: 0.8132\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.6795 - accuracy: 0.8096 - val_loss: 0.6916 - val_accuracy: 0.8094\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.6675 - accuracy: 0.8152 - val_loss: 0.6732 - val_accuracy: 0.8192\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.6572 - accuracy: 0.8157 - val_loss: 0.6720 - val_accuracy: 0.8196\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6479 - accuracy: 0.8189 - val_loss: 0.7362 - val_accuracy: 0.7922\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6383 - accuracy: 0.8213 - val_loss: 0.6566 - val_accuracy: 0.8248\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6312 - accuracy: 0.8206 - val_loss: 0.6677 - val_accuracy: 0.8184\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.6240 - accuracy: 0.8219 - val_loss: 0.6722 - val_accuracy: 0.8158\n",
      "18334/18334 [==============================] - 1s 32us/sample - loss: 0.6745 - accuracy: 0.8151\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 1.6765 - accuracy: 0.3646 - val_loss: 1.2611 - val_accuracy: 0.5620\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1112 - accuracy: 0.6111 - val_loss: 0.9479 - val_accuracy: 0.6704\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8940 - accuracy: 0.7057 - val_loss: 0.7900 - val_accuracy: 0.7556\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7772 - accuracy: 0.7544 - val_loss: 0.7257 - val_accuracy: 0.7758\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7093 - accuracy: 0.7773 - val_loss: 0.6682 - val_accuracy: 0.7986\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6674 - accuracy: 0.7944 - val_loss: 0.6336 - val_accuracy: 0.8130\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6302 - accuracy: 0.8097 - val_loss: 0.6221 - val_accuracy: 0.8262\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6035 - accuracy: 0.8212 - val_loss: 0.5890 - val_accuracy: 0.8412\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.5874 - accuracy: 0.8279 - val_loss: 0.5732 - val_accuracy: 0.8490\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.5736 - accuracy: 0.8340 - val_loss: 0.5637 - val_accuracy: 0.8522\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.5630 - accuracy: 0.8357 - val_loss: 0.5668 - val_accuracy: 0.8544\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5535 - accuracy: 0.8397 - val_loss: 0.5658 - val_accuracy: 0.8520\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.5962 - accuracy: 0.8328\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 1.7469 - accuracy: 0.3448 - val_loss: 1.4302 - val_accuracy: 0.4766\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.2948 - accuracy: 0.5608 - val_loss: 1.1072 - val_accuracy: 0.6456\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.0548 - accuracy: 0.6490 - val_loss: 0.9265 - val_accuracy: 0.6902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.9367 - accuracy: 0.6861 - val_loss: 0.8688 - val_accuracy: 0.7324\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8533 - accuracy: 0.7375 - val_loss: 0.8055 - val_accuracy: 0.7672\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7866 - accuracy: 0.7608 - val_loss: 0.7546 - val_accuracy: 0.7676\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7465 - accuracy: 0.7740 - val_loss: 0.7395 - val_accuracy: 0.7826\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7130 - accuracy: 0.7859 - val_loss: 0.6893 - val_accuracy: 0.8040\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.6875 - accuracy: 0.7945 - val_loss: 0.6760 - val_accuracy: 0.7980\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6692 - accuracy: 0.7995 - val_loss: 0.6653 - val_accuracy: 0.8106\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6537 - accuracy: 0.8039 - val_loss: 0.6486 - val_accuracy: 0.8116\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6448 - accuracy: 0.8060 - val_loss: 0.6352 - val_accuracy: 0.8098\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6302 - accuracy: 0.8111 - val_loss: 0.6293 - val_accuracy: 0.8174\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6192 - accuracy: 0.8137 - val_loss: 0.6544 - val_accuracy: 0.8140\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6120 - accuracy: 0.8149 - val_loss: 0.6463 - val_accuracy: 0.8088\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.6327 - accuracy: 0.8059\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 1.6367 - accuracy: 0.4113 - val_loss: 1.1161 - val_accuracy: 0.6262\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9643 - accuracy: 0.7099 - val_loss: 0.8348 - val_accuracy: 0.7718\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7607 - accuracy: 0.7812 - val_loss: 0.7035 - val_accuracy: 0.8014\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6724 - accuracy: 0.8024 - val_loss: 0.6445 - val_accuracy: 0.8124\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.6239 - accuracy: 0.8164 - val_loss: 0.6072 - val_accuracy: 0.8212\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5899 - accuracy: 0.8261 - val_loss: 0.5864 - val_accuracy: 0.8264\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5656 - accuracy: 0.8317 - val_loss: 0.5812 - val_accuracy: 0.8310\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5419 - accuracy: 0.8396 - val_loss: 0.5804 - val_accuracy: 0.8384\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5237 - accuracy: 0.8464 - val_loss: 0.5483 - val_accuracy: 0.8480\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5025 - accuracy: 0.8533 - val_loss: 0.5296 - val_accuracy: 0.8546\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4853 - accuracy: 0.8580 - val_loss: 0.5070 - val_accuracy: 0.8622\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4697 - accuracy: 0.8646 - val_loss: 0.5016 - val_accuracy: 0.8604\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4565 - accuracy: 0.8660 - val_loss: 0.4760 - val_accuracy: 0.8680\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4480 - accuracy: 0.8711 - val_loss: 0.4897 - val_accuracy: 0.8588\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.4397 - accuracy: 0.8725 - val_loss: 0.4679 - val_accuracy: 0.8704\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4312 - accuracy: 0.8752 - val_loss: 0.4645 - val_accuracy: 0.8714\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 0.4243 - accuracy: 0.8778 - val_loss: 0.4447 - val_accuracy: 0.8776\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4170 - accuracy: 0.8797 - val_loss: 0.4589 - val_accuracy: 0.8750\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4124 - accuracy: 0.8807 - val_loss: 0.4320 - val_accuracy: 0.8814\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4079 - accuracy: 0.8831 - val_loss: 0.4289 - val_accuracy: 0.8826\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4031 - accuracy: 0.8839 - val_loss: 0.4399 - val_accuracy: 0.8818\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4004 - accuracy: 0.8858 - val_loss: 0.4257 - val_accuracy: 0.8858\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 0.3969 - accuracy: 0.8872 - val_loss: 0.4343 - val_accuracy: 0.8832\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 3s 72us/sample - loss: 0.3934 - accuracy: 0.8876 - val_loss: 0.4349 - val_accuracy: 0.8814\n",
      "18334/18334 [==============================] - 1s 30us/sample - loss: 0.4599 - accuracy: 0.8749\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.6811 - accuracy: 0.3287 - val_loss: 1.2729 - val_accuracy: 0.5442\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1651 - accuracy: 0.6152 - val_loss: 1.0511 - val_accuracy: 0.6740\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.9906 - accuracy: 0.6954 - val_loss: 0.9219 - val_accuracy: 0.7210\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.9020 - accuracy: 0.7224 - val_loss: 0.8611 - val_accuracy: 0.7366\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.8516 - accuracy: 0.7359 - val_loss: 0.8442 - val_accuracy: 0.7402\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.8160 - accuracy: 0.7459 - val_loss: 0.8217 - val_accuracy: 0.7464\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.7886 - accuracy: 0.7574 - val_loss: 0.7686 - val_accuracy: 0.7728\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7665 - accuracy: 0.7670 - val_loss: 0.7523 - val_accuracy: 0.7776\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7477 - accuracy: 0.7745 - val_loss: 0.7302 - val_accuracy: 0.7842\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.7343 - accuracy: 0.7802 - val_loss: 0.7195 - val_accuracy: 0.7910\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7213 - accuracy: 0.7865 - val_loss: 0.7445 - val_accuracy: 0.7842\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7107 - accuracy: 0.7932 - val_loss: 0.7098 - val_accuracy: 0.7950\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7011 - accuracy: 0.7972 - val_loss: 0.6949 - val_accuracy: 0.8038\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6882 - accuracy: 0.8031 - val_loss: 0.6863 - val_accuracy: 0.8078\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6781 - accuracy: 0.8081 - val_loss: 0.6834 - val_accuracy: 0.8090\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6684 - accuracy: 0.8126 - val_loss: 0.6842 - val_accuracy: 0.8108\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6623 - accuracy: 0.8148 - val_loss: 0.6625 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6510 - accuracy: 0.8215 - val_loss: 0.6603 - val_accuracy: 0.8194\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.6440 - accuracy: 0.8228 - val_loss: 0.6539 - val_accuracy: 0.8180\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6365 - accuracy: 0.8282 - val_loss: 0.6563 - val_accuracy: 0.8216\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6291 - accuracy: 0.8294 - val_loss: 0.6726 - val_accuracy: 0.8194\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.7085 - accuracy: 0.8047\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 1.8641 - accuracy: 0.3029 - val_loss: 1.6196 - val_accuracy: 0.4244\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.4325 - accuracy: 0.4952 - val_loss: 1.2975 - val_accuracy: 0.5356\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.1916 - accuracy: 0.5819 - val_loss: 1.0950 - val_accuracy: 0.6168\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9993 - accuracy: 0.6917 - val_loss: 0.8745 - val_accuracy: 0.7178\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8365 - accuracy: 0.7234 - val_loss: 0.7814 - val_accuracy: 0.7496\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7774 - accuracy: 0.7514 - val_loss: 0.7443 - val_accuracy: 0.7808\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.7365 - accuracy: 0.7786 - val_loss: 0.7178 - val_accuracy: 0.7934\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7014 - accuracy: 0.7940 - val_loss: 0.7091 - val_accuracy: 0.8048\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6738 - accuracy: 0.8042 - val_loss: 0.6925 - val_accuracy: 0.8164\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.6505 - accuracy: 0.8116 - val_loss: 0.6379 - val_accuracy: 0.8322\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6306 - accuracy: 0.8214 - val_loss: 0.6277 - val_accuracy: 0.8406\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6103 - accuracy: 0.8290 - val_loss: 0.6157 - val_accuracy: 0.8478\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.5908 - accuracy: 0.8381 - val_loss: 0.5754 - val_accuracy: 0.8532\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5741 - accuracy: 0.8458 - val_loss: 0.5700 - val_accuracy: 0.8630\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5545 - accuracy: 0.8543 - val_loss: 0.5716 - val_accuracy: 0.8632\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5407 - accuracy: 0.8577 - val_loss: 0.5470 - val_accuracy: 0.8656\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5276 - accuracy: 0.8627 - val_loss: 0.5305 - val_accuracy: 0.8716\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5153 - accuracy: 0.8661 - val_loss: 0.5258 - val_accuracy: 0.8710\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5038 - accuracy: 0.8695 - val_loss: 0.5413 - val_accuracy: 0.8706\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.4957 - accuracy: 0.8718 - val_loss: 0.4995 - val_accuracy: 0.8802\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4846 - accuracy: 0.8779 - val_loss: 0.5010 - val_accuracy: 0.8838\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4768 - accuracy: 0.8800 - val_loss: 0.5119 - val_accuracy: 0.8814\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.5110 - accuracy: 0.8691\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 1.3946 - accuracy: 0.4470 - val_loss: 0.9718 - val_accuracy: 0.6508\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.8206 - accuracy: 0.7161 - val_loss: 0.7245 - val_accuracy: 0.7648\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.7006 - accuracy: 0.7652 - val_loss: 0.6438 - val_accuracy: 0.8016\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6099 - accuracy: 0.8090 - val_loss: 0.5553 - val_accuracy: 0.8430\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.5240 - accuracy: 0.8456 - val_loss: 0.4744 - val_accuracy: 0.8662\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4688 - accuracy: 0.8660 - val_loss: 0.4368 - val_accuracy: 0.8742\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.4393 - accuracy: 0.8742 - val_loss: 0.4369 - val_accuracy: 0.8782\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4187 - accuracy: 0.8798 - val_loss: 0.4124 - val_accuracy: 0.8868\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4046 - accuracy: 0.8839 - val_loss: 0.4117 - val_accuracy: 0.8862\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.3942 - accuracy: 0.8870 - val_loss: 0.3927 - val_accuracy: 0.8944\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3841 - accuracy: 0.8902 - val_loss: 0.3871 - val_accuracy: 0.8952\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3760 - accuracy: 0.8922 - val_loss: 0.3788 - val_accuracy: 0.9010\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3684 - accuracy: 0.8952 - val_loss: 0.3678 - val_accuracy: 0.9002\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 0.3607 - accuracy: 0.8977 - val_loss: 0.4192 - val_accuracy: 0.8866\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3550 - accuracy: 0.9005 - val_loss: 0.3618 - val_accuracy: 0.9048\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3502 - accuracy: 0.9002 - val_loss: 0.3487 - val_accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3469 - accuracy: 0.9017 - val_loss: 0.3474 - val_accuracy: 0.9082\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3430 - accuracy: 0.9033 - val_loss: 0.3544 - val_accuracy: 0.9022\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3395 - accuracy: 0.9039 - val_loss: 0.3548 - val_accuracy: 0.9086\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3873 - accuracy: 0.8958\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.6113 - accuracy: 0.4099 - val_loss: 1.1685 - val_accuracy: 0.5964\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.9641 - accuracy: 0.6918 - val_loss: 0.7147 - val_accuracy: 0.7900\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6685 - accuracy: 0.7995 - val_loss: 0.5878 - val_accuracy: 0.8344\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5836 - accuracy: 0.8282 - val_loss: 0.5418 - val_accuracy: 0.8464\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5375 - accuracy: 0.8437 - val_loss: 0.4931 - val_accuracy: 0.8650\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5008 - accuracy: 0.8573 - val_loss: 0.4736 - val_accuracy: 0.8782\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4676 - accuracy: 0.8700 - val_loss: 0.4596 - val_accuracy: 0.8798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4446 - accuracy: 0.8773 - val_loss: 0.4534 - val_accuracy: 0.8906\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4270 - accuracy: 0.8825 - val_loss: 0.4583 - val_accuracy: 0.8852\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4144 - accuracy: 0.8883 - val_loss: 0.4227 - val_accuracy: 0.8912\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4043 - accuracy: 0.8920 - val_loss: 0.4208 - val_accuracy: 0.8970\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.3953 - accuracy: 0.8942 - val_loss: 0.4163 - val_accuracy: 0.8964\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3875 - accuracy: 0.8966 - val_loss: 0.4085 - val_accuracy: 0.9018\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3827 - accuracy: 0.8972 - val_loss: 0.4243 - val_accuracy: 0.8948\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3780 - accuracy: 0.8998 - val_loss: 0.4024 - val_accuracy: 0.8962\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3741 - accuracy: 0.8997 - val_loss: 0.3966 - val_accuracy: 0.8982\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3674 - accuracy: 0.9013 - val_loss: 0.4177 - val_accuracy: 0.8990\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3630 - accuracy: 0.9033 - val_loss: 0.3970 - val_accuracy: 0.9042\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.4445 - accuracy: 0.8845\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.3270 - accuracy: 0.5142 - val_loss: 0.8319 - val_accuracy: 0.7532\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.7365 - accuracy: 0.7820 - val_loss: 0.6231 - val_accuracy: 0.8304\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6085 - accuracy: 0.8245 - val_loss: 0.5486 - val_accuracy: 0.8526\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5558 - accuracy: 0.8438 - val_loss: 0.5166 - val_accuracy: 0.8612\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5239 - accuracy: 0.8565 - val_loss: 0.4991 - val_accuracy: 0.8656\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.5010 - accuracy: 0.8639 - val_loss: 0.4682 - val_accuracy: 0.8774\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4802 - accuracy: 0.8708 - val_loss: 0.4770 - val_accuracy: 0.8776\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.4662 - accuracy: 0.8739 - val_loss: 0.4429 - val_accuracy: 0.8844\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4505 - accuracy: 0.8773 - val_loss: 0.4298 - val_accuracy: 0.8872\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4402 - accuracy: 0.8797 - val_loss: 0.4368 - val_accuracy: 0.8854\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4293 - accuracy: 0.8824 - val_loss: 0.4290 - val_accuracy: 0.8888\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4188 - accuracy: 0.8843 - val_loss: 0.4215 - val_accuracy: 0.8892\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4102 - accuracy: 0.8883 - val_loss: 0.4215 - val_accuracy: 0.8928\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3994 - accuracy: 0.8901 - val_loss: 0.4111 - val_accuracy: 0.8926\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3924 - accuracy: 0.8922 - val_loss: 0.3998 - val_accuracy: 0.8940\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3848 - accuracy: 0.8947 - val_loss: 0.4030 - val_accuracy: 0.8932\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3778 - accuracy: 0.8966 - val_loss: 0.3896 - val_accuracy: 0.8970\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3725 - accuracy: 0.8970 - val_loss: 0.3828 - val_accuracy: 0.8970\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3654 - accuracy: 0.8999 - val_loss: 0.3824 - val_accuracy: 0.8964\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3582 - accuracy: 0.9003 - val_loss: 0.3716 - val_accuracy: 0.9004\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3527 - accuracy: 0.9042 - val_loss: 0.3673 - val_accuracy: 0.9038\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.3479 - accuracy: 0.9045 - val_loss: 0.3717 - val_accuracy: 0.8984\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3448 - accuracy: 0.9054 - val_loss: 0.3637 - val_accuracy: 0.9058\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3403 - accuracy: 0.9063 - val_loss: 0.3640 - val_accuracy: 0.9036\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3365 - accuracy: 0.9072 - val_loss: 0.3675 - val_accuracy: 0.9050\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.3817 - accuracy: 0.9000\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 1.5827 - accuracy: 0.4236 - val_loss: 1.1841 - val_accuracy: 0.5950\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9125 - accuracy: 0.7014 - val_loss: 0.6938 - val_accuracy: 0.8056\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.6146 - accuracy: 0.8260 - val_loss: 0.5446 - val_accuracy: 0.8656\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.5118 - accuracy: 0.8636 - val_loss: 0.4886 - val_accuracy: 0.8774\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.4571 - accuracy: 0.8773 - val_loss: 0.4287 - val_accuracy: 0.8898\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4194 - accuracy: 0.8874 - val_loss: 0.4139 - val_accuracy: 0.8902\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3886 - accuracy: 0.8943 - val_loss: 0.3892 - val_accuracy: 0.9010\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3685 - accuracy: 0.8998 - val_loss: 0.3966 - val_accuracy: 0.8956\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3521 - accuracy: 0.9051 - val_loss: 0.3772 - val_accuracy: 0.9030\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3430 - accuracy: 0.9065 - val_loss: 0.3513 - val_accuracy: 0.9058\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3337 - accuracy: 0.9086 - val_loss: 0.3718 - val_accuracy: 0.8998\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3265 - accuracy: 0.9094 - val_loss: 0.3553 - val_accuracy: 0.9082\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.3966 - accuracy: 0.8938\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.2016 - accuracy: 0.5563 - val_loss: 0.7275 - val_accuracy: 0.7938\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.6130 - accuracy: 0.8213 - val_loss: 0.5234 - val_accuracy: 0.8562\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5098 - accuracy: 0.8537 - val_loss: 0.4731 - val_accuracy: 0.8752\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4561 - accuracy: 0.8700 - val_loss: 0.4284 - val_accuracy: 0.8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4241 - accuracy: 0.8813 - val_loss: 0.3972 - val_accuracy: 0.8912\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3969 - accuracy: 0.8896 - val_loss: 0.3802 - val_accuracy: 0.8988\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3771 - accuracy: 0.8937 - val_loss: 0.3625 - val_accuracy: 0.9074\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3642 - accuracy: 0.8975 - val_loss: 0.3528 - val_accuracy: 0.9084\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3545 - accuracy: 0.9006 - val_loss: 0.3848 - val_accuracy: 0.8942\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3458 - accuracy: 0.9052 - val_loss: 0.3517 - val_accuracy: 0.9088\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3397 - accuracy: 0.9057 - val_loss: 0.3373 - val_accuracy: 0.9092\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3346 - accuracy: 0.9078 - val_loss: 0.3393 - val_accuracy: 0.9096\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3300 - accuracy: 0.9088 - val_loss: 0.3412 - val_accuracy: 0.9094\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3769 - accuracy: 0.8955\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 1.1046 - accuracy: 0.6252 - val_loss: 0.7567 - val_accuracy: 0.7728\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.6901 - accuracy: 0.7904 - val_loss: 0.5902 - val_accuracy: 0.8338\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5821 - accuracy: 0.8301 - val_loss: 0.5366 - val_accuracy: 0.8512\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5100 - accuracy: 0.8534 - val_loss: 0.4544 - val_accuracy: 0.8734\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4624 - accuracy: 0.8679 - val_loss: 0.4504 - val_accuracy: 0.8732\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.4311 - accuracy: 0.8770 - val_loss: 0.4028 - val_accuracy: 0.8916\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.4082 - accuracy: 0.8844 - val_loss: 0.3865 - val_accuracy: 0.8938\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3867 - accuracy: 0.8896 - val_loss: 0.3897 - val_accuracy: 0.8916\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3723 - accuracy: 0.8958 - val_loss: 0.3704 - val_accuracy: 0.8952\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3604 - accuracy: 0.8992 - val_loss: 0.3603 - val_accuracy: 0.9060\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3495 - accuracy: 0.9020 - val_loss: 0.3385 - val_accuracy: 0.9038\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3427 - accuracy: 0.9050 - val_loss: 0.3525 - val_accuracy: 0.9088\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3354 - accuracy: 0.9058 - val_loss: 0.3416 - val_accuracy: 0.9094\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.3601 - accuracy: 0.9011\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 60us/sample - loss: 1.2425 - accuracy: 0.5608 - val_loss: 0.7530 - val_accuracy: 0.7974\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6232 - accuracy: 0.8180 - val_loss: 0.5553 - val_accuracy: 0.8476\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.5025 - accuracy: 0.8529 - val_loss: 0.4603 - val_accuracy: 0.8686\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.4459 - accuracy: 0.8697 - val_loss: 0.4038 - val_accuracy: 0.8828\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4067 - accuracy: 0.8822 - val_loss: 0.3885 - val_accuracy: 0.8924\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.3787 - accuracy: 0.8899 - val_loss: 0.3669 - val_accuracy: 0.9004\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3584 - accuracy: 0.8963 - val_loss: 0.3944 - val_accuracy: 0.8914\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3406 - accuracy: 0.9030 - val_loss: 0.3523 - val_accuracy: 0.9018\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.3249 - accuracy: 0.9066 - val_loss: 0.3300 - val_accuracy: 0.9064\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3136 - accuracy: 0.9096 - val_loss: 0.3487 - val_accuracy: 0.9022\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.3033 - accuracy: 0.9122 - val_loss: 0.3232 - val_accuracy: 0.9086\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.2955 - accuracy: 0.9147 - val_loss: 0.3045 - val_accuracy: 0.9184\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.2870 - accuracy: 0.9163 - val_loss: 0.3228 - val_accuracy: 0.9096\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 1s 37us/sample - loss: 0.2811 - accuracy: 0.9172 - val_loss: 0.3194 - val_accuracy: 0.9112\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3376 - accuracy: 0.9080\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.2337 - accuracy: 0.5663 - val_loss: 0.7279 - val_accuracy: 0.8038\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.5910 - accuracy: 0.8382 - val_loss: 0.5148 - val_accuracy: 0.8680\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.4594 - accuracy: 0.8745 - val_loss: 0.4364 - val_accuracy: 0.8834\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4043 - accuracy: 0.8882 - val_loss: 0.3853 - val_accuracy: 0.8994\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3726 - accuracy: 0.8961 - val_loss: 0.3822 - val_accuracy: 0.8976\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.3525 - accuracy: 0.9008 - val_loss: 0.3713 - val_accuracy: 0.9042\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3366 - accuracy: 0.9066 - val_loss: 0.3430 - val_accuracy: 0.9080\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3254 - accuracy: 0.9092 - val_loss: 0.3389 - val_accuracy: 0.9130\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3155 - accuracy: 0.9128 - val_loss: 0.3765 - val_accuracy: 0.9040\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3071 - accuracy: 0.9148 - val_loss: 0.3370 - val_accuracy: 0.9138\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3003 - accuracy: 0.9165 - val_loss: 0.3306 - val_accuracy: 0.9150\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2926 - accuracy: 0.9189 - val_loss: 0.3323 - val_accuracy: 0.9152\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2876 - accuracy: 0.9201 - val_loss: 0.3197 - val_accuracy: 0.9172\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2826 - accuracy: 0.9215 - val_loss: 0.3204 - val_accuracy: 0.9154\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.2765 - accuracy: 0.9236 - val_loss: 0.3162 - val_accuracy: 0.9206\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2723 - accuracy: 0.9235 - val_loss: 0.3261 - val_accuracy: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2670 - accuracy: 0.9264 - val_loss: 0.3147 - val_accuracy: 0.9216\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2643 - accuracy: 0.9264 - val_loss: 0.3264 - val_accuracy: 0.9220\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 37us/sample - loss: 0.2605 - accuracy: 0.9279 - val_loss: 0.3244 - val_accuracy: 0.9190\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3517 - accuracy: 0.9038\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 1.1371 - accuracy: 0.6066 - val_loss: 0.6854 - val_accuracy: 0.7920\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.5523 - accuracy: 0.8448 - val_loss: 0.4494 - val_accuracy: 0.8810\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4436 - accuracy: 0.8757 - val_loss: 0.3965 - val_accuracy: 0.8912\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3920 - accuracy: 0.8911 - val_loss: 0.3580 - val_accuracy: 0.9022\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3630 - accuracy: 0.8982 - val_loss: 0.3418 - val_accuracy: 0.9080\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.3444 - accuracy: 0.9048 - val_loss: 0.3343 - val_accuracy: 0.9102\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.3277 - accuracy: 0.9102 - val_loss: 0.3432 - val_accuracy: 0.9028\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3137 - accuracy: 0.9111 - val_loss: 0.3008 - val_accuracy: 0.9140\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.3034 - accuracy: 0.9150 - val_loss: 0.2915 - val_accuracy: 0.9164\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2931 - accuracy: 0.9183 - val_loss: 0.2945 - val_accuracy: 0.9176\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2854 - accuracy: 0.9204 - val_loss: 0.2883 - val_accuracy: 0.9210\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.2801 - accuracy: 0.9215 - val_loss: 0.2784 - val_accuracy: 0.9212\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2737 - accuracy: 0.9226 - val_loss: 0.2757 - val_accuracy: 0.9242\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2672 - accuracy: 0.9236 - val_loss: 0.2983 - val_accuracy: 0.9172\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.2652 - accuracy: 0.9250 - val_loss: 0.2883 - val_accuracy: 0.9192\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 0.3023 - accuracy: 0.9147\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 23us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 2.0243 - accuracy: 0.2102 - val_loss: 1.8942 - val_accuracy: 0.2458\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.8653 - accuracy: 0.2546 - val_loss: 1.8218 - val_accuracy: 0.2756\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.8168 - accuracy: 0.2803 - val_loss: 1.7895 - val_accuracy: 0.2920\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.7893 - accuracy: 0.2955 - val_loss: 1.7706 - val_accuracy: 0.3038\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7705 - accuracy: 0.3060 - val_loss: 1.7554 - val_accuracy: 0.3200\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.7537 - accuracy: 0.3134 - val_loss: 1.7451 - val_accuracy: 0.3126\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7304 - accuracy: 0.3159 - val_loss: 1.7227 - val_accuracy: 0.3216\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.7113 - accuracy: 0.3259 - val_loss: 1.6920 - val_accuracy: 0.3364\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6963 - accuracy: 0.3311 - val_loss: 1.6806 - val_accuracy: 0.3488\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6844 - accuracy: 0.3385 - val_loss: 1.6647 - val_accuracy: 0.3526\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6736 - accuracy: 0.3442 - val_loss: 1.6528 - val_accuracy: 0.3668\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6641 - accuracy: 0.3470 - val_loss: 1.6443 - val_accuracy: 0.3656\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6561 - accuracy: 0.3536 - val_loss: 1.6421 - val_accuracy: 0.3706\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6490 - accuracy: 0.3599 - val_loss: 1.6331 - val_accuracy: 0.3778\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6416 - accuracy: 0.3659 - val_loss: 1.6333 - val_accuracy: 0.3776\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.6337 - accuracy: 0.3727 - val_loss: 1.6163 - val_accuracy: 0.3900\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6244 - accuracy: 0.3803 - val_loss: 1.6084 - val_accuracy: 0.4022\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6154 - accuracy: 0.3853 - val_loss: 1.6069 - val_accuracy: 0.3978\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.6070 - accuracy: 0.3940 - val_loss: 1.5985 - val_accuracy: 0.3960\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 1.6012 - accuracy: 0.3951 - val_loss: 1.5914 - val_accuracy: 0.4018\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5958 - accuracy: 0.3998 - val_loss: 1.5848 - val_accuracy: 0.4198\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5902 - accuracy: 0.3995 - val_loss: 1.5860 - val_accuracy: 0.3928\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.5849 - accuracy: 0.4030 - val_loss: 1.5765 - val_accuracy: 0.4224\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5814 - accuracy: 0.4038 - val_loss: 1.5771 - val_accuracy: 0.4096\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5769 - accuracy: 0.4060 - val_loss: 1.5713 - val_accuracy: 0.4236\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5736 - accuracy: 0.4087 - val_loss: 1.5752 - val_accuracy: 0.4126\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.5695 - accuracy: 0.4094 - val_loss: 1.5677 - val_accuracy: 0.4278\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5670 - accuracy: 0.4091 - val_loss: 1.5626 - val_accuracy: 0.4222\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5629 - accuracy: 0.4108 - val_loss: 1.5593 - val_accuracy: 0.4222\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.5605 - accuracy: 0.4090 - val_loss: 1.5648 - val_accuracy: 0.4332\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.5679 - accuracy: 0.4142\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 1.9831 - accuracy: 0.2384 - val_loss: 1.8717 - val_accuracy: 0.2786\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.8024 - accuracy: 0.3000 - val_loss: 1.7538 - val_accuracy: 0.3268\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.7144 - accuracy: 0.3540 - val_loss: 1.6869 - val_accuracy: 0.3890\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.6567 - accuracy: 0.3874 - val_loss: 1.6413 - val_accuracy: 0.4078\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.6095 - accuracy: 0.4107 - val_loss: 1.5868 - val_accuracy: 0.4350\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.5625 - accuracy: 0.4306 - val_loss: 1.5459 - val_accuracy: 0.4588\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.5304 - accuracy: 0.4437 - val_loss: 1.5166 - val_accuracy: 0.4564\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.5054 - accuracy: 0.4484 - val_loss: 1.5030 - val_accuracy: 0.4496\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.4870 - accuracy: 0.4531 - val_loss: 1.4908 - val_accuracy: 0.4642\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4746 - accuracy: 0.4592 - val_loss: 1.4795 - val_accuracy: 0.4674\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.4618 - accuracy: 0.4622 - val_loss: 1.4805 - val_accuracy: 0.4660\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4490 - accuracy: 0.4702 - val_loss: 1.4653 - val_accuracy: 0.4810\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.4408 - accuracy: 0.4724 - val_loss: 1.4575 - val_accuracy: 0.4804\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.4324 - accuracy: 0.4706 - val_loss: 1.4586 - val_accuracy: 0.4644\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4254 - accuracy: 0.4749 - val_loss: 1.4363 - val_accuracy: 0.4922\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.4196 - accuracy: 0.4759 - val_loss: 1.4317 - val_accuracy: 0.4756\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.4144 - accuracy: 0.4735 - val_loss: 1.4326 - val_accuracy: 0.4818\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 1.4112 - accuracy: 0.4773 - val_loss: 1.4226 - val_accuracy: 0.4912\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.4078 - accuracy: 0.4770 - val_loss: 1.4255 - val_accuracy: 0.4682\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.4041 - accuracy: 0.4791 - val_loss: 1.4229 - val_accuracy: 0.4890\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 1.4548 - accuracy: 0.4735\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 1.9962 - accuracy: 0.2437 - val_loss: 1.6974 - val_accuracy: 0.3654\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4908 - accuracy: 0.4233 - val_loss: 1.3469 - val_accuracy: 0.4574\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.3094 - accuracy: 0.4826 - val_loss: 1.2599 - val_accuracy: 0.5144\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.2324 - accuracy: 0.5423 - val_loss: 1.1975 - val_accuracy: 0.5882\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1667 - accuracy: 0.5893 - val_loss: 1.1372 - val_accuracy: 0.5990\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1179 - accuracy: 0.6090 - val_loss: 1.1135 - val_accuracy: 0.6262\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0846 - accuracy: 0.6259 - val_loss: 1.1030 - val_accuracy: 0.6436\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0633 - accuracy: 0.6401 - val_loss: 1.1081 - val_accuracy: 0.6200\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.0484 - accuracy: 0.6463 - val_loss: 1.0649 - val_accuracy: 0.6496\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.0369 - accuracy: 0.6494 - val_loss: 1.0614 - val_accuracy: 0.6642\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.0272 - accuracy: 0.6578 - val_loss: 1.0395 - val_accuracy: 0.6718\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.0188 - accuracy: 0.6600 - val_loss: 1.0413 - val_accuracy: 0.6700\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.0120 - accuracy: 0.6650 - val_loss: 1.0451 - val_accuracy: 0.6582\n",
      "18333/18333 [==============================] - 0s 24us/sample - loss: 1.0603 - accuracy: 0.6548\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 63us/sample - loss: 2.3015 - accuracy: 0.1132 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 57us/sample - loss: 1.8135 - accuracy: 0.3110 - val_loss: 1.5109 - val_accuracy: 0.4206\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 1.4340 - accuracy: 0.4630 - val_loss: 1.3744 - val_accuracy: 0.4668\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.3155 - accuracy: 0.5028 - val_loss: 1.2644 - val_accuracy: 0.5370\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 1.2211 - accuracy: 0.5644 - val_loss: 1.1596 - val_accuracy: 0.5740\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 1.1368 - accuracy: 0.6064 - val_loss: 1.0993 - val_accuracy: 0.6212\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 1.0787 - accuracy: 0.6392 - val_loss: 1.0461 - val_accuracy: 0.6778\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 1s 40us/sample - loss: 1.0372 - accuracy: 0.6785 - val_loss: 1.0080 - val_accuracy: 0.6866\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.0111 - accuracy: 0.6903 - val_loss: 1.0067 - val_accuracy: 0.7018\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 1s 38us/sample - loss: 0.9902 - accuracy: 0.6995 - val_loss: 0.9654 - val_accuracy: 0.7266\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9731 - accuracy: 0.7146 - val_loss: 0.9443 - val_accuracy: 0.7336\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9601 - accuracy: 0.7149 - val_loss: 0.9570 - val_accuracy: 0.7356\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 1s 39us/sample - loss: 0.9437 - accuracy: 0.7235 - val_loss: 0.9454 - val_accuracy: 0.7346\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.9978 - accuracy: 0.7130\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.9962 - accuracy: 0.2012 - val_loss: 1.8943 - val_accuracy: 0.2196\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.8133 - accuracy: 0.3228 - val_loss: 1.7557 - val_accuracy: 0.3918\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.6445 - accuracy: 0.4325 - val_loss: 1.6163 - val_accuracy: 0.4582\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.5192 - accuracy: 0.4752 - val_loss: 1.4960 - val_accuracy: 0.4832\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.4032 - accuracy: 0.5016 - val_loss: 1.3903 - val_accuracy: 0.5118\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.2822 - accuracy: 0.5398 - val_loss: 1.2957 - val_accuracy: 0.5598\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1888 - accuracy: 0.5660 - val_loss: 1.2056 - val_accuracy: 0.5678\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.1316 - accuracy: 0.5810 - val_loss: 1.1805 - val_accuracy: 0.5870\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.1012 - accuracy: 0.5873 - val_loss: 1.1593 - val_accuracy: 0.5858\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.0771 - accuracy: 0.5951 - val_loss: 1.1194 - val_accuracy: 0.5954\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 1.0520 - accuracy: 0.6011 - val_loss: 1.0724 - val_accuracy: 0.6022\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.9967 - accuracy: 0.6241 - val_loss: 1.0269 - val_accuracy: 0.6212\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9773 - accuracy: 0.6337 - val_loss: 1.0067 - val_accuracy: 0.6310\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9639 - accuracy: 0.6374 - val_loss: 0.9975 - val_accuracy: 0.6284\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9545 - accuracy: 0.6416 - val_loss: 0.9873 - val_accuracy: 0.6316\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.9424 - accuracy: 0.6446 - val_loss: 0.9852 - val_accuracy: 0.6296\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9343 - accuracy: 0.6467 - val_loss: 0.9839 - val_accuracy: 0.6386\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9313 - accuracy: 0.6469 - val_loss: 0.9725 - val_accuracy: 0.6370\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.9257 - accuracy: 0.6513 - val_loss: 0.9693 - val_accuracy: 0.6312\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9188 - accuracy: 0.6514 - val_loss: 0.9670 - val_accuracy: 0.6388\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9142 - accuracy: 0.6520 - val_loss: 0.9769 - val_accuracy: 0.6428\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.9104 - accuracy: 0.6533 - val_loss: 0.9583 - val_accuracy: 0.6334\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.9060 - accuracy: 0.6556 - val_loss: 0.9544 - val_accuracy: 0.6394\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 1s 38us/sample - loss: 0.9034 - accuracy: 0.6564 - val_loss: 0.9534 - val_accuracy: 0.6422\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8991 - accuracy: 0.6564 - val_loss: 0.9473 - val_accuracy: 0.6376\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8963 - accuracy: 0.6586 - val_loss: 0.9585 - val_accuracy: 0.6452\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 0.8957 - accuracy: 0.6590 - val_loss: 0.9564 - val_accuracy: 0.6402\n",
      "18333/18333 [==============================] - 0s 23us/sample - loss: 0.9624 - accuracy: 0.6401\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.9426 - accuracy: 0.2709 - val_loss: 1.6006 - val_accuracy: 0.3506\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.4699 - accuracy: 0.3710 - val_loss: 1.3713 - val_accuracy: 0.3852\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 1.3480 - accuracy: 0.4296 - val_loss: 1.2806 - val_accuracy: 0.4610\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.2846 - accuracy: 0.4829 - val_loss: 1.2379 - val_accuracy: 0.4798\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.2340 - accuracy: 0.5098 - val_loss: 1.1828 - val_accuracy: 0.5236\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 39us/sample - loss: 1.2000 - accuracy: 0.5189 - val_loss: 1.1567 - val_accuracy: 0.5252\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 1.1840 - accuracy: 0.5280 - val_loss: 1.1633 - val_accuracy: 0.5354\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.1711 - accuracy: 0.5354 - val_loss: 1.1597 - val_accuracy: 0.5420\n",
      "18333/18333 [==============================] - 1s 35us/sample - loss: 1.1865 - accuracy: 0.5216\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 75us/sample - loss: 1.8366 - accuracy: 0.2221 - val_loss: 1.5943 - val_accuracy: 0.3686\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 57us/sample - loss: 1.4555 - accuracy: 0.4831 - val_loss: 1.3616 - val_accuracy: 0.5958\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.1607 - accuracy: 0.6466 - val_loss: 1.0619 - val_accuracy: 0.68141.1653 - accuracy: 0.\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9790 - accuracy: 0.6986 - val_loss: 0.9487 - val_accuracy: 0.7104\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.9005 - accuracy: 0.7251 - val_loss: 0.8933 - val_accuracy: 0.7448\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.8496 - accuracy: 0.7478 - val_loss: 0.8563 - val_accuracy: 0.7662\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.8163 - accuracy: 0.7636 - val_loss: 0.8460 - val_accuracy: 0.7648\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.7930 - accuracy: 0.7697 - val_loss: 0.8216 - val_accuracy: 0.7792\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.7743 - accuracy: 0.7786 - val_loss: 0.7958 - val_accuracy: 0.7864\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7606 - accuracy: 0.7820 - val_loss: 0.7961 - val_accuracy: 0.7882\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.7528 - accuracy: 0.7861 - val_loss: 0.8188 - val_accuracy: 0.7754\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.8225 - accuracy: 0.7745\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 1.7818 - accuracy: 0.3023 - val_loss: 1.4231 - val_accuracy: 0.4952\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.2520 - accuracy: 0.5639 - val_loss: 1.0077 - val_accuracy: 0.6690\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9384 - accuracy: 0.6873 - val_loss: 0.8559 - val_accuracy: 0.7332\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8253 - accuracy: 0.7275 - val_loss: 0.8081 - val_accuracy: 0.7486\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7726 - accuracy: 0.7500 - val_loss: 0.7796 - val_accuracy: 0.7664\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7404 - accuracy: 0.7651 - val_loss: 0.7637 - val_accuracy: 0.7606\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7191 - accuracy: 0.7726 - val_loss: 0.7431 - val_accuracy: 0.7762\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7013 - accuracy: 0.7811 - val_loss: 0.7220 - val_accuracy: 0.7916\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6882 - accuracy: 0.7868 - val_loss: 0.7199 - val_accuracy: 0.7886\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6794 - accuracy: 0.7918 - val_loss: 0.7244 - val_accuracy: 0.7894\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6686 - accuracy: 0.7955 - val_loss: 0.7026 - val_accuracy: 0.7958\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.6617 - accuracy: 0.8001 - val_loss: 0.6995 - val_accuracy: 0.7942\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6550 - accuracy: 0.8023 - val_loss: 0.7095 - val_accuracy: 0.7974\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6460 - accuracy: 0.8048 - val_loss: 0.6810 - val_accuracy: 0.8006\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6447 - accuracy: 0.8073 - val_loss: 0.6736 - val_accuracy: 0.8022\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6376 - accuracy: 0.8088 - val_loss: 0.6690 - val_accuracy: 0.8094\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6337 - accuracy: 0.8097 - val_loss: 0.6703 - val_accuracy: 0.8082\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6292 - accuracy: 0.8114 - val_loss: 0.6670 - val_accuracy: 0.8098\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6256 - accuracy: 0.8138 - val_loss: 0.6810 - val_accuracy: 0.8006\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6212 - accuracy: 0.8155 - val_loss: 0.6516 - val_accuracy: 0.8164\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6211 - accuracy: 0.8185 - val_loss: 0.6617 - val_accuracy: 0.8140\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6193 - accuracy: 0.8183 - val_loss: 0.6452 - val_accuracy: 0.8180\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6138 - accuracy: 0.8222 - val_loss: 0.6474 - val_accuracy: 0.8172\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6121 - accuracy: 0.8233 - val_loss: 0.6541 - val_accuracy: 0.8178\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.6884 - accuracy: 0.8092\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 1.7258 - accuracy: 0.3269 - val_loss: 1.3246 - val_accuracy: 0.5464s - loss: 1.8265 \n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.1238 - accuracy: 0.6549 - val_loss: 0.9324 - val_accuracy: 0.7494\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8723 - accuracy: 0.7535 - val_loss: 0.8034 - val_accuracy: 0.7934\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8005 - accuracy: 0.7785 - val_loss: 0.7640 - val_accuracy: 0.7978\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 0.7683 - accuracy: 0.7883 - val_loss: 0.7511 - val_accuracy: 0.8128\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7523 - accuracy: 0.7941 - val_loss: 0.7671 - val_accuracy: 0.7994\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7380 - accuracy: 0.7995 - val_loss: 0.7399 - val_accuracy: 0.8138\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7314 - accuracy: 0.8060 - val_loss: 0.7257 - val_accuracy: 0.8250\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7252 - accuracy: 0.8079 - val_loss: 0.7219 - val_accuracy: 0.8200\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7214 - accuracy: 0.8105 - val_loss: 0.7167 - val_accuracy: 0.8196\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.7150 - accuracy: 0.8125 - val_loss: 0.7192 - val_accuracy: 0.8228\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.7155 - accuracy: 0.8137 - val_loss: 0.7113 - val_accuracy: 0.8240\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7106 - accuracy: 0.8151 - val_loss: 0.7113 - val_accuracy: 0.8304\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7049 - accuracy: 0.8157 - val_loss: 0.7081 - val_accuracy: 0.8250\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7038 - accuracy: 0.8172 - val_loss: 0.7138 - val_accuracy: 0.8270\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7007 - accuracy: 0.8193 - val_loss: 0.7107 - val_accuracy: 0.8318\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.7312 - accuracy: 0.8095\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 84us/sample - loss: 1.7856 - accuracy: 0.2468 - val_loss: 1.5505 - val_accuracy: 0.3172\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 1.4824 - accuracy: 0.4031 - val_loss: 1.3369 - val_accuracy: 0.5122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 1.2071 - accuracy: 0.5511 - val_loss: 1.0821 - val_accuracy: 0.6266\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.0398 - accuracy: 0.6380 - val_loss: 1.0011 - val_accuracy: 0.6750\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.9401 - accuracy: 0.6954 - val_loss: 0.8696 - val_accuracy: 0.7392\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.8337 - accuracy: 0.7444 - val_loss: 0.7881 - val_accuracy: 0.7680\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.7677 - accuracy: 0.7730 - val_loss: 0.7139 - val_accuracy: 0.8098\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.7019 - accuracy: 0.8045 - val_loss: 0.6807 - val_accuracy: 0.8270\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.6632 - accuracy: 0.8194 - val_loss: 0.6394 - val_accuracy: 0.8372\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6363 - accuracy: 0.8276 - val_loss: 0.6347 - val_accuracy: 0.8440\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6169 - accuracy: 0.8339 - val_loss: 0.6160 - val_accuracy: 0.8382\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5982 - accuracy: 0.8376 - val_loss: 0.6045 - val_accuracy: 0.8442\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5859 - accuracy: 0.8414 - val_loss: 0.6014 - val_accuracy: 0.8420\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5729 - accuracy: 0.8466 - val_loss: 0.6010 - val_accuracy: 0.8418\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5667 - accuracy: 0.8488 - val_loss: 0.5704 - val_accuracy: 0.8478\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5578 - accuracy: 0.8500 - val_loss: 0.5621 - val_accuracy: 0.8570\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5480 - accuracy: 0.8509 - val_loss: 0.5643 - val_accuracy: 0.8610\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5406 - accuracy: 0.8543 - val_loss: 0.5507 - val_accuracy: 0.8572\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5362 - accuracy: 0.8583 - val_loss: 0.5291 - val_accuracy: 0.8642\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5272 - accuracy: 0.8597 - val_loss: 0.5324 - val_accuracy: 0.8632\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5229 - accuracy: 0.8613 - val_loss: 0.5409 - val_accuracy: 0.8596\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.5791 - accuracy: 0.8465\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 1.6385 - accuracy: 0.4340 - val_loss: 1.2231 - val_accuracy: 0.5920\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.0474 - accuracy: 0.6430 - val_loss: 0.8864 - val_accuracy: 0.6956\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8419 - accuracy: 0.7157 - val_loss: 0.7816 - val_accuracy: 0.7512\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7460 - accuracy: 0.7556 - val_loss: 0.7163 - val_accuracy: 0.7830\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6792 - accuracy: 0.7856 - val_loss: 0.6627 - val_accuracy: 0.8078\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6325 - accuracy: 0.8035 - val_loss: 0.6172 - val_accuracy: 0.8182\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5994 - accuracy: 0.8154 - val_loss: 0.5873 - val_accuracy: 0.8306\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5679 - accuracy: 0.8283 - val_loss: 0.5542 - val_accuracy: 0.8466\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5361 - accuracy: 0.8429 - val_loss: 0.5547 - val_accuracy: 0.8526\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5137 - accuracy: 0.8505 - val_loss: 0.5242 - val_accuracy: 0.8596\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4932 - accuracy: 0.8575 - val_loss: 0.5091 - val_accuracy: 0.8602\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4773 - accuracy: 0.8634 - val_loss: 0.5351 - val_accuracy: 0.8416\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4639 - accuracy: 0.8661 - val_loss: 0.4772 - val_accuracy: 0.8690\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4485 - accuracy: 0.8716 - val_loss: 0.4818 - val_accuracy: 0.8704\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4376 - accuracy: 0.8739 - val_loss: 0.4688 - val_accuracy: 0.8734\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4286 - accuracy: 0.8755 - val_loss: 0.4605 - val_accuracy: 0.8756\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4148 - accuracy: 0.8798 - val_loss: 0.4812 - val_accuracy: 0.8718\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4074 - accuracy: 0.8825 - val_loss: 0.4446 - val_accuracy: 0.8772\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3998 - accuracy: 0.8845 - val_loss: 0.4465 - val_accuracy: 0.8738\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3955 - accuracy: 0.8860 - val_loss: 0.4231 - val_accuracy: 0.8850\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3871 - accuracy: 0.8874 - val_loss: 0.4608 - val_accuracy: 0.8794\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3845 - accuracy: 0.8893 - val_loss: 0.4236 - val_accuracy: 0.8870\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4265 - accuracy: 0.8793\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.7252 - accuracy: 0.2980 - val_loss: 1.4018 - val_accuracy: 0.4648\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.1157 - accuracy: 0.6169 - val_loss: 0.8385 - val_accuracy: 0.7422\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.7999 - accuracy: 0.7626 - val_loss: 0.6708 - val_accuracy: 0.8056\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.6996 - accuracy: 0.7982 - val_loss: 0.6410 - val_accuracy: 0.8218\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.6568 - accuracy: 0.8112 - val_loss: 0.5970 - val_accuracy: 0.8372\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6339 - accuracy: 0.8201 - val_loss: 0.6238 - val_accuracy: 0.8184\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6177 - accuracy: 0.8261 - val_loss: 0.5785 - val_accuracy: 0.8454\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5991 - accuracy: 0.8304 - val_loss: 0.5820 - val_accuracy: 0.8426\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5828 - accuracy: 0.8381 - val_loss: 0.5624 - val_accuracy: 0.8468\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5703 - accuracy: 0.8411 - val_loss: 0.5671 - val_accuracy: 0.8522\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5561 - accuracy: 0.8454 - val_loss: 0.5465 - val_accuracy: 0.8578\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5448 - accuracy: 0.8485 - val_loss: 0.5380 - val_accuracy: 0.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5325 - accuracy: 0.8537 - val_loss: 0.5326 - val_accuracy: 0.8620\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5216 - accuracy: 0.8558 - val_loss: 0.5212 - val_accuracy: 0.8704\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5127 - accuracy: 0.8603 - val_loss: 0.5320 - val_accuracy: 0.8558\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5055 - accuracy: 0.8616 - val_loss: 0.5075 - val_accuracy: 0.8688\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4999 - accuracy: 0.8639 - val_loss: 0.5058 - val_accuracy: 0.8678\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4903 - accuracy: 0.8659 - val_loss: 0.4949 - val_accuracy: 0.8774\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4863 - accuracy: 0.8663 - val_loss: 0.4882 - val_accuracy: 0.8708\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4867 - accuracy: 0.8671 - val_loss: 0.5251 - val_accuracy: 0.8642\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4791 - accuracy: 0.8694 - val_loss: 0.4871 - val_accuracy: 0.8740\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4760 - accuracy: 0.8700 - val_loss: 0.4812 - val_accuracy: 0.8710\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4720 - accuracy: 0.8713 - val_loss: 0.4629 - val_accuracy: 0.8810\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4685 - accuracy: 0.8712 - val_loss: 0.5355 - val_accuracy: 0.8536\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4658 - accuracy: 0.8720 - val_loss: 0.4693 - val_accuracy: 0.8784\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.4957 - accuracy: 0.8682\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 62us/sample - loss: 1.7694 - accuracy: 0.3065 - val_loss: 1.4068 - val_accuracy: 0.4562\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.1876 - accuracy: 0.5634 - val_loss: 1.0291 - val_accuracy: 0.6156\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.9579 - accuracy: 0.6588 - val_loss: 0.8756 - val_accuracy: 0.7166\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.7822 - accuracy: 0.7465 - val_loss: 0.7228 - val_accuracy: 0.7866\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6888 - accuracy: 0.7925 - val_loss: 0.6532 - val_accuracy: 0.8134\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 0.6249 - accuracy: 0.8229 - val_loss: 0.5931 - val_accuracy: 0.8428\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5790 - accuracy: 0.8408 - val_loss: 0.5644 - val_accuracy: 0.8570\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5412 - accuracy: 0.8538 - val_loss: 0.5820 - val_accuracy: 0.8496\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5119 - accuracy: 0.8629 - val_loss: 0.5353 - val_accuracy: 0.8658\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4907 - accuracy: 0.8693 - val_loss: 0.5019 - val_accuracy: 0.8772\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4710 - accuracy: 0.8764 - val_loss: 0.4915 - val_accuracy: 0.8734\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4571 - accuracy: 0.8801 - val_loss: 0.4824 - val_accuracy: 0.8786\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4409 - accuracy: 0.8828 - val_loss: 0.4491 - val_accuracy: 0.8888\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4260 - accuracy: 0.8873 - val_loss: 0.4635 - val_accuracy: 0.8822\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4145 - accuracy: 0.8917 - val_loss: 0.4346 - val_accuracy: 0.8934\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4040 - accuracy: 0.8922 - val_loss: 0.4208 - val_accuracy: 0.8908\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3952 - accuracy: 0.8952 - val_loss: 0.4058 - val_accuracy: 0.8974\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3878 - accuracy: 0.8984 - val_loss: 0.4052 - val_accuracy: 0.8978\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3850 - accuracy: 0.8977 - val_loss: 0.4001 - val_accuracy: 0.9026\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3771 - accuracy: 0.9004 - val_loss: 0.4014 - val_accuracy: 0.9004\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3707 - accuracy: 0.9020 - val_loss: 0.4003 - val_accuracy: 0.8982\n",
      "18334/18334 [==============================] - 1s 27us/sample - loss: 0.4633 - accuracy: 0.8869\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 1.6160 - accuracy: 0.4239 - val_loss: 1.1151 - val_accuracy: 0.6202\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9330 - accuracy: 0.6815 - val_loss: 0.8277 - val_accuracy: 0.7284\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7408 - accuracy: 0.7711 - val_loss: 0.6635 - val_accuracy: 0.8200\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6253 - accuracy: 0.8234 - val_loss: 0.5763 - val_accuracy: 0.8392\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5700 - accuracy: 0.8364 - val_loss: 0.5559 - val_accuracy: 0.8436\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5333 - accuracy: 0.8498 - val_loss: 0.5423 - val_accuracy: 0.8514\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5068 - accuracy: 0.8570 - val_loss: 0.5185 - val_accuracy: 0.8566\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4875 - accuracy: 0.8638 - val_loss: 0.5081 - val_accuracy: 0.8640\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4727 - accuracy: 0.8688 - val_loss: 0.4889 - val_accuracy: 0.8678\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4553 - accuracy: 0.8741 - val_loss: 0.4723 - val_accuracy: 0.8676\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4451 - accuracy: 0.8781 - val_loss: 0.4955 - val_accuracy: 0.8682\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4336 - accuracy: 0.8814 - val_loss: 0.4591 - val_accuracy: 0.8812\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4270 - accuracy: 0.8828 - val_loss: 0.4853 - val_accuracy: 0.8750\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4191 - accuracy: 0.8854 - val_loss: 0.4369 - val_accuracy: 0.8814\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4117 - accuracy: 0.8879 - val_loss: 0.4426 - val_accuracy: 0.8816\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4059 - accuracy: 0.8873 - val_loss: 0.4263 - val_accuracy: 0.8906\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4000 - accuracy: 0.8899 - val_loss: 0.4595 - val_accuracy: 0.8798\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3936 - accuracy: 0.8910 - val_loss: 0.4192 - val_accuracy: 0.8888\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3905 - accuracy: 0.8928 - val_loss: 0.4159 - val_accuracy: 0.8896\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3860 - accuracy: 0.8943 - val_loss: 0.4278 - val_accuracy: 0.8876\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3802 - accuracy: 0.8952 - val_loss: 0.4169 - val_accuracy: 0.8920\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.4628 - accuracy: 0.8766\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 1.4622 - accuracy: 0.4874 - val_loss: 0.9916 - val_accuracy: 0.7114\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.8335 - accuracy: 0.7688 - val_loss: 0.6906 - val_accuracy: 0.8190\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5854 - accuracy: 0.8475 - val_loss: 0.4999 - val_accuracy: 0.8760\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4624 - accuracy: 0.8763 - val_loss: 0.4182 - val_accuracy: 0.8952\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4137 - accuracy: 0.8900 - val_loss: 0.3988 - val_accuracy: 0.8966\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3893 - accuracy: 0.8953 - val_loss: 0.4165 - val_accuracy: 0.8922\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3710 - accuracy: 0.8995 - val_loss: 0.3820 - val_accuracy: 0.8986\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3574 - accuracy: 0.9036 - val_loss: 0.3586 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3459 - accuracy: 0.9065 - val_loss: 0.3658 - val_accuracy: 0.9050\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3388 - accuracy: 0.9086 - val_loss: 0.3458 - val_accuracy: 0.9110\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3300 - accuracy: 0.9109 - val_loss: 0.3510 - val_accuracy: 0.9072\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3244 - accuracy: 0.9114 - val_loss: 0.3436 - val_accuracy: 0.9092\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3208 - accuracy: 0.9132 - val_loss: 0.3444 - val_accuracy: 0.9094\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3161 - accuracy: 0.9132 - val_loss: 0.3333 - val_accuracy: 0.9116\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3119 - accuracy: 0.9153 - val_loss: 0.3368 - val_accuracy: 0.9110\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3106 - accuracy: 0.9149 - val_loss: 0.3389 - val_accuracy: 0.9086\n",
      "18333/18333 [==============================] - 1s 33us/sample - loss: 0.3387 - accuracy: 0.9112\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 1.4387 - accuracy: 0.4647 - val_loss: 0.9701 - val_accuracy: 0.6658\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.7833 - accuracy: 0.7390 - val_loss: 0.6446 - val_accuracy: 0.8050\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6055 - accuracy: 0.8125 - val_loss: 0.5579 - val_accuracy: 0.8434\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5324 - accuracy: 0.8425 - val_loss: 0.5257 - val_accuracy: 0.8564\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4726 - accuracy: 0.8672 - val_loss: 0.4668 - val_accuracy: 0.8794\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4380 - accuracy: 0.8785 - val_loss: 0.4400 - val_accuracy: 0.8828\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4133 - accuracy: 0.8841 - val_loss: 0.4184 - val_accuracy: 0.8904\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3917 - accuracy: 0.8917 - val_loss: 0.4361 - val_accuracy: 0.8826\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3752 - accuracy: 0.8959 - val_loss: 0.4068 - val_accuracy: 0.8960\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3609 - accuracy: 0.9003 - val_loss: 0.4034 - val_accuracy: 0.8984\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3503 - accuracy: 0.9047 - val_loss: 0.3984 - val_accuracy: 0.9044\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3403 - accuracy: 0.9075 - val_loss: 0.3789 - val_accuracy: 0.9038\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3359 - accuracy: 0.9088 - val_loss: 0.3831 - val_accuracy: 0.9056\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3290 - accuracy: 0.9111 - val_loss: 0.4020 - val_accuracy: 0.8906\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.4042 - accuracy: 0.8929\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 1.3557 - accuracy: 0.5336 - val_loss: 0.8476 - val_accuracy: 0.7376\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6851 - accuracy: 0.7837 - val_loss: 0.6044 - val_accuracy: 0.8288\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5295 - accuracy: 0.8472 - val_loss: 0.4919 - val_accuracy: 0.8674\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4660 - accuracy: 0.8690 - val_loss: 0.4479 - val_accuracy: 0.8792\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4220 - accuracy: 0.8817 - val_loss: 0.4075 - val_accuracy: 0.8964\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3949 - accuracy: 0.8900 - val_loss: 0.3896 - val_accuracy: 0.9026\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3756 - accuracy: 0.8950 - val_loss: 0.3907 - val_accuracy: 0.8990\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3640 - accuracy: 0.8988 - val_loss: 0.3669 - val_accuracy: 0.9064\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3528 - accuracy: 0.9006 - val_loss: 0.4450 - val_accuracy: 0.8792\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3425 - accuracy: 0.9053 - val_loss: 0.3677 - val_accuracy: 0.9040\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.3982 - accuracy: 0.8891\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.7231 - accuracy: 0.3746 - val_loss: 1.3300 - val_accuracy: 0.5526\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1595 - accuracy: 0.6313 - val_loss: 1.0118 - val_accuracy: 0.6786\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.8959 - accuracy: 0.7470 - val_loss: 0.7752 - val_accuracy: 0.8176\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7116 - accuracy: 0.8241 - val_loss: 0.6392 - val_accuracy: 0.8488\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6171 - accuracy: 0.8488 - val_loss: 0.5846 - val_accuracy: 0.8604\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5650 - accuracy: 0.8615 - val_loss: 0.5468 - val_accuracy: 0.8674\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5243 - accuracy: 0.8706 - val_loss: 0.4999 - val_accuracy: 0.8776\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4883 - accuracy: 0.8764 - val_loss: 0.4663 - val_accuracy: 0.8848\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4556 - accuracy: 0.8829 - val_loss: 0.4446 - val_accuracy: 0.8874\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4327 - accuracy: 0.8885 - val_loss: 0.4415 - val_accuracy: 0.8914\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4146 - accuracy: 0.8944 - val_loss: 0.4224 - val_accuracy: 0.8894\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 0.3999 - accuracy: 0.8972 - val_loss: 0.3866 - val_accuracy: 0.9018\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.3885 - accuracy: 0.8985 - val_loss: 0.3886 - val_accuracy: 0.9032\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.3781 - accuracy: 0.9011 - val_loss: 0.3820 - val_accuracy: 0.8982\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3680 - accuracy: 0.9029 - val_loss: 0.3820 - val_accuracy: 0.9020\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3611 - accuracy: 0.9050 - val_loss: 0.3691 - val_accuracy: 0.9042\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3537 - accuracy: 0.9068 - val_loss: 0.3647 - val_accuracy: 0.9056\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3473 - accuracy: 0.9071 - val_loss: 0.3542 - val_accuracy: 0.9056\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3436 - accuracy: 0.9073 - val_loss: 0.3750 - val_accuracy: 0.9002\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3375 - accuracy: 0.9077 - val_loss: 0.3655 - val_accuracy: 0.9046\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 0.3806 - accuracy: 0.8973\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 91us/sample - loss: 1.2130 - accuracy: 0.5923 - val_loss: 0.6207 - val_accuracy: 0.8212\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.5145 - accuracy: 0.8555 - val_loss: 0.4124 - val_accuracy: 0.8838\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3904 - accuracy: 0.8903 - val_loss: 0.3565 - val_accuracy: 0.9008\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3437 - accuracy: 0.9028 - val_loss: 0.3390 - val_accuracy: 0.9100\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.3182 - accuracy: 0.9097 - val_loss: 0.3179 - val_accuracy: 0.9148\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.2992 - accuracy: 0.9149 - val_loss: 0.3307 - val_accuracy: 0.9096\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.2886 - accuracy: 0.9187 - val_loss: 0.3047 - val_accuracy: 0.9196\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.2783 - accuracy: 0.9218 - val_loss: 0.2995 - val_accuracy: 0.9208\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.2683 - accuracy: 0.9240 - val_loss: 0.2837 - val_accuracy: 0.9202\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.2608 - accuracy: 0.9269 - val_loss: 0.2912 - val_accuracy: 0.9222\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.2530 - accuracy: 0.9289 - val_loss: 0.2894 - val_accuracy: 0.9244\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 0.3097 - accuracy: 0.9135\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 68us/sample - loss: 1.2512 - accuracy: 0.5506 - val_loss: 0.6952 - val_accuracy: 0.7570\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6141 - accuracy: 0.8061 - val_loss: 0.5468 - val_accuracy: 0.8512\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4905 - accuracy: 0.8628 - val_loss: 0.4479 - val_accuracy: 0.8874\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4088 - accuracy: 0.8898 - val_loss: 0.3883 - val_accuracy: 0.8982\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3659 - accuracy: 0.9002 - val_loss: 0.3657 - val_accuracy: 0.9024\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3410 - accuracy: 0.9066 - val_loss: 0.3337 - val_accuracy: 0.9066\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3196 - accuracy: 0.9123 - val_loss: 0.3288 - val_accuracy: 0.9064\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3045 - accuracy: 0.9166 - val_loss: 0.3071 - val_accuracy: 0.9150\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2930 - accuracy: 0.9201 - val_loss: 0.3155 - val_accuracy: 0.9074\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.2838 - accuracy: 0.9205 - val_loss: 0.2968 - val_accuracy: 0.9182\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.2755 - accuracy: 0.9233 - val_loss: 0.3118 - val_accuracy: 0.9106\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.2672 - accuracy: 0.9256 - val_loss: 0.3019 - val_accuracy: 0.9142\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3327 - accuracy: 0.9077\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.2207 - accuracy: 0.5807 - val_loss: 0.6429 - val_accuracy: 0.7980\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5671 - accuracy: 0.8319 - val_loss: 0.4677 - val_accuracy: 0.8626\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4764 - accuracy: 0.8645 - val_loss: 0.4160 - val_accuracy: 0.8820\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4350 - accuracy: 0.8786 - val_loss: 0.3966 - val_accuracy: 0.8880\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4055 - accuracy: 0.8877 - val_loss: 0.3637 - val_accuracy: 0.9088\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3882 - accuracy: 0.8945 - val_loss: 0.3551 - val_accuracy: 0.9032\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3697 - accuracy: 0.8986 - val_loss: 0.3477 - val_accuracy: 0.9094\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3522 - accuracy: 0.9054 - val_loss: 0.3362 - val_accuracy: 0.9134\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3367 - accuracy: 0.9104 - val_loss: 0.3279 - val_accuracy: 0.9168\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3221 - accuracy: 0.9142 - val_loss: 0.3144 - val_accuracy: 0.9212\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3123 - accuracy: 0.9180 - val_loss: 0.3113 - val_accuracy: 0.9198\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3023 - accuracy: 0.9198 - val_loss: 0.3097 - val_accuracy: 0.9168\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2954 - accuracy: 0.9219 - val_loss: 0.3050 - val_accuracy: 0.9184\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2866 - accuracy: 0.9233 - val_loss: 0.3066 - val_accuracy: 0.9186\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.2817 - accuracy: 0.9250 - val_loss: 0.2938 - val_accuracy: 0.9222\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.2746 - accuracy: 0.9269 - val_loss: 0.3021 - val_accuracy: 0.9242\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.2703 - accuracy: 0.9285 - val_loss: 0.2803 - val_accuracy: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.2630 - accuracy: 0.9305 - val_loss: 0.2807 - val_accuracy: 0.9256\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2600 - accuracy: 0.9312 - val_loss: 0.2748 - val_accuracy: 0.9314\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2535 - accuracy: 0.9329 - val_loss: 0.2978 - val_accuracy: 0.9260\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.2520 - accuracy: 0.9342 - val_loss: 0.2689 - val_accuracy: 0.9340\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2487 - accuracy: 0.9348 - val_loss: 0.2698 - val_accuracy: 0.9312\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.2437 - accuracy: 0.9362 - val_loss: 0.2652 - val_accuracy: 0.9298\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.2410 - accuracy: 0.9371 - val_loss: 0.2736 - val_accuracy: 0.9302: 0.2419 - accu\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.2388 - accuracy: 0.9369 - val_loss: 0.2745 - val_accuracy: 0.9302\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.2873 - accuracy: 0.9262\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 66us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.11263012 - accuracy: \n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 73us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 73us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 29us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 70us/sample - loss: 1.9626 - accuracy: 0.2453 - val_loss: 1.8053 - val_accuracy: 0.3416\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.7259 - accuracy: 0.3316 - val_loss: 1.6459 - val_accuracy: 0.3724\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.6092 - accuracy: 0.3804 - val_loss: 1.5486 - val_accuracy: 0.4010\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.5126 - accuracy: 0.4111 - val_loss: 1.4667 - val_accuracy: 0.4254\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.4437 - accuracy: 0.4257 - val_loss: 1.4166 - val_accuracy: 0.4436\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.4018 - accuracy: 0.4369 - val_loss: 1.4076 - val_accuracy: 0.4276\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.3733 - accuracy: 0.4382 - val_loss: 1.3925 - val_accuracy: 0.4378\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 1.3513 - accuracy: 0.4395 - val_loss: 1.3621 - val_accuracy: 0.4436\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.3345 - accuracy: 0.4414 - val_loss: 1.3671 - val_accuracy: 0.4450\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.3236 - accuracy: 0.4461 - val_loss: 1.3510 - val_accuracy: 0.4398\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.3120 - accuracy: 0.4505 - val_loss: 1.3453 - val_accuracy: 0.4478\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.3009 - accuracy: 0.4599 - val_loss: 1.3300 - val_accuracy: 0.4498\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2907 - accuracy: 0.4632 - val_loss: 1.3295 - val_accuracy: 0.4652\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2824 - accuracy: 0.4780 - val_loss: 1.3292 - val_accuracy: 0.4806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2734 - accuracy: 0.4913 - val_loss: 1.3248 - val_accuracy: 0.4962\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.2590 - accuracy: 0.5057 - val_loss: 1.2908 - val_accuracy: 0.5168\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 1.2476 - accuracy: 0.5199 - val_loss: 1.2896 - val_accuracy: 0.5168\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.2340 - accuracy: 0.5244 - val_loss: 1.2757 - val_accuracy: 0.5328\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.2192 - accuracy: 0.5360 - val_loss: 1.2553 - val_accuracy: 0.5428\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.1980 - accuracy: 0.5515 - val_loss: 1.2394 - val_accuracy: 0.5492\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.1652 - accuracy: 0.5675 - val_loss: 1.1863 - val_accuracy: 0.5910\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.1261 - accuracy: 0.5952 - val_loss: 1.1479 - val_accuracy: 0.6246\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.0865 - accuracy: 0.6271 - val_loss: 1.1102 - val_accuracy: 0.6148\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.0459 - accuracy: 0.6491 - val_loss: 1.0858 - val_accuracy: 0.6604\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.0260 - accuracy: 0.6656 - val_loss: 1.0570 - val_accuracy: 0.6774\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.0106 - accuracy: 0.6724 - val_loss: 1.0370 - val_accuracy: 0.6820\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 0.9959 - accuracy: 0.6786 - val_loss: 1.0264 - val_accuracy: 0.6882\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.9876 - accuracy: 0.6849 - val_loss: 1.0237 - val_accuracy: 0.6944\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.9803 - accuracy: 0.6939 - val_loss: 1.0105 - val_accuracy: 0.6996\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.9699 - accuracy: 0.6986 - val_loss: 1.0084 - val_accuracy: 0.7020\n",
      "18333/18333 [==============================] - 1s 28us/sample - loss: 1.0263 - accuracy: 0.6896\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 2.3015 - accuracy: 0.1135 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3019 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 68us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 2.3017 - accuracy: 0.1115 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126ss: 2.3014 - accuracy: 0.11\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 1.8295 - accuracy: 0.2647 - val_loss: 1.5398 - val_accuracy: 0.3894\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 1.4128 - accuracy: 0.4730 - val_loss: 1.3732 - val_accuracy: 0.4694\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.2821 - accuracy: 0.5244 - val_loss: 1.2274 - val_accuracy: 0.5566\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.2194 - accuracy: 0.5414 - val_loss: 1.1895 - val_accuracy: 0.5722\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.1684 - accuracy: 0.5647 - val_loss: 1.1656 - val_accuracy: 0.5842\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 1.1319 - accuracy: 0.5953 - val_loss: 1.0899 - val_accuracy: 0.6062\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.0897 - accuracy: 0.6368 - val_loss: 1.0446 - val_accuracy: 0.6612\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.0454 - accuracy: 0.6616 - val_loss: 1.0797 - val_accuracy: 0.6442\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.0131 - accuracy: 0.6733 - val_loss: 0.9826 - val_accuracy: 0.6850\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.9920 - accuracy: 0.6822 - val_loss: 0.9606 - val_accuracy: 0.6990\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 0.9740 - accuracy: 0.6899 - val_loss: 0.9722 - val_accuracy: 0.6990\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.9620 - accuracy: 0.6934 - val_loss: 0.9647 - val_accuracy: 0.7170\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.9997 - accuracy: 0.6916\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 86us/sample - loss: 1.9704 - accuracy: 0.2163 - val_loss: 1.8226 - val_accuracy: 0.3122\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.6750 - accuracy: 0.3706 - val_loss: 1.5544 - val_accuracy: 0.4372\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.4263 - accuracy: 0.4393 - val_loss: 1.3482 - val_accuracy: 0.4660\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.2371 - accuracy: 0.5049 - val_loss: 1.1289 - val_accuracy: 0.5290\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.0769 - accuracy: 0.5660 - val_loss: 1.0078 - val_accuracy: 0.5910\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.0124 - accuracy: 0.5902 - val_loss: 0.9605 - val_accuracy: 0.6220\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 0.9532 - accuracy: 0.6231 - val_loss: 0.9305 - val_accuracy: 0.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 0.9166 - accuracy: 0.6439 - val_loss: 0.9061 - val_accuracy: 0.6532\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.8927 - accuracy: 0.6535 - val_loss: 0.9163 - val_accuracy: 0.6426\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8772 - accuracy: 0.6558 - val_loss: 0.8832 - val_accuracy: 0.6562\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.8638 - accuracy: 0.6631 - val_loss: 0.8697 - val_accuracy: 0.6608\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8546 - accuracy: 0.6684 - val_loss: 0.8668 - val_accuracy: 0.6660\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8416 - accuracy: 0.7070 - val_loss: 0.8480 - val_accuracy: 0.7290\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7912 - accuracy: 0.7402 - val_loss: 0.7894 - val_accuracy: 0.7490\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7424 - accuracy: 0.7664 - val_loss: 0.7251 - val_accuracy: 0.7890\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7060 - accuracy: 0.7937 - val_loss: 0.6944 - val_accuracy: 0.7938\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6850 - accuracy: 0.8018 - val_loss: 0.6707 - val_accuracy: 0.8118\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6723 - accuracy: 0.8082 - val_loss: 0.6835 - val_accuracy: 0.8134\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6635 - accuracy: 0.8123 - val_loss: 0.6522 - val_accuracy: 0.8166\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6603 - accuracy: 0.8143 - val_loss: 0.6498 - val_accuracy: 0.8210\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6542 - accuracy: 0.8171 - val_loss: 0.6590 - val_accuracy: 0.8180\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.6484 - accuracy: 0.8179 - val_loss: 0.6579 - val_accuracy: 0.8202\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.7125 - accuracy: 0.8047\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 68us/sample - loss: 1.9427 - accuracy: 0.2510 - val_loss: 1.7350 - val_accuracy: 0.3138\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.5786 - accuracy: 0.3528 - val_loss: 1.4297 - val_accuracy: 0.3882\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.3502 - accuracy: 0.4833 - val_loss: 1.1717 - val_accuracy: 0.5518\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.1213 - accuracy: 0.5790 - val_loss: 1.0283 - val_accuracy: 0.6320\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.0279 - accuracy: 0.6436 - val_loss: 0.9544 - val_accuracy: 0.6958\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.9451 - accuracy: 0.7127 - val_loss: 0.8675 - val_accuracy: 0.7572\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8749 - accuracy: 0.7479 - val_loss: 0.8323 - val_accuracy: 0.7654\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8321 - accuracy: 0.7665 - val_loss: 0.7780 - val_accuracy: 0.7884\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7964 - accuracy: 0.7804 - val_loss: 0.7523 - val_accuracy: 0.7864\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.7655 - accuracy: 0.7918 - val_loss: 0.7266 - val_accuracy: 0.8000\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.7381 - accuracy: 0.8018 - val_loss: 0.7063 - val_accuracy: 0.8150\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.7158 - accuracy: 0.8100 - val_loss: 0.7031 - val_accuracy: 0.8184\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6978 - accuracy: 0.8165 - val_loss: 0.6798 - val_accuracy: 0.8214\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6835 - accuracy: 0.8205 - val_loss: 0.6660 - val_accuracy: 0.8262\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6674 - accuracy: 0.8220 - val_loss: 0.6496 - val_accuracy: 0.8296\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6557 - accuracy: 0.8263 - val_loss: 0.6476 - val_accuracy: 0.8352\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.6467 - accuracy: 0.8279 - val_loss: 0.6549 - val_accuracy: 0.8334\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6377 - accuracy: 0.8286 - val_loss: 0.6258 - val_accuracy: 0.8332\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6256 - accuracy: 0.8313 - val_loss: 0.6272 - val_accuracy: 0.8374\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6201 - accuracy: 0.8318 - val_loss: 0.6119 - val_accuracy: 0.8384\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6118 - accuracy: 0.8334 - val_loss: 0.6120 - val_accuracy: 0.8382\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6047 - accuracy: 0.8351 - val_loss: 0.5964 - val_accuracy: 0.8410\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.5975 - accuracy: 0.8352 - val_loss: 0.5911 - val_accuracy: 0.8424\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5926 - accuracy: 0.8371 - val_loss: 0.5943 - val_accuracy: 0.8424\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5876 - accuracy: 0.8385 - val_loss: 0.5977 - val_accuracy: 0.8414\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.6211 - accuracy: 0.8338\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 68us/sample - loss: 1.7619 - accuracy: 0.3440 - val_loss: 1.2648 - val_accuracy: 0.6088\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.0154 - accuracy: 0.6923 - val_loss: 0.9046 - val_accuracy: 0.7432\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.8019 - accuracy: 0.7795 - val_loss: 0.7424 - val_accuracy: 0.8116\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.7169 - accuracy: 0.8060 - val_loss: 0.7049 - val_accuracy: 0.8226\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.6706 - accuracy: 0.8221 - val_loss: 0.6835 - val_accuracy: 0.8160\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.6397 - accuracy: 0.8310 - val_loss: 0.6455 - val_accuracy: 0.8420\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6154 - accuracy: 0.8375 - val_loss: 0.6352 - val_accuracy: 0.8372\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.5976 - accuracy: 0.8427 - val_loss: 0.6397 - val_accuracy: 0.8382\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5809 - accuracy: 0.8467 - val_loss: 0.6168 - val_accuracy: 0.8506\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5681 - accuracy: 0.8517 - val_loss: 0.6080 - val_accuracy: 0.8452\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5597 - accuracy: 0.8525 - val_loss: 0.5959 - val_accuracy: 0.8564\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.5477 - accuracy: 0.8578 - val_loss: 0.5879 - val_accuracy: 0.8558\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5371 - accuracy: 0.8600 - val_loss: 0.5838 - val_accuracy: 0.8646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5303 - accuracy: 0.8621 - val_loss: 0.5869 - val_accuracy: 0.8550\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5243 - accuracy: 0.8648 - val_loss: 0.5640 - val_accuracy: 0.8676\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.5155 - accuracy: 0.8651 - val_loss: 0.5650 - val_accuracy: 0.8632\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.5113 - accuracy: 0.8677 - val_loss: 0.5903 - val_accuracy: 0.8514\n",
      "18334/18334 [==============================] - 1s 29us/sample - loss: 0.5760 - accuracy: 0.8545\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 1.6685 - accuracy: 0.3505 - val_loss: 1.3018 - val_accuracy: 0.4812\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.1648 - accuracy: 0.5854 - val_loss: 0.9781 - val_accuracy: 0.7180\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.9390 - accuracy: 0.7362 - val_loss: 0.8432 - val_accuracy: 0.7800\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8302 - accuracy: 0.7802 - val_loss: 0.7510 - val_accuracy: 0.8122\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7365 - accuracy: 0.8119 - val_loss: 0.6772 - val_accuracy: 0.8396\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6665 - accuracy: 0.8347 - val_loss: 0.6239 - val_accuracy: 0.8550\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6164 - accuracy: 0.8463 - val_loss: 0.5925 - val_accuracy: 0.8592\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.5841 - accuracy: 0.8561 - val_loss: 0.5879 - val_accuracy: 0.8638\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5455 - accuracy: 0.8638 - val_loss: 0.5609 - val_accuracy: 0.8668\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5149 - accuracy: 0.8732 - val_loss: 0.5148 - val_accuracy: 0.8786\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4938 - accuracy: 0.8774 - val_loss: 0.4994 - val_accuracy: 0.8772\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4746 - accuracy: 0.8803 - val_loss: 0.4863 - val_accuracy: 0.8834\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4618 - accuracy: 0.8838 - val_loss: 0.4871 - val_accuracy: 0.8732\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4498 - accuracy: 0.8840 - val_loss: 0.4712 - val_accuracy: 0.8868\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4372 - accuracy: 0.8851 - val_loss: 0.4502 - val_accuracy: 0.8862\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4311 - accuracy: 0.8872 - val_loss: 0.4543 - val_accuracy: 0.8870\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4259 - accuracy: 0.8882 - val_loss: 0.4465 - val_accuracy: 0.8900\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4202 - accuracy: 0.8897 - val_loss: 0.4331 - val_accuracy: 0.8908\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4126 - accuracy: 0.8912 - val_loss: 0.4422 - val_accuracy: 0.8884\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4063 - accuracy: 0.8927 - val_loss: 0.4282 - val_accuracy: 0.8940\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3994 - accuracy: 0.8934 - val_loss: 0.4526 - val_accuracy: 0.8856\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3952 - accuracy: 0.8945 - val_loss: 0.4397 - val_accuracy: 0.8862\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.4584 - accuracy: 0.8794\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 67us/sample - loss: 1.6531 - accuracy: 0.3490 - val_loss: 1.2887 - val_accuracy: 0.5534\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.1484 - accuracy: 0.6079 - val_loss: 1.0375 - val_accuracy: 0.6600\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.9927 - accuracy: 0.6862 - val_loss: 0.9074 - val_accuracy: 0.7264\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8841 - accuracy: 0.7203 - val_loss: 0.8890 - val_accuracy: 0.7442\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8194 - accuracy: 0.7463 - val_loss: 0.7758 - val_accuracy: 0.7784\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7691 - accuracy: 0.7767 - val_loss: 0.7272 - val_accuracy: 0.8056\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7279 - accuracy: 0.7939 - val_loss: 0.7410 - val_accuracy: 0.8060\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.7026 - accuracy: 0.8027 - val_loss: 0.6795 - val_accuracy: 0.8194\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6775 - accuracy: 0.8082 - val_loss: 0.6667 - val_accuracy: 0.8238\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6584 - accuracy: 0.8174 - val_loss: 0.6418 - val_accuracy: 0.8294\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6393 - accuracy: 0.8220 - val_loss: 0.6314 - val_accuracy: 0.8310\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6283 - accuracy: 0.8309 - val_loss: 0.6243 - val_accuracy: 0.8384\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6129 - accuracy: 0.8335 - val_loss: 0.6064 - val_accuracy: 0.8462\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5977 - accuracy: 0.8382 - val_loss: 0.5928 - val_accuracy: 0.8476\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 0.5877 - accuracy: 0.8397 - val_loss: 0.5995 - val_accuracy: 0.8466\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5755 - accuracy: 0.8431 - val_loss: 0.5945 - val_accuracy: 0.8440\n",
      "18333/18333 [==============================] - 1s 38us/sample - loss: 0.6059 - accuracy: 0.8408\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 84us/sample - loss: 1.4244 - accuracy: 0.4937 - val_loss: 0.9948 - val_accuracy: 0.7216\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.8702 - accuracy: 0.7590 - val_loss: 0.7521 - val_accuracy: 0.8014\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7225 - accuracy: 0.7996 - val_loss: 0.6473 - val_accuracy: 0.8270\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.6528 - accuracy: 0.8184 - val_loss: 0.6199 - val_accuracy: 0.8314\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6045 - accuracy: 0.8296 - val_loss: 0.5634 - val_accuracy: 0.8506\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.5607 - accuracy: 0.8394 - val_loss: 0.5447 - val_accuracy: 0.8524\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.5254 - accuracy: 0.8495 - val_loss: 0.5247 - val_accuracy: 0.8630\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5003 - accuracy: 0.8578 - val_loss: 0.5209 - val_accuracy: 0.8644\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 58us/sample - loss: 0.4790 - accuracy: 0.8628 - val_loss: 0.4707 - val_accuracy: 0.8746\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4650 - accuracy: 0.8676 - val_loss: 0.4885 - val_accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.4522 - accuracy: 0.8714 - val_loss: 0.4626 - val_accuracy: 0.8742\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.4383 - accuracy: 0.8754 - val_loss: 0.4557 - val_accuracy: 0.8808\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4320 - accuracy: 0.8781 - val_loss: 0.4820 - val_accuracy: 0.8710\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.4241 - accuracy: 0.8787 - val_loss: 0.4430 - val_accuracy: 0.8850\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.4153 - accuracy: 0.8817 - val_loss: 0.4324 - val_accuracy: 0.8878\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.4098 - accuracy: 0.8846 - val_loss: 0.4367 - val_accuracy: 0.8832\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4020 - accuracy: 0.8872 - val_loss: 0.4230 - val_accuracy: 0.8896\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 41us/sample - loss: 0.3946 - accuracy: 0.8891 - val_loss: 0.4528 - val_accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3891 - accuracy: 0.8904 - val_loss: 0.4116 - val_accuracy: 0.8934\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3827 - accuracy: 0.8914 - val_loss: 0.4317 - val_accuracy: 0.8876\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3762 - accuracy: 0.8936 - val_loss: 0.4251 - val_accuracy: 0.8882\n",
      "18334/18334 [==============================] - 0s 25us/sample - loss: 0.4405 - accuracy: 0.8783\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 1.6363 - accuracy: 0.3373 - val_loss: 1.2518 - val_accuracy: 0.5692\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.1078 - accuracy: 0.6395 - val_loss: 0.9040 - val_accuracy: 0.7466\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7925 - accuracy: 0.7649 - val_loss: 0.6683 - val_accuracy: 0.8104\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6226 - accuracy: 0.8223 - val_loss: 0.6138 - val_accuracy: 0.8248\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.5444 - accuracy: 0.8471 - val_loss: 0.5308 - val_accuracy: 0.8548\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5023 - accuracy: 0.8614 - val_loss: 0.4933 - val_accuracy: 0.8714\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4742 - accuracy: 0.8703 - val_loss: 0.4652 - val_accuracy: 0.8796\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4564 - accuracy: 0.8772 - val_loss: 0.4657 - val_accuracy: 0.8836\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4436 - accuracy: 0.8824 - val_loss: 0.4666 - val_accuracy: 0.8738\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.4914 - accuracy: 0.8699\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 1.6242 - accuracy: 0.4509 - val_loss: 1.1287 - val_accuracy: 0.6882\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.9451 - accuracy: 0.7266 - val_loss: 0.7700 - val_accuracy: 0.7904\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7685 - accuracy: 0.7836 - val_loss: 0.6683 - val_accuracy: 0.8188\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6862 - accuracy: 0.8111 - val_loss: 0.6085 - val_accuracy: 0.8340\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6270 - accuracy: 0.8283 - val_loss: 0.5712 - val_accuracy: 0.8524\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.5878 - accuracy: 0.8410 - val_loss: 0.5320 - val_accuracy: 0.8588\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 3s 83us/sample - loss: 0.5524 - accuracy: 0.8497 - val_loss: 0.5041 - val_accuracy: 0.8686\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 3s 82us/sample - loss: 0.5283 - accuracy: 0.8574 - val_loss: 0.4824 - val_accuracy: 0.8766\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.5069 - accuracy: 0.8654 - val_loss: 0.4595 - val_accuracy: 0.8808\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4827 - accuracy: 0.8724 - val_loss: 0.4400 - val_accuracy: 0.8900\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4649 - accuracy: 0.8771 - val_loss: 0.4337 - val_accuracy: 0.8880\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.4434 - accuracy: 0.8831 - val_loss: 0.4141 - val_accuracy: 0.8922\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4294 - accuracy: 0.8865 - val_loss: 0.4179 - val_accuracy: 0.8938\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4171 - accuracy: 0.8880 - val_loss: 0.4043 - val_accuracy: 0.8954\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4091 - accuracy: 0.8910 - val_loss: 0.3984 - val_accuracy: 0.8982\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4014 - accuracy: 0.8939 - val_loss: 0.4207 - val_accuracy: 0.8946\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3936 - accuracy: 0.8971 - val_loss: 0.4026 - val_accuracy: 0.8978\n",
      "18333/18333 [==============================] - 1s 31us/sample - loss: 0.4257 - accuracy: 0.8860\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 1.5629 - accuracy: 0.3994 - val_loss: 1.0298 - val_accuracy: 0.6728\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.8334 - accuracy: 0.7387 - val_loss: 0.6124 - val_accuracy: 0.8310\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.5919 - accuracy: 0.8364 - val_loss: 0.5032 - val_accuracy: 0.8724\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5038 - accuracy: 0.8648 - val_loss: 0.4631 - val_accuracy: 0.8812\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.4538 - accuracy: 0.8793 - val_loss: 0.4275 - val_accuracy: 0.8870\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4223 - accuracy: 0.8873 - val_loss: 0.4047 - val_accuracy: 0.8956\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3991 - accuracy: 0.8934 - val_loss: 0.4126 - val_accuracy: 0.8954\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 0.3808 - accuracy: 0.8998 - val_loss: 0.3915 - val_accuracy: 0.8968\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3665 - accuracy: 0.9032 - val_loss: 0.3733 - val_accuracy: 0.9040\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3586 - accuracy: 0.9047 - val_loss: 0.3709 - val_accuracy: 0.9026\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3507 - accuracy: 0.9076 - val_loss: 0.3762 - val_accuracy: 0.9020\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 5s 123us/sample - loss: 0.3414 - accuracy: 0.9110 - val_loss: 0.3679 - val_accuracy: 0.9068\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 0.3369 - accuracy: 0.9096 - val_loss: 0.3754 - val_accuracy: 0.9034\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 0.3325 - accuracy: 0.9125 - val_loss: 0.3581 - val_accuracy: 0.9060\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.3273 - accuracy: 0.9131 - val_loss: 0.3622 - val_accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3240 - accuracy: 0.9137 - val_loss: 0.3570 - val_accuracy: 0.9122\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3206 - accuracy: 0.9157 - val_loss: 0.3576 - val_accuracy: 0.9084\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 1s 41us/sample - loss: 0.3152 - accuracy: 0.9167 - val_loss: 0.3547 - val_accuracy: 0.9068\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3113 - accuracy: 0.9180 - val_loss: 0.3744 - val_accuracy: 0.9052\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3116 - accuracy: 0.9177 - val_loss: 0.3621 - val_accuracy: 0.9100\n",
      "18334/18334 [==============================] - 0s 24us/sample - loss: 0.3758 - accuracy: 0.9033\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.4691 - accuracy: 0.4459 - val_loss: 1.1036 - val_accuracy: 0.6508\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.9319 - accuracy: 0.7328 - val_loss: 0.7702 - val_accuracy: 0.7858\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7301 - accuracy: 0.7867 - val_loss: 0.6726 - val_accuracy: 0.8134\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 1s 41us/sample - loss: 0.6536 - accuracy: 0.8107 - val_loss: 0.6325 - val_accuracy: 0.8148\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6042 - accuracy: 0.8290 - val_loss: 0.5924 - val_accuracy: 0.8498\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.5609 - accuracy: 0.8471 - val_loss: 0.5571 - val_accuracy: 0.8584\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5266 - accuracy: 0.8619 - val_loss: 0.5406 - val_accuracy: 0.8640\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.5009 - accuracy: 0.8691 - val_loss: 0.5071 - val_accuracy: 0.8756\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4815 - accuracy: 0.8771 - val_loss: 0.5183 - val_accuracy: 0.8802\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4614 - accuracy: 0.8801 - val_loss: 0.4751 - val_accuracy: 0.8914\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4443 - accuracy: 0.8869 - val_loss: 0.4521 - val_accuracy: 0.8962\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4260 - accuracy: 0.8909 - val_loss: 0.5040 - val_accuracy: 0.8748\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4009 - accuracy: 0.8959 - val_loss: 0.4394 - val_accuracy: 0.8882\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3814 - accuracy: 0.8989 - val_loss: 0.3968 - val_accuracy: 0.9040\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3655 - accuracy: 0.9034 - val_loss: 0.3857 - val_accuracy: 0.9054\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3514 - accuracy: 0.9059 - val_loss: 0.3706 - val_accuracy: 0.9064\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3417 - accuracy: 0.9080 - val_loss: 0.3794 - val_accuracy: 0.9048\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3340 - accuracy: 0.9098 - val_loss: 0.3670 - val_accuracy: 0.9082\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3282 - accuracy: 0.9131 - val_loss: 0.3716 - val_accuracy: 0.9064\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3211 - accuracy: 0.9129 - val_loss: 0.3576 - val_accuracy: 0.9076\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3174 - accuracy: 0.9143 - val_loss: 0.3542 - val_accuracy: 0.9146\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3114 - accuracy: 0.9164 - val_loss: 0.3530 - val_accuracy: 0.9112\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.3076 - accuracy: 0.9154 - val_loss: 0.3475 - val_accuracy: 0.9130\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 0.3041 - accuracy: 0.9187 - val_loss: 0.3384 - val_accuracy: 0.9196\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.3005 - accuracy: 0.9197 - val_loss: 0.3478 - val_accuracy: 0.9128\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.2961 - accuracy: 0.9200 - val_loss: 0.3370 - val_accuracy: 0.9176\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.2939 - accuracy: 0.9214 - val_loss: 0.3371 - val_accuracy: 0.9174\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.2924 - accuracy: 0.9211 - val_loss: 0.3397 - val_accuracy: 0.9152\n",
      "18333/18333 [==============================] - 1s 29us/sample - loss: 0.3720 - accuracy: 0.9056\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 84us/sample - loss: 1.4453 - accuracy: 0.5097 - val_loss: 0.8340 - val_accuracy: 0.7420\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.6834 - accuracy: 0.8028 - val_loss: 0.5863 - val_accuracy: 0.8438\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5423 - accuracy: 0.8472 - val_loss: 0.5074 - val_accuracy: 0.8672\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4854 - accuracy: 0.8672 - val_loss: 0.4958 - val_accuracy: 0.8694\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4469 - accuracy: 0.8772 - val_loss: 0.4474 - val_accuracy: 0.8802\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4196 - accuracy: 0.8863 - val_loss: 0.4248 - val_accuracy: 0.8872\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3956 - accuracy: 0.8913 - val_loss: 0.4220 - val_accuracy: 0.8882\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.3788 - accuracy: 0.8969 - val_loss: 0.4287 - val_accuracy: 0.8870\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3633 - accuracy: 0.9002 - val_loss: 0.3922 - val_accuracy: 0.8992\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3505 - accuracy: 0.9048 - val_loss: 0.3799 - val_accuracy: 0.8992\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3414 - accuracy: 0.9065 - val_loss: 0.3648 - val_accuracy: 0.9034\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.3353 - accuracy: 0.9087 - val_loss: 0.3547 - val_accuracy: 0.9082\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3266 - accuracy: 0.9096 - val_loss: 0.3742 - val_accuracy: 0.9052\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 3s 78us/sample - loss: 0.3209 - accuracy: 0.9127 - val_loss: 0.3474 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3136 - accuracy: 0.9150 - val_loss: 0.3441 - val_accuracy: 0.9076\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3082 - accuracy: 0.9171 - val_loss: 0.3437 - val_accuracy: 0.9056\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3085 - accuracy: 0.9151 - val_loss: 0.3365 - val_accuracy: 0.9138\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.3004 - accuracy: 0.9170 - val_loss: 0.3524 - val_accuracy: 0.9034\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.2960 - accuracy: 0.9178 - val_loss: 0.3438 - val_accuracy: 0.9086\n",
      "18333/18333 [==============================] - 1s 35us/sample - loss: 0.3392 - accuracy: 0.9077\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 60us/sample - loss: 1.4819 - accuracy: 0.4216 - val_loss: 1.0818 - val_accuracy: 0.6142\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9748 - accuracy: 0.6436 - val_loss: 0.8933 - val_accuracy: 0.6852\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7955 - accuracy: 0.7308 - val_loss: 0.6983 - val_accuracy: 0.7956\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6429 - accuracy: 0.8108 - val_loss: 0.5801 - val_accuracy: 0.8400\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5312 - accuracy: 0.8470 - val_loss: 0.4939 - val_accuracy: 0.8662\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.4726 - accuracy: 0.8655 - val_loss: 0.4620 - val_accuracy: 0.8674\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4254 - accuracy: 0.8805 - val_loss: 0.4784 - val_accuracy: 0.8562\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.3950 - accuracy: 0.8892 - val_loss: 0.4206 - val_accuracy: 0.8910\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3706 - accuracy: 0.8966 - val_loss: 0.3700 - val_accuracy: 0.9036\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3495 - accuracy: 0.9041 - val_loss: 0.3652 - val_accuracy: 0.9096\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 56us/sample - loss: 0.3334 - accuracy: 0.9090 - val_loss: 0.3676 - val_accuracy: 0.9094\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.3203 - accuracy: 0.9117 - val_loss: 0.3256 - val_accuracy: 0.9212\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3117 - accuracy: 0.9140 - val_loss: 0.3790 - val_accuracy: 0.9040\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3061 - accuracy: 0.9152 - val_loss: 0.3390 - val_accuracy: 0.9124\n",
      "18334/18334 [==============================] - 1s 27us/sample - loss: 0.3676 - accuracy: 0.9014\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.4651 - accuracy: 0.4506 - val_loss: 1.1251 - val_accuracy: 0.6274\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.0076 - accuracy: 0.6687 - val_loss: 0.8860 - val_accuracy: 0.7326\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7496 - accuracy: 0.7837 - val_loss: 0.6041 - val_accuracy: 0.8434\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6045 - accuracy: 0.8340 - val_loss: 0.5520 - val_accuracy: 0.8532\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5225 - accuracy: 0.8582 - val_loss: 0.4752 - val_accuracy: 0.8758\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4640 - accuracy: 0.8750 - val_loss: 0.4481 - val_accuracy: 0.8836\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4117 - accuracy: 0.8903 - val_loss: 0.3849 - val_accuracy: 0.9026\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 0.3770 - accuracy: 0.8975 - val_loss: 0.3702 - val_accuracy: 0.9104\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3583 - accuracy: 0.9020 - val_loss: 0.3591 - val_accuracy: 0.9116\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 1s 40us/sample - loss: 0.3420 - accuracy: 0.9089 - val_loss: 0.3476 - val_accuracy: 0.9142\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3321 - accuracy: 0.9122 - val_loss: 0.3438 - val_accuracy: 0.9168\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3196 - accuracy: 0.9168 - val_loss: 0.3387 - val_accuracy: 0.9178\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3112 - accuracy: 0.9176 - val_loss: 0.3300 - val_accuracy: 0.9196\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3037 - accuracy: 0.9195 - val_loss: 0.3274 - val_accuracy: 0.9160\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.2950 - accuracy: 0.9209 - val_loss: 0.3342 - val_accuracy: 0.9168\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.2882 - accuracy: 0.9226 - val_loss: 0.3250 - val_accuracy: 0.9206\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.2841 - accuracy: 0.9236 - val_loss: 0.3489 - val_accuracy: 0.9126\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.2810 - accuracy: 0.9231 - val_loss: 0.3184 - val_accuracy: 0.9206\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.2783 - accuracy: 0.9253 - val_loss: 0.3251 - val_accuracy: 0.9230\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.2746 - accuracy: 0.9257 - val_loss: 0.3190 - val_accuracy: 0.9204\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.3665 - accuracy: 0.9068\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 1.4766 - accuracy: 0.4375 - val_loss: 1.1321 - val_accuracy: 0.6092\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 1.0437 - accuracy: 0.6418 - val_loss: 0.9330 - val_accuracy: 0.7084\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8911 - accuracy: 0.7142 - val_loss: 0.7802 - val_accuracy: 0.7700\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7044 - accuracy: 0.7961 - val_loss: 0.6099 - val_accuracy: 0.8346\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5902 - accuracy: 0.8363 - val_loss: 0.5298 - val_accuracy: 0.8624\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5305 - accuracy: 0.8576 - val_loss: 0.4849 - val_accuracy: 0.8774\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4835 - accuracy: 0.8715 - val_loss: 0.4584 - val_accuracy: 0.8822\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4487 - accuracy: 0.8801 - val_loss: 0.4464 - val_accuracy: 0.8838\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4229 - accuracy: 0.8866 - val_loss: 0.3933 - val_accuracy: 0.8994\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.4038 - accuracy: 0.8916 - val_loss: 0.3911 - val_accuracy: 0.9014\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 41us/sample - loss: 0.3891 - accuracy: 0.8960 - val_loss: 0.3974 - val_accuracy: 0.9012\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3735 - accuracy: 0.9006 - val_loss: 0.3797 - val_accuracy: 0.9010\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3625 - accuracy: 0.9031 - val_loss: 0.3724 - val_accuracy: 0.9054\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.3568 - accuracy: 0.9051 - val_loss: 0.3467 - val_accuracy: 0.9104\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3446 - accuracy: 0.9088 - val_loss: 0.3543 - val_accuracy: 0.9130\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3368 - accuracy: 0.9092 - val_loss: 0.3334 - val_accuracy: 0.9114\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.3317 - accuracy: 0.9111 - val_loss: 0.3548 - val_accuracy: 0.9102\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3259 - accuracy: 0.9135 - val_loss: 0.3295 - val_accuracy: 0.9142\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3189 - accuracy: 0.9144 - val_loss: 0.3403 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3120 - accuracy: 0.9158 - val_loss: 0.3363 - val_accuracy: 0.9134\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.3519 - accuracy: 0.9074\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 30us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 2.0843 - accuracy: 0.1959 - val_loss: 1.9505 - val_accuracy: 0.2396\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.9001 - accuracy: 0.2704 - val_loss: 1.8304 - val_accuracy: 0.3008\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.8188 - accuracy: 0.2987 - val_loss: 1.7725 - val_accuracy: 0.2850\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.7730 - accuracy: 0.3133 - val_loss: 1.7394 - val_accuracy: 0.3252\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.7507 - accuracy: 0.3238 - val_loss: 1.7264 - val_accuracy: 0.3370\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.7380 - accuracy: 0.3316 - val_loss: 1.7151 - val_accuracy: 0.3404\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.7271 - accuracy: 0.3368 - val_loss: 1.7075 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.7201 - accuracy: 0.3448 - val_loss: 1.6974 - val_accuracy: 0.3540\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.7142 - accuracy: 0.3449 - val_loss: 1.6927 - val_accuracy: 0.3576\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.7089 - accuracy: 0.3499 - val_loss: 1.6886 - val_accuracy: 0.3622\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.7041 - accuracy: 0.3497 - val_loss: 1.6839 - val_accuracy: 0.3538\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6992 - accuracy: 0.3566 - val_loss: 1.6800 - val_accuracy: 0.3618\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.6942 - accuracy: 0.3589 - val_loss: 1.6799 - val_accuracy: 0.3642\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6911 - accuracy: 0.3593 - val_loss: 1.6759 - val_accuracy: 0.3780\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.6875 - accuracy: 0.3659 - val_loss: 1.6788 - val_accuracy: 0.3708\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.6849 - accuracy: 0.3650 - val_loss: 1.6683 - val_accuracy: 0.3728\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.6816 - accuracy: 0.3660 - val_loss: 1.6665 - val_accuracy: 0.3698\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.6786 - accuracy: 0.3661 - val_loss: 1.6724 - val_accuracy: 0.3638\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.6767 - accuracy: 0.3666 - val_loss: 1.6631 - val_accuracy: 0.3760\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.6747 - accuracy: 0.3681 - val_loss: 1.6618 - val_accuracy: 0.3724\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.6732 - accuracy: 0.3682 - val_loss: 1.6637 - val_accuracy: 0.3748\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 59us/sample - loss: 1.6713 - accuracy: 0.3654 - val_loss: 1.6590 - val_accuracy: 0.3736\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.6698 - accuracy: 0.3690 - val_loss: 1.6630 - val_accuracy: 0.3726\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.6682 - accuracy: 0.3711 - val_loss: 1.6562 - val_accuracy: 0.3732\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6670 - accuracy: 0.3699 - val_loss: 1.6554 - val_accuracy: 0.3762\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.6654 - accuracy: 0.3707 - val_loss: 1.6564 - val_accuracy: 0.3690\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6649 - accuracy: 0.3716 - val_loss: 1.6543 - val_accuracy: 0.3732\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 1.6639 - accuracy: 0.3730 - val_loss: 1.6518 - val_accuracy: 0.3772\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.6628 - accuracy: 0.3739 - val_loss: 1.6506 - val_accuracy: 0.3698\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.6617 - accuracy: 0.3740 - val_loss: 1.6517 - val_accuracy: 0.3572\n",
      "18333/18333 [==============================] - 1s 28us/sample - loss: 1.6845 - accuracy: 0.3494\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 73us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 101us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 2.3017 - accuracy: 0.1110 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36666/36666 [==============================] - 2s 63us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 0s 26us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 2.3017 - accuracy: 0.1109 - val_loss: 2.3012 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 2.3014 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 2.3013 - accuracy: 0.1113 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 2.3014 - accuracy: 0.1144\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 95us/sample - loss: 2.3015 - accuracy: 0.1138 - val_loss: 2.3007 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 2.3012 - accuracy: 0.1143 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 2.3011 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18333/18333 [==============================] - 1s 28us/sample - loss: 2.3018 - accuracy: 0.1085\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 89us/sample - loss: 2.3018 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1126\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 3s 73us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3009 - val_accuracy: 0.1126\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 2.3016 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1126\n",
      "18334/18334 [==============================] - 1s 30us/sample - loss: 2.3011 - accuracy: 0.1142\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 101us/sample - loss: 1.9073 - accuracy: 0.2388 - val_loss: 1.6170 - val_accuracy: 0.3654\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 4s 107us/sample - loss: 1.4808 - accuracy: 0.4058 - val_loss: 1.3801 - val_accuracy: 0.4646\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 92us/sample - loss: 1.3029 - accuracy: 0.4998 - val_loss: 1.2675 - val_accuracy: 0.5362\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 1.2083 - accuracy: 0.5364 - val_loss: 1.1985 - val_accuracy: 0.5520\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 1.1449 - accuracy: 0.5629 - val_loss: 1.1453 - val_accuracy: 0.5596\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 1.1022 - accuracy: 0.5756 - val_loss: 1.1076 - val_accuracy: 0.5856\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 1.0731 - accuracy: 0.5856 - val_loss: 1.0861 - val_accuracy: 0.5802\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 1.0484 - accuracy: 0.5902 - val_loss: 1.0694 - val_accuracy: 0.6036\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.0338 - accuracy: 0.6018 - val_loss: 1.0639 - val_accuracy: 0.6028\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 1.0219 - accuracy: 0.6097 - val_loss: 1.0552 - val_accuracy: 0.6042\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 1.0112 - accuracy: 0.6174 - val_loss: 1.0558 - val_accuracy: 0.6110\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.0011 - accuracy: 0.6309 - val_loss: 1.0431 - val_accuracy: 0.6344\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.9901 - accuracy: 0.6539 - val_loss: 1.0173 - val_accuracy: 0.6650\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.9684 - accuracy: 0.6713 - val_loss: 0.9854 - val_accuracy: 0.6812\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.9476 - accuracy: 0.6866 - val_loss: 0.9705 - val_accuracy: 0.6968\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.9314 - accuracy: 0.6989 - val_loss: 0.9520 - val_accuracy: 0.6978\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.9165 - accuracy: 0.7016 - val_loss: 0.9431 - val_accuracy: 0.7074\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.9058 - accuracy: 0.7071 - val_loss: 0.9309 - val_accuracy: 0.7050\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.8978 - accuracy: 0.7118 - val_loss: 0.9255 - val_accuracy: 0.7066\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.8912 - accuracy: 0.7145 - val_loss: 0.9162 - val_accuracy: 0.7128\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8842 - accuracy: 0.7158 - val_loss: 0.9184 - val_accuracy: 0.7120\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.8741 - accuracy: 0.7239 - val_loss: 0.8954 - val_accuracy: 0.7364\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.8654 - accuracy: 0.7357 - val_loss: 0.8928 - val_accuracy: 0.7472\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.8579 - accuracy: 0.7449 - val_loss: 0.8823 - val_accuracy: 0.7504\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.8491 - accuracy: 0.7504 - val_loss: 0.8640 - val_accuracy: 0.7572\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.8415 - accuracy: 0.7535 - val_loss: 0.9135 - val_accuracy: 0.7274\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.8370 - accuracy: 0.7571 - val_loss: 0.9506 - val_accuracy: 0.7154\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.9074 - accuracy: 0.7432\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 1.9786 - accuracy: 0.2086 - val_loss: 1.7817 - val_accuracy: 0.2474\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 3s 77us/sample - loss: 1.6795 - accuracy: 0.3151 - val_loss: 1.5111 - val_accuracy: 0.3968\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 1.4468 - accuracy: 0.4419 - val_loss: 1.3430 - val_accuracy: 0.5090\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 1.3567 - accuracy: 0.4934 - val_loss: 1.2975 - val_accuracy: 0.5256\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 1.2675 - accuracy: 0.5219 - val_loss: 1.1615 - val_accuracy: 0.5672\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.1376 - accuracy: 0.5492 - val_loss: 1.0812 - val_accuracy: 0.5832\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.0633 - accuracy: 0.5898 - val_loss: 1.0105 - val_accuracy: 0.6100\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.0176 - accuracy: 0.6186 - val_loss: 0.9666 - val_accuracy: 0.6410\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.9828 - accuracy: 0.6287 - val_loss: 0.9463 - val_accuracy: 0.6526\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.9570 - accuracy: 0.6430 - val_loss: 0.9117 - val_accuracy: 0.6634\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.9380 - accuracy: 0.6476 - val_loss: 0.9171 - val_accuracy: 0.6630\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.9253 - accuracy: 0.6534 - val_loss: 0.9058 - val_accuracy: 0.6624\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 57us/sample - loss: 0.9161 - accuracy: 0.6544 - val_loss: 0.8968 - val_accuracy: 0.6696\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.9057 - accuracy: 0.6538 - val_loss: 0.8799 - val_accuracy: 0.6742\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.9004 - accuracy: 0.6583 - val_loss: 0.8851 - val_accuracy: 0.6766\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.8954 - accuracy: 0.6595 - val_loss: 0.8823 - val_accuracy: 0.6820\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.9116 - accuracy: 0.6667\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 4s 104us/sample - loss: 1.9273 - accuracy: 0.2342 - val_loss: 1.6553 - val_accuracy: 0.3396\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 61us/sample - loss: 1.5079 - accuracy: 0.4233 - val_loss: 1.3894 - val_accuracy: 0.4740\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.3834 - accuracy: 0.4899 - val_loss: 1.2985 - val_accuracy: 0.5380\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.2978 - accuracy: 0.5280 - val_loss: 1.2302 - val_accuracy: 0.5850\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.2341 - accuracy: 0.5563 - val_loss: 1.1841 - val_accuracy: 0.5788\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 1.1765 - accuracy: 0.5970 - val_loss: 1.1366 - val_accuracy: 0.6140\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 1.1457 - accuracy: 0.6063 - val_loss: 1.1427 - val_accuracy: 0.6128\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 1.1298 - accuracy: 0.6117 - val_loss: 1.1192 - val_accuracy: 0.6142\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.1146 - accuracy: 0.6187 - val_loss: 1.1004 - val_accuracy: 0.6448\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 1.1021 - accuracy: 0.6247 - val_loss: 1.0874 - val_accuracy: 0.6442\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 1.0858 - accuracy: 0.6282 - val_loss: 1.0793 - val_accuracy: 0.6460\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 1.0742 - accuracy: 0.6322 - val_loss: 1.1192 - val_accuracy: 0.6054\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 55us/sample - loss: 1.0629 - accuracy: 0.6351 - val_loss: 1.0749 - val_accuracy: 0.6316\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 1.0548 - accuracy: 0.6391 - val_loss: 1.0884 - val_accuracy: 0.6290\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 3s 70us/sample - loss: 1.0479 - accuracy: 0.6457 - val_loss: 1.0750 - val_accuracy: 0.6634\n",
      "18334/18334 [==============================] - 1s 32us/sample - loss: 1.1354 - accuracy: 0.6098\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 105us/sample - loss: 1.6180 - accuracy: 0.4045 - val_loss: 1.2321 - val_accuracy: 0.5582\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.1230 - accuracy: 0.6236 - val_loss: 1.0000 - val_accuracy: 0.6792\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.9495 - accuracy: 0.6943 - val_loss: 0.8535 - val_accuracy: 0.7218\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.8431 - accuracy: 0.7207 - val_loss: 0.7844 - val_accuracy: 0.7438\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.7860 - accuracy: 0.7367 - val_loss: 0.7439 - val_accuracy: 0.7538\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7457 - accuracy: 0.7524 - val_loss: 0.7209 - val_accuracy: 0.7732\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7126 - accuracy: 0.7626 - val_loss: 0.7009 - val_accuracy: 0.7698\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6900 - accuracy: 0.7683 - val_loss: 0.6786 - val_accuracy: 0.7754\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6662 - accuracy: 0.7759 - val_loss: 0.6613 - val_accuracy: 0.7860\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6447 - accuracy: 0.7816 - val_loss: 0.6444 - val_accuracy: 0.7910\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6278 - accuracy: 0.7909 - val_loss: 0.6308 - val_accuracy: 0.8072\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6120 - accuracy: 0.7983 - val_loss: 0.6182 - val_accuracy: 0.8070\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.5967 - accuracy: 0.8078 - val_loss: 0.6078 - val_accuracy: 0.8190\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5808 - accuracy: 0.8138 - val_loss: 0.5878 - val_accuracy: 0.8280\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5700 - accuracy: 0.8229 - val_loss: 0.5806 - val_accuracy: 0.8206\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.5548 - accuracy: 0.8304 - val_loss: 0.5686 - val_accuracy: 0.8396\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5400 - accuracy: 0.8382 - val_loss: 0.5457 - val_accuracy: 0.8516\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5302 - accuracy: 0.8432 - val_loss: 0.5182 - val_accuracy: 0.8500\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.5207 - accuracy: 0.8476 - val_loss: 0.5145 - val_accuracy: 0.8590\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.5121 - accuracy: 0.8503 - val_loss: 0.5109 - val_accuracy: 0.8648\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5061 - accuracy: 0.8543 - val_loss: 0.5016 - val_accuracy: 0.8636\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5006 - accuracy: 0.8575 - val_loss: 0.4935 - val_accuracy: 0.8670\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4948 - accuracy: 0.8579 - val_loss: 0.4858 - val_accuracy: 0.8698\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4844 - accuracy: 0.8604 - val_loss: 0.4837 - val_accuracy: 0.8714\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4826 - accuracy: 0.8638 - val_loss: 0.5137 - val_accuracy: 0.8620\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.4784 - accuracy: 0.8662 - val_loss: 0.4883 - val_accuracy: 0.8680\n",
      "18333/18333 [==============================] - 1s 32us/sample - loss: 0.5403 - accuracy: 0.8510\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 69us/sample - loss: 1.7562 - accuracy: 0.2673 - val_loss: 1.4463 - val_accuracy: 0.3908\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.4230 - accuracy: 0.3975 - val_loss: 1.3525 - val_accuracy: 0.4278\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.3459 - accuracy: 0.4490 - val_loss: 1.3027 - val_accuracy: 0.4572\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 1.2729 - accuracy: 0.4918 - val_loss: 1.2161 - val_accuracy: 0.5168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.1887 - accuracy: 0.5260 - val_loss: 1.1145 - val_accuracy: 0.5630\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.1082 - accuracy: 0.5757 - val_loss: 1.0541 - val_accuracy: 0.5996\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.0332 - accuracy: 0.6061 - val_loss: 0.9930 - val_accuracy: 0.6118\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.9830 - accuracy: 0.6276 - val_loss: 1.0395 - val_accuracy: 0.6088\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.9447 - accuracy: 0.6387 - val_loss: 0.9091 - val_accuracy: 0.6472\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.9143 - accuracy: 0.6492 - val_loss: 0.8867 - val_accuracy: 0.6562\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.8896 - accuracy: 0.6531 - val_loss: 0.8784 - val_accuracy: 0.6572\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8699 - accuracy: 0.6575 - val_loss: 0.8829 - val_accuracy: 0.6472\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.8554 - accuracy: 0.6629 - val_loss: 0.8722 - val_accuracy: 0.6636\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.8491 - accuracy: 0.6656 - val_loss: 0.8637 - val_accuracy: 0.6622\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.8425 - accuracy: 0.6685 - val_loss: 0.8502 - val_accuracy: 0.6688\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.8335 - accuracy: 0.6733 - val_loss: 0.8655 - val_accuracy: 0.6604\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8245 - accuracy: 0.6827 - val_loss: 0.8496 - val_accuracy: 0.6820\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.7984 - accuracy: 0.7147 - val_loss: 0.7854 - val_accuracy: 0.7470\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.7578 - accuracy: 0.7359 - val_loss: 0.7783 - val_accuracy: 0.7450\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7341 - accuracy: 0.7438 - val_loss: 0.7408 - val_accuracy: 0.7526\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7214 - accuracy: 0.7481 - val_loss: 0.7219 - val_accuracy: 0.7534\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.7088 - accuracy: 0.7544 - val_loss: 0.7285 - val_accuracy: 0.7680\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6962 - accuracy: 0.7760 - val_loss: 0.6855 - val_accuracy: 0.8106\n",
      "Epoch 24/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6620 - accuracy: 0.8087 - val_loss: 0.6516 - val_accuracy: 0.8232\n",
      "Epoch 25/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6437 - accuracy: 0.8187 - val_loss: 0.6535 - val_accuracy: 0.8236\n",
      "Epoch 26/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6306 - accuracy: 0.8228 - val_loss: 0.6409 - val_accuracy: 0.8342\n",
      "Epoch 27/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.6230 - accuracy: 0.8245 - val_loss: 0.6312 - val_accuracy: 0.8400\n",
      "Epoch 28/30\n",
      "36667/36667 [==============================] - 2s 61us/sample - loss: 0.6161 - accuracy: 0.8269 - val_loss: 0.6249 - val_accuracy: 0.8430\n",
      "Epoch 29/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.6110 - accuracy: 0.8299 - val_loss: 0.6185 - val_accuracy: 0.8402\n",
      "Epoch 30/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6069 - accuracy: 0.8316 - val_loss: 0.6257 - val_accuracy: 0.8422\n",
      "18333/18333 [==============================] - 1s 30us/sample - loss: 0.6210 - accuracy: 0.8273\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 71us/sample - loss: 1.6377 - accuracy: 0.3792 - val_loss: 1.2785 - val_accuracy: 0.5336\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 1.1038 - accuracy: 0.6214 - val_loss: 0.9907 - val_accuracy: 0.6824\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.9364 - accuracy: 0.6945 - val_loss: 0.8956 - val_accuracy: 0.7106\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.8316 - accuracy: 0.7506 - val_loss: 0.7802 - val_accuracy: 0.7952\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7404 - accuracy: 0.7971 - val_loss: 0.7248 - val_accuracy: 0.8068\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6983 - accuracy: 0.8091 - val_loss: 0.7016 - val_accuracy: 0.8224\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6779 - accuracy: 0.8169 - val_loss: 0.7071 - val_accuracy: 0.8180\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6635 - accuracy: 0.8197 - val_loss: 0.6871 - val_accuracy: 0.8162\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6531 - accuracy: 0.8224 - val_loss: 0.6840 - val_accuracy: 0.8206\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6470 - accuracy: 0.8217 - val_loss: 0.6797 - val_accuracy: 0.8228\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6381 - accuracy: 0.8260 - val_loss: 0.6798 - val_accuracy: 0.8096\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.6250 - accuracy: 0.8285 - val_loss: 0.6440 - val_accuracy: 0.8326\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.6138 - accuracy: 0.8331 - val_loss: 0.6796 - val_accuracy: 0.8278\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.6068 - accuracy: 0.8363 - val_loss: 0.6620 - val_accuracy: 0.8430\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.6903 - accuracy: 0.8203\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 74us/sample - loss: 1.5889 - accuracy: 0.4174 - val_loss: 1.1194 - val_accuracy: 0.6464\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 1.0053 - accuracy: 0.6751 - val_loss: 0.8633 - val_accuracy: 0.7334\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.8531 - accuracy: 0.7422 - val_loss: 0.7744 - val_accuracy: 0.7760\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.7494 - accuracy: 0.7953 - val_loss: 0.6762 - val_accuracy: 0.8124\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.6785 - accuracy: 0.8179 - val_loss: 0.6491 - val_accuracy: 0.8242\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.6346 - accuracy: 0.8312 - val_loss: 0.6153 - val_accuracy: 0.8362\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 60us/sample - loss: 0.5957 - accuracy: 0.8460 - val_loss: 0.5742 - val_accuracy: 0.8498\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5550 - accuracy: 0.8563 - val_loss: 0.5370 - val_accuracy: 0.8636\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5133 - accuracy: 0.8671 - val_loss: 0.5256 - val_accuracy: 0.8692\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4880 - accuracy: 0.8738 - val_loss: 0.5018 - val_accuracy: 0.8734\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4725 - accuracy: 0.8785 - val_loss: 0.4837 - val_accuracy: 0.8752\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.4551 - accuracy: 0.8817 - val_loss: 0.5043 - val_accuracy: 0.8728\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36667/36667 [==============================] - 3s 75us/sample - loss: 0.4399 - accuracy: 0.8862 - val_loss: 0.4587 - val_accuracy: 0.8802\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 64us/sample - loss: 0.4308 - accuracy: 0.8865 - val_loss: 0.4603 - val_accuracy: 0.8882\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4184 - accuracy: 0.8901 - val_loss: 0.4530 - val_accuracy: 0.8894\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4112 - accuracy: 0.8928 - val_loss: 0.4523 - val_accuracy: 0.8892\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4022 - accuracy: 0.8955 - val_loss: 0.4627 - val_accuracy: 0.8878\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.3990 - accuracy: 0.8976 - val_loss: 0.4451 - val_accuracy: 0.8862\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3944 - accuracy: 0.8995 - val_loss: 0.4312 - val_accuracy: 0.8954\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.3877 - accuracy: 0.9014 - val_loss: 0.4395 - val_accuracy: 0.8934\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3819 - accuracy: 0.9018 - val_loss: 0.4333 - val_accuracy: 0.8974\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.4683 - accuracy: 0.8849\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 68us/sample - loss: 1.8199 - accuracy: 0.2743 - val_loss: 1.5544 - val_accuracy: 0.3908\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 1.4259 - accuracy: 0.4374 - val_loss: 1.2964 - val_accuracy: 0.5620\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 1.1611 - accuracy: 0.5876 - val_loss: 1.0334 - val_accuracy: 0.6712\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.9208 - accuracy: 0.6821 - val_loss: 0.8516 - val_accuracy: 0.7134\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.8168 - accuracy: 0.7168 - val_loss: 0.8020 - val_accuracy: 0.7436\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.7798 - accuracy: 0.7356 - val_loss: 0.7957 - val_accuracy: 0.7420\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.7580 - accuracy: 0.7407 - val_loss: 0.7885 - val_accuracy: 0.7456\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7456 - accuracy: 0.7494 - val_loss: 0.7601 - val_accuracy: 0.7554\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7273 - accuracy: 0.7505 - val_loss: 0.7537 - val_accuracy: 0.7608\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7196 - accuracy: 0.7550 - val_loss: 0.7544 - val_accuracy: 0.7582\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.7126 - accuracy: 0.7581 - val_loss: 0.7627 - val_accuracy: 0.7522\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.7488 - accuracy: 0.7577\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 66us/sample - loss: 1.7149 - accuracy: 0.3061 - val_loss: 1.3859 - val_accuracy: 0.5216\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 1.2623 - accuracy: 0.5934 - val_loss: 1.1179 - val_accuracy: 0.6722\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 1.0693 - accuracy: 0.6737 - val_loss: 1.0416 - val_accuracy: 0.6606\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.9466 - accuracy: 0.7151 - val_loss: 0.8507 - val_accuracy: 0.7588\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.8586 - accuracy: 0.7448 - val_loss: 0.8584 - val_accuracy: 0.7204\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7936 - accuracy: 0.7709 - val_loss: 0.7665 - val_accuracy: 0.7952\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.7413 - accuracy: 0.7929 - val_loss: 0.7423 - val_accuracy: 0.8022\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6960 - accuracy: 0.8087 - val_loss: 0.6706 - val_accuracy: 0.8238\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.6659 - accuracy: 0.8193 - val_loss: 0.6602 - val_accuracy: 0.8332\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.6414 - accuracy: 0.8279 - val_loss: 0.6317 - val_accuracy: 0.8404\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6238 - accuracy: 0.8362 - val_loss: 0.6053 - val_accuracy: 0.8468\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 51us/sample - loss: 0.6075 - accuracy: 0.8386 - val_loss: 0.6040 - val_accuracy: 0.8484\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5921 - accuracy: 0.8448 - val_loss: 0.6072 - val_accuracy: 0.8452\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.5822 - accuracy: 0.8493 - val_loss: 0.5815 - val_accuracy: 0.8480\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5687 - accuracy: 0.8528 - val_loss: 0.5780 - val_accuracy: 0.8526\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5605 - accuracy: 0.8562 - val_loss: 0.5753 - val_accuracy: 0.8566\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5509 - accuracy: 0.8593 - val_loss: 0.5705 - val_accuracy: 0.8530\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5429 - accuracy: 0.8621 - val_loss: 0.5768 - val_accuracy: 0.8488\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5377 - accuracy: 0.8623 - val_loss: 0.5604 - val_accuracy: 0.8558\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5315 - accuracy: 0.8664 - val_loss: 0.5936 - val_accuracy: 0.8514\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.5231 - accuracy: 0.8680 - val_loss: 0.5472 - val_accuracy: 0.8638\n",
      "Epoch 22/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5184 - accuracy: 0.8687 - val_loss: 0.5339 - val_accuracy: 0.8674\n",
      "Epoch 23/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.5115 - accuracy: 0.8717 - val_loss: 0.5396 - val_accuracy: 0.8628\n",
      "Epoch 24/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5046 - accuracy: 0.8747 - val_loss: 0.5230 - val_accuracy: 0.8674\n",
      "Epoch 25/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.5054 - accuracy: 0.8754 - val_loss: 0.5505 - val_accuracy: 0.8582\n",
      "Epoch 26/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4951 - accuracy: 0.8754 - val_loss: 0.5286 - val_accuracy: 0.8716\n",
      "18334/18334 [==============================] - 0s 27us/sample - loss: 0.5759 - accuracy: 0.8549\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 72us/sample - loss: 1.4859 - accuracy: 0.4490 - val_loss: 0.9874 - val_accuracy: 0.7042\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.8474 - accuracy: 0.7421 - val_loss: 0.9455 - val_accuracy: 0.6790\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6855 - accuracy: 0.7905 - val_loss: 0.5979 - val_accuracy: 0.8380\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6251 - accuracy: 0.8151 - val_loss: 0.5937 - val_accuracy: 0.8368\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.5796 - accuracy: 0.8359 - val_loss: 0.5265 - val_accuracy: 0.8620\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5249 - accuracy: 0.8562 - val_loss: 0.4913 - val_accuracy: 0.8720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.4783 - accuracy: 0.8690 - val_loss: 0.5441 - val_accuracy: 0.8544\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4554 - accuracy: 0.8769 - val_loss: 0.4450 - val_accuracy: 0.8876\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4403 - accuracy: 0.8788 - val_loss: 0.4689 - val_accuracy: 0.8800\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4288 - accuracy: 0.8834 - val_loss: 0.4433 - val_accuracy: 0.8888\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4162 - accuracy: 0.8872 - val_loss: 0.4348 - val_accuracy: 0.8904\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4077 - accuracy: 0.8893 - val_loss: 0.4568 - val_accuracy: 0.8832\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4024 - accuracy: 0.8925 - val_loss: 0.4722 - val_accuracy: 0.8734\n",
      "18333/18333 [==============================] - 0s 26us/sample - loss: 0.4747 - accuracy: 0.8718\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 4s 100us/sample - loss: 1.9201 - accuracy: 0.2394 - val_loss: 1.6580 - val_accuracy: 0.3266\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 1.4904 - accuracy: 0.4108 - val_loss: 1.4012 - val_accuracy: 0.4896\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.2744 - accuracy: 0.5377 - val_loss: 1.2026 - val_accuracy: 0.5496\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 1.1994 - accuracy: 0.5604 - val_loss: 1.1823 - val_accuracy: 0.5752\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 1.1635 - accuracy: 0.5696 - val_loss: 1.1250 - val_accuracy: 0.5904\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 1.1127 - accuracy: 0.6059 - val_loss: 1.0645 - val_accuracy: 0.6484\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.9416 - accuracy: 0.6810 - val_loss: 0.8923 - val_accuracy: 0.6982\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.8461 - accuracy: 0.7417 - val_loss: 0.7703 - val_accuracy: 0.7924\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.7236 - accuracy: 0.8006 - val_loss: 0.7112 - val_accuracy: 0.8154\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.6740 - accuracy: 0.8151 - val_loss: 0.6436 - val_accuracy: 0.8298\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6442 - accuracy: 0.8238 - val_loss: 0.6483 - val_accuracy: 0.8250\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.6225 - accuracy: 0.8344 - val_loss: 0.6136 - val_accuracy: 0.8348\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.6050 - accuracy: 0.8411 - val_loss: 0.6250 - val_accuracy: 0.8358\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.5939 - accuracy: 0.8450 - val_loss: 0.6358 - val_accuracy: 0.8422\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.6317 - accuracy: 0.8322\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 3s 70us/sample - loss: 1.4036 - accuracy: 0.4985 - val_loss: 0.9291 - val_accuracy: 0.7162\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.8350 - accuracy: 0.7441 - val_loss: 0.7812 - val_accuracy: 0.7784\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 59us/sample - loss: 0.7235 - accuracy: 0.7844 - val_loss: 0.6724 - val_accuracy: 0.8152\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.6283 - accuracy: 0.8204 - val_loss: 0.5930 - val_accuracy: 0.8426\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.5584 - accuracy: 0.8419 - val_loss: 0.5792 - val_accuracy: 0.8330\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.5161 - accuracy: 0.8538 - val_loss: 0.4978 - val_accuracy: 0.8692\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4911 - accuracy: 0.8620 - val_loss: 0.4840 - val_accuracy: 0.8738\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4691 - accuracy: 0.8684 - val_loss: 0.4727 - val_accuracy: 0.8700\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.4546 - accuracy: 0.8717 - val_loss: 0.4739 - val_accuracy: 0.8730\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4424 - accuracy: 0.8757 - val_loss: 0.4309 - val_accuracy: 0.8846\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.4302 - accuracy: 0.8794 - val_loss: 0.4732 - val_accuracy: 0.8720\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4182 - accuracy: 0.8825 - val_loss: 0.4189 - val_accuracy: 0.8842\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.4100 - accuracy: 0.8856 - val_loss: 0.4322 - val_accuracy: 0.8842\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 42us/sample - loss: 0.3975 - accuracy: 0.8907 - val_loss: 0.4062 - val_accuracy: 0.8914\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3855 - accuracy: 0.8935 - val_loss: 0.3908 - val_accuracy: 0.8940\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.3746 - accuracy: 0.8972 - val_loss: 0.3808 - val_accuracy: 0.8986\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.3660 - accuracy: 0.8993 - val_loss: 0.3746 - val_accuracy: 0.8962\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3567 - accuracy: 0.9006 - val_loss: 0.3763 - val_accuracy: 0.9030\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 50us/sample - loss: 0.3491 - accuracy: 0.9034 - val_loss: 0.3911 - val_accuracy: 0.8998\n",
      "18334/18334 [==============================] - 1s 28us/sample - loss: 0.4079 - accuracy: 0.8886\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 89us/sample - loss: 1.5364 - accuracy: 0.3995 - val_loss: 1.0721 - val_accuracy: 0.5912\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.9497 - accuracy: 0.6750 - val_loss: 0.8139 - val_accuracy: 0.7536\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.7548 - accuracy: 0.7691 - val_loss: 0.6759 - val_accuracy: 0.8062\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 58us/sample - loss: 0.6477 - accuracy: 0.8115 - val_loss: 0.5844 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 62us/sample - loss: 0.5765 - accuracy: 0.8382 - val_loss: 0.5274 - val_accuracy: 0.8590\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.5260 - accuracy: 0.8547 - val_loss: 0.5070 - val_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4941 - accuracy: 0.8648 - val_loss: 0.4765 - val_accuracy: 0.8726\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4659 - accuracy: 0.8745 - val_loss: 0.4694 - val_accuracy: 0.8740\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4456 - accuracy: 0.8795 - val_loss: 0.4965 - val_accuracy: 0.8666\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 50us/sample - loss: 0.4266 - accuracy: 0.8847 - val_loss: 0.4157 - val_accuracy: 0.8876\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4124 - accuracy: 0.8888 - val_loss: 0.4367 - val_accuracy: 0.8790\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3999 - accuracy: 0.8928 - val_loss: 0.4352 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18333/18333 [==============================] - 1s 32us/sample - loss: 0.4698 - accuracy: 0.8749\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 1.6436 - accuracy: 0.3935 - val_loss: 1.1870 - val_accuracy: 0.6268\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.9765 - accuracy: 0.6851 - val_loss: 0.8161 - val_accuracy: 0.7224\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 52us/sample - loss: 0.7746 - accuracy: 0.7359 - val_loss: 0.6971 - val_accuracy: 0.7644\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.6991 - accuracy: 0.7752 - val_loss: 0.6565 - val_accuracy: 0.8136\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.6380 - accuracy: 0.8120 - val_loss: 0.6493 - val_accuracy: 0.8084\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.6026 - accuracy: 0.8244 - val_loss: 0.5938 - val_accuracy: 0.8522\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.5744 - accuracy: 0.8337 - val_loss: 0.5793 - val_accuracy: 0.8434\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.5546 - accuracy: 0.8404 - val_loss: 0.5557 - val_accuracy: 0.8462\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.5344 - accuracy: 0.8457 - val_loss: 0.5957 - val_accuracy: 0.8348\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5218 - accuracy: 0.8525 - val_loss: 0.5315 - val_accuracy: 0.8608\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5056 - accuracy: 0.8566 - val_loss: 0.5320 - val_accuracy: 0.8626\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.4927 - accuracy: 0.8611 - val_loss: 0.5277 - val_accuracy: 0.8654\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4763 - accuracy: 0.8664 - val_loss: 0.4936 - val_accuracy: 0.8780\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 42us/sample - loss: 0.4632 - accuracy: 0.8712 - val_loss: 0.5017 - val_accuracy: 0.8660\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4513 - accuracy: 0.8740 - val_loss: 0.4786 - val_accuracy: 0.8784\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4410 - accuracy: 0.8777 - val_loss: 0.4497 - val_accuracy: 0.8852\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4301 - accuracy: 0.8818 - val_loss: 0.4476 - val_accuracy: 0.8874\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4196 - accuracy: 0.8836 - val_loss: 0.4431 - val_accuracy: 0.8920\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.4133 - accuracy: 0.8881 - val_loss: 0.4340 - val_accuracy: 0.8908\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 63us/sample - loss: 0.4043 - accuracy: 0.8904 - val_loss: 0.4663 - val_accuracy: 0.8800\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 55us/sample - loss: 0.3979 - accuracy: 0.8925 - val_loss: 0.4483 - val_accuracy: 0.8886\n",
      "18333/18333 [==============================] - 0s 25us/sample - loss: 0.4377 - accuracy: 0.8808\n",
      "Train on 36666 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36666/36666 [==============================] - 2s 64us/sample - loss: 1.4684 - accuracy: 0.4687 - val_loss: 0.9098 - val_accuracy: 0.7350\n",
      "Epoch 2/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.7764 - accuracy: 0.7863 - val_loss: 0.6856 - val_accuracy: 0.8106\n",
      "Epoch 3/30\n",
      "36666/36666 [==============================] - 2s 52us/sample - loss: 0.6185 - accuracy: 0.8357 - val_loss: 0.5625 - val_accuracy: 0.8530\n",
      "Epoch 4/30\n",
      "36666/36666 [==============================] - 2s 49us/sample - loss: 0.5079 - accuracy: 0.8678 - val_loss: 0.4880 - val_accuracy: 0.8682\n",
      "Epoch 5/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4447 - accuracy: 0.8861 - val_loss: 0.4210 - val_accuracy: 0.8904\n",
      "Epoch 6/30\n",
      "36666/36666 [==============================] - 2s 53us/sample - loss: 0.4131 - accuracy: 0.8956 - val_loss: 0.4152 - val_accuracy: 0.8890\n",
      "Epoch 7/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3868 - accuracy: 0.9002 - val_loss: 0.4035 - val_accuracy: 0.8980\n",
      "Epoch 8/30\n",
      "36666/36666 [==============================] - 2s 46us/sample - loss: 0.3669 - accuracy: 0.9060 - val_loss: 0.3832 - val_accuracy: 0.8978\n",
      "Epoch 9/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3500 - accuracy: 0.9103 - val_loss: 0.3756 - val_accuracy: 0.9066\n",
      "Epoch 10/30\n",
      "36666/36666 [==============================] - 2s 48us/sample - loss: 0.3381 - accuracy: 0.9136 - val_loss: 0.3843 - val_accuracy: 0.9020\n",
      "Epoch 11/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3241 - accuracy: 0.9148 - val_loss: 0.3474 - val_accuracy: 0.9114\n",
      "Epoch 12/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.3148 - accuracy: 0.9180 - val_loss: 0.3461 - val_accuracy: 0.9100\n",
      "Epoch 13/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.3088 - accuracy: 0.9192 - val_loss: 0.3455 - val_accuracy: 0.9146\n",
      "Epoch 14/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.2991 - accuracy: 0.9208 - val_loss: 0.3350 - val_accuracy: 0.9126\n",
      "Epoch 15/30\n",
      "36666/36666 [==============================] - 2s 61us/sample - loss: 0.2921 - accuracy: 0.9225 - val_loss: 0.3513 - val_accuracy: 0.9112\n",
      "Epoch 16/30\n",
      "36666/36666 [==============================] - 2s 54us/sample - loss: 0.2855 - accuracy: 0.9237 - val_loss: 0.3192 - val_accuracy: 0.9188\n",
      "Epoch 17/30\n",
      "36666/36666 [==============================] - 2s 44us/sample - loss: 0.2786 - accuracy: 0.9258 - val_loss: 0.3234 - val_accuracy: 0.9182\n",
      "Epoch 18/30\n",
      "36666/36666 [==============================] - 2s 43us/sample - loss: 0.2735 - accuracy: 0.9271 - val_loss: 0.3188 - val_accuracy: 0.9204\n",
      "Epoch 19/30\n",
      "36666/36666 [==============================] - 2s 47us/sample - loss: 0.2693 - accuracy: 0.9288 - val_loss: 0.3063 - val_accuracy: 0.9248\n",
      "Epoch 20/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.2631 - accuracy: 0.9299 - val_loss: 0.3176 - val_accuracy: 0.9190\n",
      "Epoch 21/30\n",
      "36666/36666 [==============================] - 2s 45us/sample - loss: 0.2587 - accuracy: 0.9308 - val_loss: 0.3226 - val_accuracy: 0.9192\n",
      "18334/18334 [==============================] - 1s 30us/sample - loss: 0.3450 - accuracy: 0.9131\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 3s 71us/sample - loss: 1.5276 - accuracy: 0.4047 - val_loss: 1.2433 - val_accuracy: 0.5128\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 1.0345 - accuracy: 0.6715 - val_loss: 0.8535 - val_accuracy: 0.7456\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 49us/sample - loss: 0.7940 - accuracy: 0.7621 - val_loss: 0.6745 - val_accuracy: 0.8252\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6378 - accuracy: 0.8259 - val_loss: 0.5657 - val_accuracy: 0.8494\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.5495 - accuracy: 0.8519 - val_loss: 0.5038 - val_accuracy: 0.8726\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.5011 - accuracy: 0.8665 - val_loss: 0.5103 - val_accuracy: 0.8604\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 53us/sample - loss: 0.4701 - accuracy: 0.8727 - val_loss: 0.4742 - val_accuracy: 0.8776\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.4461 - accuracy: 0.8782 - val_loss: 0.4364 - val_accuracy: 0.8876\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.4286 - accuracy: 0.8853 - val_loss: 0.4877 - val_accuracy: 0.8684\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.4117 - accuracy: 0.8875 - val_loss: 0.4210 - val_accuracy: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3970 - accuracy: 0.8920 - val_loss: 0.4041 - val_accuracy: 0.8944\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3833 - accuracy: 0.8958 - val_loss: 0.3909 - val_accuracy: 0.8958\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3737 - accuracy: 0.8982 - val_loss: 0.3955 - val_accuracy: 0.8968\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3652 - accuracy: 0.9004 - val_loss: 0.4009 - val_accuracy: 0.8944\n",
      "18333/18333 [==============================] - 0s 27us/sample - loss: 0.4423 - accuracy: 0.8880\n",
      "Train on 36667 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "36667/36667 [==============================] - 2s 65us/sample - loss: 1.5874 - accuracy: 0.3770 - val_loss: 1.1720 - val_accuracy: 0.6232\n",
      "Epoch 2/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 1.0864 - accuracy: 0.6453 - val_loss: 0.9153 - val_accuracy: 0.7092\n",
      "Epoch 3/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.8373 - accuracy: 0.7500 - val_loss: 0.6303 - val_accuracy: 0.8424\n",
      "Epoch 4/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.6368 - accuracy: 0.8264 - val_loss: 0.5179 - val_accuracy: 0.8676\n",
      "Epoch 5/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.5423 - accuracy: 0.8553 - val_loss: 0.4595 - val_accuracy: 0.8842\n",
      "Epoch 6/30\n",
      "36667/36667 [==============================] - 2s 56us/sample - loss: 0.4830 - accuracy: 0.8727 - val_loss: 0.4310 - val_accuracy: 0.8900\n",
      "Epoch 7/30\n",
      "36667/36667 [==============================] - 2s 54us/sample - loss: 0.4459 - accuracy: 0.8826 - val_loss: 0.4092 - val_accuracy: 0.8910\n",
      "Epoch 8/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.4181 - accuracy: 0.8896 - val_loss: 0.4143 - val_accuracy: 0.8858\n",
      "Epoch 9/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3977 - accuracy: 0.8943 - val_loss: 0.3631 - val_accuracy: 0.9032\n",
      "Epoch 10/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3837 - accuracy: 0.8984 - val_loss: 0.3584 - val_accuracy: 0.9048\n",
      "Epoch 11/30\n",
      "36667/36667 [==============================] - 2s 47us/sample - loss: 0.3698 - accuracy: 0.9015 - val_loss: 0.3922 - val_accuracy: 0.9000\n",
      "Epoch 12/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3618 - accuracy: 0.9050 - val_loss: 0.3477 - val_accuracy: 0.9110\n",
      "Epoch 13/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3530 - accuracy: 0.9064 - val_loss: 0.3615 - val_accuracy: 0.9038\n",
      "Epoch 14/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3444 - accuracy: 0.9084 - val_loss: 0.3458 - val_accuracy: 0.9108\n",
      "Epoch 15/30\n",
      "36667/36667 [==============================] - 2s 46us/sample - loss: 0.3390 - accuracy: 0.9119 - val_loss: 0.3432 - val_accuracy: 0.9102\n",
      "Epoch 16/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3328 - accuracy: 0.9125 - val_loss: 0.3399 - val_accuracy: 0.9138\n",
      "Epoch 17/30\n",
      "36667/36667 [==============================] - 2s 43us/sample - loss: 0.3297 - accuracy: 0.9140 - val_loss: 0.3476 - val_accuracy: 0.9088\n",
      "Epoch 18/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3231 - accuracy: 0.9139 - val_loss: 0.3388 - val_accuracy: 0.9122\n",
      "Epoch 19/30\n",
      "36667/36667 [==============================] - 2s 51us/sample - loss: 0.3193 - accuracy: 0.9158 - val_loss: 0.3416 - val_accuracy: 0.9122\n",
      "Epoch 20/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3164 - accuracy: 0.9153 - val_loss: 0.3315 - val_accuracy: 0.9136\n",
      "Epoch 21/30\n",
      "36667/36667 [==============================] - 2s 44us/sample - loss: 0.3106 - accuracy: 0.9172 - val_loss: 0.3220 - val_accuracy: 0.9154\n",
      "Epoch 22/30\n",
      "36667/36667 [==============================] - 2s 45us/sample - loss: 0.3061 - accuracy: 0.9183 - val_loss: 0.3379 - val_accuracy: 0.9130\n",
      "Epoch 23/30\n",
      "36667/36667 [==============================] - 2s 48us/sample - loss: 0.3034 - accuracy: 0.9194 - val_loss: 0.3643 - val_accuracy: 0.9044\n",
      "18333/18333 [==============================] - 1s 28us/sample - loss: 0.3568 - accuracy: 0.9073\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.6952 - accuracy: 0.7971 - val_loss: 0.3429 - val_accuracy: 0.9056\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3334 - accuracy: 0.9062 - val_loss: 0.2928 - val_accuracy: 0.9162\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2935 - accuracy: 0.9180 - val_loss: 0.2674 - val_accuracy: 0.9230\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 2s 31us/sample - loss: 0.2756 - accuracy: 0.9235 - val_loss: 0.2627 - val_accuracy: 0.9262\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 2s 32us/sample - loss: 0.2651 - accuracy: 0.9255 - val_loss: 0.2525 - val_accuracy: 0.9290\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.2562 - accuracy: 0.9281 - val_loss: 0.2496 - val_accuracy: 0.9302\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 2s 36us/sample - loss: 0.2492 - accuracy: 0.9314 - val_loss: 0.2528 - val_accuracy: 0.9328\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2427 - accuracy: 0.9323 - val_loss: 0.2355 - val_accuracy: 0.9352\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2380 - accuracy: 0.9352 - val_loss: 0.2331 - val_accuracy: 0.9342\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.2336 - accuracy: 0.9349 - val_loss: 0.2300 - val_accuracy: 0.9354\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2289 - accuracy: 0.9370 - val_loss: 0.2261 - val_accuracy: 0.9348\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 2s 32us/sample - loss: 0.2250 - accuracy: 0.9375 - val_loss: 0.2257 - val_accuracy: 0.9392\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2222 - accuracy: 0.9383 - val_loss: 0.2225 - val_accuracy: 0.9370\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2191 - accuracy: 0.9388 - val_loss: 0.2211 - val_accuracy: 0.9380\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2160 - accuracy: 0.9413 - val_loss: 0.2208 - val_accuracy: 0.9408\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2137 - accuracy: 0.9407 - val_loss: 0.2188 - val_accuracy: 0.9416\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2112 - accuracy: 0.9422 - val_loss: 0.2270 - val_accuracy: 0.9358\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2095 - accuracy: 0.9419 - val_loss: 0.2146 - val_accuracy: 0.9406\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2076 - accuracy: 0.9427 - val_loss: 0.2121 - val_accuracy: 0.9412\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2066 - accuracy: 0.9427 - val_loss: 0.2095 - val_accuracy: 0.9422\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 2s 32us/sample - loss: 0.2046 - accuracy: 0.9435 - val_loss: 0.2187 - val_accuracy: 0.9396\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.2040 - accuracy: 0.9431 - val_loss: 0.2175 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x1a4ecc1810>,\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_hidden': range(1, 10), 'n_neurons': range(1, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_cv3 = GridSearchCV(estimator=keras_clf3, param_grid=param_grid3,cv=3,verbose = 0)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_cv3.fit(train_images, train_labels, epochs=30,\n",
    "                  validation_data=(val_images, val_labels),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6069.762193918228 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 2, 'n_neurons': 9}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv3.best_params_ # parameters of best model obtain from GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the results to compare the performance of the 81 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = grid_cv3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_n_hidden', 'param_n_neurons', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_hidden': 1, 'n_neurons': 1},\n",
       " {'n_hidden': 1, 'n_neurons': 2},\n",
       " {'n_hidden': 1, 'n_neurons': 3},\n",
       " {'n_hidden': 1, 'n_neurons': 4},\n",
       " {'n_hidden': 1, 'n_neurons': 5},\n",
       " {'n_hidden': 1, 'n_neurons': 6},\n",
       " {'n_hidden': 1, 'n_neurons': 7},\n",
       " {'n_hidden': 1, 'n_neurons': 8},\n",
       " {'n_hidden': 1, 'n_neurons': 9},\n",
       " {'n_hidden': 2, 'n_neurons': 1},\n",
       " {'n_hidden': 2, 'n_neurons': 2},\n",
       " {'n_hidden': 2, 'n_neurons': 3},\n",
       " {'n_hidden': 2, 'n_neurons': 4},\n",
       " {'n_hidden': 2, 'n_neurons': 5},\n",
       " {'n_hidden': 2, 'n_neurons': 6},\n",
       " {'n_hidden': 2, 'n_neurons': 7},\n",
       " {'n_hidden': 2, 'n_neurons': 8},\n",
       " {'n_hidden': 2, 'n_neurons': 9},\n",
       " {'n_hidden': 3, 'n_neurons': 1},\n",
       " {'n_hidden': 3, 'n_neurons': 2},\n",
       " {'n_hidden': 3, 'n_neurons': 3},\n",
       " {'n_hidden': 3, 'n_neurons': 4},\n",
       " {'n_hidden': 3, 'n_neurons': 5},\n",
       " {'n_hidden': 3, 'n_neurons': 6},\n",
       " {'n_hidden': 3, 'n_neurons': 7},\n",
       " {'n_hidden': 3, 'n_neurons': 8},\n",
       " {'n_hidden': 3, 'n_neurons': 9},\n",
       " {'n_hidden': 4, 'n_neurons': 1},\n",
       " {'n_hidden': 4, 'n_neurons': 2},\n",
       " {'n_hidden': 4, 'n_neurons': 3},\n",
       " {'n_hidden': 4, 'n_neurons': 4},\n",
       " {'n_hidden': 4, 'n_neurons': 5},\n",
       " {'n_hidden': 4, 'n_neurons': 6},\n",
       " {'n_hidden': 4, 'n_neurons': 7},\n",
       " {'n_hidden': 4, 'n_neurons': 8},\n",
       " {'n_hidden': 4, 'n_neurons': 9},\n",
       " {'n_hidden': 5, 'n_neurons': 1},\n",
       " {'n_hidden': 5, 'n_neurons': 2},\n",
       " {'n_hidden': 5, 'n_neurons': 3},\n",
       " {'n_hidden': 5, 'n_neurons': 4},\n",
       " {'n_hidden': 5, 'n_neurons': 5},\n",
       " {'n_hidden': 5, 'n_neurons': 6},\n",
       " {'n_hidden': 5, 'n_neurons': 7},\n",
       " {'n_hidden': 5, 'n_neurons': 8},\n",
       " {'n_hidden': 5, 'n_neurons': 9},\n",
       " {'n_hidden': 6, 'n_neurons': 1},\n",
       " {'n_hidden': 6, 'n_neurons': 2},\n",
       " {'n_hidden': 6, 'n_neurons': 3},\n",
       " {'n_hidden': 6, 'n_neurons': 4},\n",
       " {'n_hidden': 6, 'n_neurons': 5},\n",
       " {'n_hidden': 6, 'n_neurons': 6},\n",
       " {'n_hidden': 6, 'n_neurons': 7},\n",
       " {'n_hidden': 6, 'n_neurons': 8},\n",
       " {'n_hidden': 6, 'n_neurons': 9},\n",
       " {'n_hidden': 7, 'n_neurons': 1},\n",
       " {'n_hidden': 7, 'n_neurons': 2},\n",
       " {'n_hidden': 7, 'n_neurons': 3},\n",
       " {'n_hidden': 7, 'n_neurons': 4},\n",
       " {'n_hidden': 7, 'n_neurons': 5},\n",
       " {'n_hidden': 7, 'n_neurons': 6},\n",
       " {'n_hidden': 7, 'n_neurons': 7},\n",
       " {'n_hidden': 7, 'n_neurons': 8},\n",
       " {'n_hidden': 7, 'n_neurons': 9},\n",
       " {'n_hidden': 8, 'n_neurons': 1},\n",
       " {'n_hidden': 8, 'n_neurons': 2},\n",
       " {'n_hidden': 8, 'n_neurons': 3},\n",
       " {'n_hidden': 8, 'n_neurons': 4},\n",
       " {'n_hidden': 8, 'n_neurons': 5},\n",
       " {'n_hidden': 8, 'n_neurons': 6},\n",
       " {'n_hidden': 8, 'n_neurons': 7},\n",
       " {'n_hidden': 8, 'n_neurons': 8},\n",
       " {'n_hidden': 8, 'n_neurons': 9},\n",
       " {'n_hidden': 9, 'n_neurons': 1},\n",
       " {'n_hidden': 9, 'n_neurons': 2},\n",
       " {'n_hidden': 9, 'n_neurons': 3},\n",
       " {'n_hidden': 9, 'n_neurons': 4},\n",
       " {'n_hidden': 9, 'n_neurons': 5},\n",
       " {'n_hidden': 9, 'n_neurons': 6},\n",
       " {'n_hidden': 9, 'n_neurons': 7},\n",
       " {'n_hidden': 9, 'n_neurons': 8},\n",
       " {'n_hidden': 9, 'n_neurons': 9}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 55, 47, 37, 27, 20, 15,  8,  4, 71, 60, 49, 34, 32, 25, 12,  6,\n",
       "        1, 69, 65, 53, 43, 36, 26, 17,  9,  2, 71, 68, 52, 54, 39, 30, 24,\n",
       "       18,  3, 71, 61, 57, 48, 38, 41, 28, 10,  5, 71, 71, 62, 58, 45, 42,\n",
       "       21, 19, 11, 71, 67, 63, 56, 46, 33, 23, 22,  7, 71, 71, 66, 71, 50,\n",
       "       35, 31, 13, 14, 70, 71, 71, 59, 51, 44, 40, 29, 16], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3['rank_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So once again we see that the best model  `{'n_hidden': 1, 'n_neurons': 4}` is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>n_neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_hidden  n_neurons\n",
       "0         1          1\n",
       "1         1          2\n",
       "2         1          3\n",
       "3         1          4\n",
       "4         1          5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(results3['params'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.855709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score\n",
       "0         0.391800\n",
       "1         0.683273\n",
       "2         0.789673\n",
       "3         0.855709\n",
       "4         0.885091"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['mean_test_score']\n",
    "df4=pd.DataFrame(results3['mean_test_score'],columns=col)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.885091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.762694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.820982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.852927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.881418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.902782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden  n_neurons  mean_test_score\n",
       "0          1          1         0.391800\n",
       "1          1          2         0.683273\n",
       "2          1          3         0.789673\n",
       "3          1          4         0.855709\n",
       "4          1          5         0.885091\n",
       "..       ...        ...              ...\n",
       "76         9          5         0.762694\n",
       "77         9          6         0.820982\n",
       "78         9          7         0.852927\n",
       "79         9          8         0.881418\n",
       "80         9          9         0.902782\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df3,df4],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.920782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.920018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.919182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.916691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.112345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden  n_neurons  mean_test_score\n",
       "17         2          9         0.923346\n",
       "26         3          9         0.920782\n",
       "35         4          9         0.920018\n",
       "8          1          9         0.919182\n",
       "44         5          9         0.916691\n",
       "..       ...        ...              ...\n",
       "73         9          2         0.112345\n",
       "9          2          1         0.112345\n",
       "63         8          1         0.112345\n",
       "66         8          4         0.112345\n",
       "27         4          1         0.112345\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='mean_test_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.789673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.885091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.762694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.820982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.852927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.881418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.902782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden  n_neurons  mean_test_score\n",
       "0          1          1         0.391800\n",
       "1          1          2         0.683273\n",
       "2          1          3         0.789673\n",
       "3          1          4         0.855709\n",
       "4          1          5         0.885091\n",
       "..       ...        ...              ...\n",
       "76         9          5         0.762694\n",
       "77         9          6         0.820982\n",
       "78         9          7         0.852927\n",
       "79         9          8         0.881418\n",
       "80         9          9         0.902782\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(df.n_hidden, df.n_neurons, df.mean_test_score, c='r', marker='o')\n",
    "\n",
    "ax.set_xlabel('n_hidden')\n",
    "ax.set_ylabel('n_neurons')\n",
    "ax.set_zlabel('mean_score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_cv3.best_estimator_.model\n",
    "keras.utils.plot_model(best_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/sample - loss: 0.2306 - accuracy: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23058634167909622, 0.9401]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1502 (Dense)           (None, 9)                 7065      \n",
      "_________________________________________________________________\n",
      "dense_1503 (Dense)           (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_1504 (Dense)           (None, 10)                100       \n",
      "=================================================================\n",
      "Total params: 7,255\n",
      "Trainable params: 7,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary() # on layer with 4 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "386.833px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
