{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATE: March 24, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1:\n",
    "\n",
    "In this assignment, we construct **dense neural networks** for classifying images from the `MNIST` dataset: http://yann.lecun.com/exdb/mnist/. The MNIST database consists of a set of 70,000 small (28x28 pixel) grayscale images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. \n",
    "\n",
    ">In **EXPERIMENTS 1 to 3**, we consider `dense neural network` models with one hidden layer. We start with one node in this hidden layer and progressively increase the number of (hidden) nodes in the layer until we find the \"best\" model in Experiment 3.\n",
    "\n",
    " But our goal in these `three` experiments is *not only* to find the \"best\" `dense neural network` model with one hidden but *also* to explore what the node(s) in the hidden layer are \"detecting\" and what their outputs (i.e. `activation values`) contribute to the final classification of an image. These are examples of intrinsic `local explanations` and `global explanations` , respectively, as described in this recent survey article: \n",
    "\n",
    "https://cacm.acm.org/magazines/2020/1/241703-techniques-for-interpretable-machine-learning/fulltext\n",
    "\n",
    "To determine what the hidden node is \"detecting\" we use gradient descent to find a visual pattern that maximizes the activation value of the hidden node, i.e. the visual pattern that the hidden node is maximally responsive to. In this case, the exercise is probably not very insightful. But in `Assignment 2`  we will repeat this analysis with \"clusters of nodes\" (`convnet filters`) in `convolutional neural network` models. By the examining the patterns that each convnet filter is maximally responsive (but also by visualizing the convnet activations for particular test images) we should be able to determine what (some of) the filters in the `CCN` model are up to.\n",
    "\n",
    "\n",
    "the (activation values of the) hidden nodes (actually, groups of hidden nodes corresponding or *convnet filters*) can be visualized in various ways to show what \"features\" (edges, texture, etc.) of the input images they capture.\n",
    "\n",
    ">In **EXPERIMENT 4** we use PCA decomposition to reduce the number of dimensions of our training set of 28x28 dimensional MNIST images from 784 to 154 (with 95% of training images variance lying along these components). We also reduce the number of dimensions of 'best' model from `Experiment 3` to 154 inputs nodes and train it on the new lower dimensional data. \n",
    "\n",
    ">In **EXPERIMENT 5** we use a Random Forest classifier to get the relative importance of the 784 features (pixels) of the 28x28 dimensional images in training set of MNIST images and select the top 70 features (pixels). We train our 'best' `dense neural network` using these 70 features and compare its performance to the the DNN models from EXPERIMENTS 3 and 4.\n",
    "\n",
    "\n",
    "Here are more details for the first `three` experiments:\n",
    "\n",
    "* **EXPERIMENT 1**: Our `dense neural network` will consist of 784 input nodes, a hidden layer with `1 node` and 10 output nodes (corresponding to the 10 digits). We use `mnist.load_data()` to get the 70,000 images divided into a set of 60,000 training images and 10,000 test images. We hold back 5,000 of the 60,000 training images for validation. After training the model, we group the 60,000 `activation values` of the hidden node for the (original) set of training images by the 10 predicted classes and visualize these sets of values using a `boxplot`. We expect the overlap between the range of values in the \"boxes\" to be minimal. In addition, we find the pattern that maximally activates the hidden node as a \"warm up\" exercise for similar analysis we will perform on `CNN` models in `Assignment 2`.\n",
    "\n",
    "* **EXPERIMENT 2**: This time our `dense neural network` will have 784 input nodes, a hidden layer with `2 nodes` and 10 output nodes (corresponding to the 10 digits). For each of the 60,000 images, the output of the two hidden nodes are plotted using a `scatterplot`. We color code the points according to which of the 10 classes the the output of the two nodes predicts. Ideally, just like in `EXPERIMENT 1`, the color clusters should have very little overlap.\n",
    "\n",
    "**NOTE**: For EXPERIMENTS 1 & 2 we also perform the following additional tasks:\n",
    "> 1. We use Matplotlib to create 2 plots--displaying the training and validation loss (resp. accuracy) for each (training) epoch side by side.\n",
    "> 2. For each model we obtain the confusion matrix and use it to display sample images of true vs false positives and negatives.\n",
    "\n",
    "\n",
    "* **EXPERIMENT 3**: Students can experiment with more hidden nodes (in the hidden layer) to obtain the `best` model. This `final` model will be used in EXPERIMENTS 4 & 5.\n",
    "\n",
    "\n",
    "**References**:\n",
    "https://github.com/fchollet/deep-learning-with-python-notebooks (2.1 & 5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages needed (and set seed)\n",
    "\n",
    "Since Keras in part of TensorFlow 2.x, we import keras from tensorflow and use tenserflow.keras.xxx to import all other Keras packages. The seed argument produces a deterministic sequence of tensors across multiple calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution() # neccessary for K.gradient to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "The MNIST dataset of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It comes prepackaged as part of tf.Keras. Use the `mnist.load_data()` to the get these datasets (and the corresponding labels) as Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT  2:\n",
    "\n",
    "Our `DNN` will consist of 784 input nodes, a hidden layer with `2 nodes` and 10 output nodes (corresponding to the 10 digits). We use `mnist.load_data()` to get the 70,000 images divided into a set of 60,000 training images and 10,000 test images. We hold back 5,000 of the 60,000 training images for validation. \n",
    "\n",
    "For each of the 60,000 training images, the output of the two hidden nodes are plotted using a scatterplot. We color code the points according to which of the 10 classes the the output of the two nodes predicts. Ideally, just like in EXPERIMENT 1, the color clusters should have very little overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the \\[0, 1] interval.\n",
    "\n",
    "Our training images are stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. \n",
    "\n",
    "We transform it into a float32 array of shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach\n",
    "\n",
    "Since we will be using categorical_crossentropy as the loss function we need to use to_categorical to convert the class vector of lables to binary matrix representation. \n",
    "\n",
    "We set apart 5,000 samples of our training data to use as a validation set. Since we will be using `sparse_categorical_crossentropy` as the loss function we **do not** need to use `to_categorical` to convert the class vector of labels to binary matrix representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, train_images = train_images[:5000], train_images[5000:] \n",
    "val_labels, train_labels = train_labels[:5000], train_labels[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "Here our network consists of a sequence of two `Dense` layers, which are densely-connected (also called \"fully-connected\") neural layers. \n",
    "\n",
    "The first `Dense` layer, the hidden layer, consists of `2 nodes`.\n",
    "\n",
    "The second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each  score will be the probability that the current digit image belongs to one of our 10 digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jensen116/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"mnist_model_2hnode.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "\n",
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be able to steer itself in the right direction.\n",
    "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "                loss='sparse_categorical_crossentropy',              \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We are now ready to train our network, which in Keras is done via a call to the `fit` method of the network: \n",
    "we \"fit\" the model to its training data. We train the model for 30 epochs with batch size 32 (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.6919 - accuracy: 0.3697 - val_loss: 1.4012 - val_accuracy: 0.4902\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 1.3194 - accuracy: 0.5150 - val_loss: 1.1962 - val_accuracy: 0.5728\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 1.1823 - accuracy: 0.5778 - val_loss: 1.1228 - val_accuracy: 0.6166\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 1.1320 - accuracy: 0.6028 - val_loss: 1.0933 - val_accuracy: 0.6260\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 1.1102 - accuracy: 0.6103 - val_loss: 1.0737 - val_accuracy: 0.6358\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.0969 - accuracy: 0.6185 - val_loss: 1.0747 - val_accuracy: 0.6300\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 1.0889 - accuracy: 0.6249 - val_loss: 1.0711 - val_accuracy: 0.6394\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 1.0826 - accuracy: 0.6304 - val_loss: 1.0554 - val_accuracy: 0.6564\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 1.0778 - accuracy: 0.6353 - val_loss: 1.0528 - val_accuracy: 0.6654\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 1.0737 - accuracy: 0.6399 - val_loss: 1.0497 - val_accuracy: 0.6640\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 1.0697 - accuracy: 0.6437 - val_loss: 1.0433 - val_accuracy: 0.6670\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 1.0664 - accuracy: 0.6481 - val_loss: 1.0409 - val_accuracy: 0.6716\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.0638 - accuracy: 0.6521 - val_loss: 1.0393 - val_accuracy: 0.6736\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 1.0604 - accuracy: 0.6555 - val_loss: 1.0408 - val_accuracy: 0.6752\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 1.0571 - accuracy: 0.6595 - val_loss: 1.0385 - val_accuracy: 0.6776\n",
      "Epoch 16/30\n",
      " 3744/55000 [=>............................] - ETA: 5s - loss: 1.0445 - accuracy: 0.6653"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=30,\n",
    "                    validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "Evaluate the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'test acc: {test_acc}, test loss: {test_loss}')  # Note very good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the performance \n",
    "\n",
    "We use Matplotlib to create 2 plots--displaying the training and validation loss (resp. accuracy) for each (training) epoch side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Let us see what the confusion matrix looks like. Using both `sklearn.metrics` and `tensorflow`. Then we visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes:\n",
    "pred_classes = model.predict_classes(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(train_labels,pred_classes)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apparently the line I added: tf.compat.v1.disable_eager_execution()\n",
    "# # broke this. But I don't really need to do this since I can use sklearn.\n",
    "# conf_mx2 = tf.math.confusion_matrix(train_labels, pred_classes)\n",
    "# conf_mx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the confusion matrix\n",
    "\n",
    "We use code from chapter 3 of Hands on Machine Learning (A. Geron) (cf. https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb) to display a \"heat map\" of the confusion matrix. Then we normalize the confusion matrix so we can compare error rates. \n",
    "\n",
    "See https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch03.html#classification_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.savefig(\"confusion_matrix_plot_mnist\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The confusion matrix looks better than the one in Experiment 1, doesn' it? Let us normalize the confusion matrix to get the error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.savefig(\"confusion_matrix_errors_plot_mnist_val\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This time let us illustrate the \"confusion\" between 5's and 8's with a grid of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = 'binary', **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 5,8\n",
    "X_aa = train_images[(train_labels == cl_a) & (pred_classes == cl_a)]\n",
    "X_ab = train_images[(train_labels == cl_a) & (pred_classes == cl_b)]\n",
    "X_ba = train_images[(train_labels == cl_b) & (pred_classes == cl_a)]\n",
    "X_bb = train_images[(train_labels == cl_b) & (pred_classes == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.savefig(\"error_analysis_digits_plot_EXP1_valid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Getting the activation values of the hidden nodes\n",
    " \n",
    " To get the activation values of the hidden nodes, we need to create a new model, `activation_model`, that takes the same input as our current model but outputs the activation value of the hidden layer, i.e. of the hidden node. Then use the `predict` function to get the activation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "# Extracts the outputs of the 2 layers:\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "print(f\"There are {len(layer_outputs)} layers\")\n",
    "layer_outputs # description of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of the hidden node for each of the 55000 training images\n",
    "activations = activation_model.predict(train_images)\n",
    "hidden_layer_activation = activations[0]\n",
    "hidden_layer_activation.shape   #  2 hidden node each has one activation value per training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_node1_activation = hidden_layer_activation[:,0] # get activation values of the first hidden node\n",
    "hidden_node2_activation = hidden_layer_activation[:,1] # get activation values of the second hidden node\n",
    "\n",
    "print(f\"The maximum activation value of the first hidden node is {hidden_node1_activation.max()}\")\n",
    "print(f\"The maximum activation value of the second hidden node is {hidden_node2_activation.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stats about the output layer as an aside...\n",
    "np.set_printoptions(suppress = True)  # display probabilities as decimals and NOT in scientific notation\n",
    "ouput_layer_activation = activations[1]\n",
    "print(f\"The output node has shape {ouput_layer_activation.shape}\")\n",
    "print(f\"The output for the first image are {ouput_layer_activation[0].round(4)}\")\n",
    "print(f\"The sum of the probabilities is (approximately) {ouput_layer_activation[0].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Creating the scatterplots\n",
    " \n",
    " We combine the activation values of the two hidden nodes together with the corresponding predicted classes into a DataFrame. We use both `matplotlib` and `seaborn` to create boxplots from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterPlot_df =  pd.DataFrame({'act_value_h1':hidden_node1_activation,\n",
    "                                'act_value_h2':hidden_node2_activation,\n",
    "                                'pred_class':pred_classes})\n",
    "scatterPlot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.legend(loc='upper left', prop={'size':6}, bbox_to_anchor=(1,1),ncol=1)\n",
    "plt.scatter(scatterPlot_df.act_value_h1, \n",
    "            scatterPlot_df.act_value_h2, \n",
    "            c=scatterPlot_df.pred_class,\n",
    "            label=scatterPlot_df.pred_class)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = scatterPlot_df.groupby('pred_class')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "for name, group in groups:\n",
    "    ax.plot(group.act_value_h1, group.act_value_h2, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
